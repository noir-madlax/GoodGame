"""
å¤šæ¨¡å‹è§†é¢‘æ¯”å¯¹åˆ†æè„šæœ¬
å¯¹æ¯” Gemini Flash 2.5 å’Œ Qwen3 VL æ¨¡å‹çš„æ€§èƒ½å’Œè¾“å‡ºè´¨é‡
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

# ç®€åŒ–çš„æ—¥å¿—ç±»
class SimpleLogger:
    """ç®€åŒ–çš„æ—¥å¿—ç±»"""
    def info(self, msg):
        print(f"[INFO] {msg}")
    
    def error(self, msg, exc_info=False):
        print(f"[ERROR] {msg}")
        if exc_info:
            import traceback
            traceback.print_exc()

log = SimpleLogger()

try:
    from google import genai
    from google.genai import types
except ImportError:
    genai = None
    types = None

import requests


def load_api_keys() -> Dict[str, str]:
    """ä» .env æ–‡ä»¶åŠ è½½æ‰€æœ‰ API Keys"""
    keys = {}
    
    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    keys["gemini"] = os.getenv("GEMINI_API_KEY", "")
    keys["openrouter"] = os.getenv("OPENROUTER_API_KEY", "")
    
    # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä» .env æ–‡ä»¶åŠ è½½
    env_paths = [
        Path(__file__).resolve().parent / ".env",
        Path(__file__).resolve().parents[1] / ".env",
        Path(__file__).resolve().parents[2] / ".env",
    ]
    
    for env_path in env_paths:
        if env_path.exists():
            log.info(f"ä» {env_path} åŠ è½½ç¯å¢ƒå˜é‡")
            with open(env_path) as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("GEMINI_API_KEY=") and not keys["gemini"]:
                        keys["gemini"] = line.split("=", 1)[1].strip().strip('"').strip("'")
                    elif line.startswith("OPENROUTER_API_KEY=") and not keys["openrouter"]:
                        keys["openrouter"] = line.split("=", 1)[1].strip().strip('"').strip("'")
    
    return keys


def encode_video_to_base64(video_path: Path) -> str:
    """å°†è§†é¢‘ç¼–ç ä¸º base64 å­—ç¬¦ä¸²"""
    with open(video_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


class ModelMetrics:
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.start_time = None
        self.end_time = None
        self.upload_time = 0
        self.inference_time = 0
        self.total_time = 0
        self.input_tokens = 0
        self.output_tokens = 0
        self.total_tokens = 0
        self.cost_input = 0.0
        self.cost_output = 0.0
        self.total_cost = 0.0
        self.success = False
        self.error_message = ""
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "model_name": self.model_name,
            "timing": {
                "upload_time_seconds": round(self.upload_time, 2),
                "inference_time_seconds": round(self.inference_time, 2),
                "total_time_seconds": round(self.total_time, 2)
            },
            "tokens": {
                "input_tokens": self.input_tokens,
                "output_tokens": self.output_tokens,
                "total_tokens": self.total_tokens
            },
            "cost": {
                "input_cost_usd": round(self.cost_input, 6),
                "output_cost_usd": round(self.cost_output, 6),
                "total_cost_usd": round(self.total_cost, 6)
            },
            "status": {
                "success": self.success,
                "error_message": self.error_message
            }
        }


class GeminiComparator:
    """Gemini æ¨¡å‹æ¯”å¯¹å™¨"""
    
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        if genai is None or types is None:
            raise RuntimeError("éœ€è¦å®‰è£… google-genai: pip install google-genai")
        self.api_key = api_key
        self.client = genai.Client(api_key=api_key)
        self.model_name = model_name
        self.metrics = ModelMetrics(f"Gemini {model_name}")
    
    def _wait_file_active(self, name: str, timeout_sec: int = 180) -> None:
        """è½®è¯¢æ–‡ä»¶çŠ¶æ€"""
        start = time.time()
        while True:
            info = self.client.files.get(name=name)
            state = getattr(info, "state", None)
            if str(state).endswith("ACTIVE") or str(state) == "ACTIVE":
                return
            if time.time() - start > timeout_sec:
                raise TimeoutError(f"æ–‡ä»¶ {name} åœ¨ {timeout_sec}ç§’ åä»æœª ACTIVE")
            time.sleep(3)
    
    def analyze(
        self,
        video1_path: Path,
        video2_path: Path,
        video1_summary: Dict[str, Any],
        video2_summary: Dict[str, Any],
        system_prompt: str,
        user_prompt: str
    ) -> Tuple[Dict[str, Any], ModelMetrics]:
        """ä½¿ç”¨ Gemini åˆ†æè§†é¢‘"""
        self.metrics.start_time = time.time()
        
        try:
            # ä¸Šä¼ è§†é¢‘
            upload_start = time.time()
            log.info(f"[{self.model_name}] ä¸Šä¼ è§†é¢‘1...")
            with open(video1_path, "rb") as f:
                file1_obj = self.client.files.upload(
                    file=f,
                    config=types.UploadFileConfig(
                        mime_type="video/mp4",
                        display_name=f"è§†é¢‘1-{video1_summary['video_id']}"
                    )
                )
            self._wait_file_active(getattr(file1_obj, "name"))
            
            log.info(f"[{self.model_name}] ä¸Šä¼ è§†é¢‘2...")
            with open(video2_path, "rb") as f:
                file2_obj = self.client.files.upload(
                    file=f,
                    config=types.UploadFileConfig(
                        mime_type="video/mp4",
                        display_name=f"è§†é¢‘2-{video2_summary['video_id']}"
                    )
                )
            self._wait_file_active(getattr(file2_obj, "name"))
            
            self.metrics.upload_time = time.time() - upload_start
            log.info(f"[{self.model_name}] âœ“ ä¸Šä¼ å®Œæˆ ({self.metrics.upload_time:.1f}ç§’)")
            
            # æ¨ç†åˆ†æ
            inference_start = time.time()
            log.info(f"[{self.model_name}] å¼€å§‹åˆ†æ...")
            
            contents = [
                types.Part.from_uri(
                    file_uri=getattr(file1_obj, "uri"),
                    mime_type="video/mp4"
                ),
                types.Part.from_uri(
                    file_uri=getattr(file2_obj, "uri"),
                    mime_type="video/mp4"
                ),
                user_prompt
            ]
            
            config = types.GenerateContentConfig(
                temperature=0.2,
                max_output_tokens=8000,
                response_mime_type="application/json",
                system_instruction=system_prompt,
            )
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=config,
            )
            
            self.metrics.inference_time = time.time() - inference_start
            
            # æå–ç»“æœ
            text = getattr(response, "text", None) or ""
            if not text:
                try:
                    cand = (getattr(response, "candidates", None) or [None])[0]
                    content = getattr(cand, "content", None)
                    if hasattr(content, "parts"):
                        text = "".join(getattr(p, "text", "") for p in content.parts)
                except Exception:
                    pass
            
            if not text:
                raise RuntimeError("æ¨¡å‹è¿”å›ç©ºå“åº”")
            
            # è§£æ JSON
            try:
                result = json.loads(text)
            except json.JSONDecodeError:
                s = text.strip()
                l = s.find("{")
                r = s.rfind("}")
                if 0 <= l < r:
                    result = json.loads(s[l : r + 1])
                else:
                    raise RuntimeError(f"æ— æ³•è§£æå“åº”ä¸º JSON")
            
            # æå– token ä½¿ç”¨æƒ…å†µ
            usage_metadata = getattr(response, "usage_metadata", None)
            if usage_metadata:
                self.metrics.input_tokens = getattr(usage_metadata, "prompt_token_count", 0)
                self.metrics.output_tokens = getattr(usage_metadata, "candidates_token_count", 0)
                self.metrics.total_tokens = getattr(usage_metadata, "total_token_count", 0)
            
            # Gemini 2.5 Flash å®šä»·ï¼ˆå‡è®¾ï¼‰
            # è¾“å…¥: $0.075 / 1M tokensï¼Œè¾“å‡º: $0.30 / 1M tokens
            self.metrics.cost_input = self.metrics.input_tokens * 0.075 / 1_000_000
            self.metrics.cost_output = self.metrics.output_tokens * 0.30 / 1_000_000
            self.metrics.total_cost = self.metrics.cost_input + self.metrics.cost_output
            
            self.metrics.end_time = time.time()
            self.metrics.total_time = self.metrics.end_time - self.metrics.start_time
            self.metrics.success = True
            
            log.info(f"[{self.model_name}] âœ“ åˆ†æå®Œæˆ")
            log.info(f"[{self.model_name}] è€—æ—¶: {self.metrics.total_time:.1f}ç§’")
            log.info(f"[{self.model_name}] Tokens: {self.metrics.input_tokens} è¾“å…¥, {self.metrics.output_tokens} è¾“å‡º")
            log.info(f"[{self.model_name}] æˆæœ¬: ${self.metrics.total_cost:.6f}")
            
            return result, self.metrics
            
        except Exception as e:
            self.metrics.end_time = time.time()
            self.metrics.total_time = self.metrics.end_time - self.metrics.start_time
            self.metrics.success = False
            self.metrics.error_message = str(e)
            log.error(f"[{self.model_name}] åˆ†æå¤±è´¥: {e}")
            raise


class OpenRouterComparator:
    """OpenRouter æ¨¡å‹æ¯”å¯¹å™¨ï¼ˆQwen3 VLï¼‰"""
    
    # ä»·æ ¼é…ç½®ï¼ˆæ ¹æ® OpenRouter ç½‘ç«™ï¼‰
    PRICING = {
        "qwen/qwen3-vl-32b-instruct": {
            "input": 0.35 / 1_000_000,   # $0.35/M tokens
            "output": 1.10 / 1_000_000   # $1.10/M tokens
        },
        "qwen/qwen3-vl-235b-a22b-instruct": {
            "input": 0.22 / 1_000_000,   # $0.22/M tokens
            "output": 0.88 / 1_000_000   # $0.88/M tokens
        }
    }
    
    def __init__(self, api_key: str, model_name: str):
        self.api_key = api_key
        self.model_name = model_name
        self.metrics = ModelMetrics(f"OpenRouter {model_name}")
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
    
    def analyze(
        self,
        video1_path: Path,
        video2_path: Path,
        video1_summary: Dict[str, Any],
        video2_summary: Dict[str, Any],
        system_prompt: str,
        user_prompt: str
    ) -> Tuple[Dict[str, Any], ModelMetrics]:
        """ä½¿ç”¨ OpenRouter / Qwen3 VL åˆ†æè§†é¢‘"""
        self.metrics.start_time = time.time()
        
        try:
            # æ³¨æ„ï¼šOpenRouter çš„ Qwen3 VL å¯èƒ½ä¸æ”¯æŒç›´æ¥ä¸Šä¼ è§†é¢‘æ–‡ä»¶
            # æˆ‘ä»¬å°è¯•ä½¿ç”¨ base64 ç¼–ç æˆ–æä¾›è§†é¢‘å¸§çš„æè¿°
            log.info(f"[{self.model_name}] å‡†å¤‡è§†é¢‘æ•°æ®...")
            upload_start = time.time()
            
            # å°è¯•æ–¹æ³•1: ä½¿ç”¨ base64 ç¼–ç ï¼ˆå¯èƒ½ä¼šå› ä¸ºæ–‡ä»¶å¤ªå¤§è€Œå¤±è´¥ï¼‰
            # å°è¯•æ–¹æ³•2: ä½¿ç”¨è§†é¢‘æ‘˜è¦ä½œä¸ºæ›¿ä»£
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è§†é¢‘æ‘˜è¦å’Œæ–‡æœ¬æè¿°ä½œä¸ºè¾“å…¥
            
            video_context = f"""
è§†é¢‘1ä¿¡æ¯ï¼š
- ID: {video1_summary.get('video_id')}
- æ ‡é¢˜: {video1_summary.get('title')}
- ä½œè€…: {video1_summary.get('author')}
- æ—¶é•¿: {video1_summary.get('duration', 0) / 1000:.1f}ç§’

è§†é¢‘2ä¿¡æ¯ï¼š
- ID: {video2_summary.get('video_id')}
- æ ‡é¢˜: {video2_summary.get('title')}
- ä½œè€…: {video2_summary.get('author')}
- æ—¶é•¿: {video2_summary.get('duration', 0) / 1000:.1f}ç§’

æ³¨æ„ï¼šç”±äº API é™åˆ¶ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥ä¸Šä¼ è§†é¢‘æ–‡ä»¶ã€‚è¯·åŸºäºæä¾›çš„è§†é¢‘å…ƒæ•°æ®å’Œæ ‡é¢˜ä¿¡æ¯è¿›è¡Œåˆ†æã€‚
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ï¼Œç›®çš„æ˜¯è¯„ä¼°åœ¨æ²¡æœ‰å®é™…è§†é¢‘å†…å®¹çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹èƒ½å¦æä¾›æœ‰ç”¨çš„åˆ†ææ¡†æ¶ã€‚
"""
            
            self.metrics.upload_time = time.time() - upload_start
            log.info(f"[{self.model_name}] âœ“ æ•°æ®å‡†å¤‡å®Œæˆ ({self.metrics.upload_time:.1f}ç§’)")
            
            # æ¨ç†åˆ†æ
            inference_start = time.time()
            log.info(f"[{self.model_name}] å¼€å§‹åˆ†æ...")
            
            # æ„å»ºè¯·æ±‚
            messages = [
                {
                    "role": "system",
                    "content": system_prompt + "\n\n" + video_context
                },
                {
                    "role": "user",
                    "content": user_prompt
                }
            ]
            
            payload = {
                "model": self.model_name,
                "messages": messages,
                "temperature": 0.2,
                "max_tokens": 8000,
                "response_format": {"type": "json_object"}
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/goodgame-video-analysis",
                "X-Title": "GoodGame Video Comparison"
            }
            
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=180
            )
            
            self.metrics.inference_time = time.time() - inference_start
            
            if response.status_code != 200:
                raise RuntimeError(f"API è¿”å›é”™è¯¯: {response.status_code} - {response.text}")
            
            data = response.json()
            
            # æå–ç»“æœ
            content = (data.get("choices") or [{}])[0].get("message", {}).get("content", "")
            if not content:
                raise RuntimeError("æ¨¡å‹è¿”å›ç©ºå“åº”")
            
            # è§£æ JSON
            try:
                result = json.loads(content)
            except json.JSONDecodeError:
                s = content.strip()
                l = s.find("{")
                r = s.rfind("}")
                if 0 <= l < r:
                    result = json.loads(s[l : r + 1])
                else:
                    raise RuntimeError(f"æ— æ³•è§£æå“åº”ä¸º JSON: {content[:200]}")
            
            # æå– token ä½¿ç”¨æƒ…å†µ
            usage = data.get("usage", {})
            self.metrics.input_tokens = usage.get("prompt_tokens", 0)
            self.metrics.output_tokens = usage.get("completion_tokens", 0)
            self.metrics.total_tokens = usage.get("total_tokens", 0)
            
            # è®¡ç®—æˆæœ¬
            pricing = self.PRICING.get(self.model_name, {"input": 0, "output": 0})
            self.metrics.cost_input = self.metrics.input_tokens * pricing["input"]
            self.metrics.cost_output = self.metrics.output_tokens * pricing["output"]
            self.metrics.total_cost = self.metrics.cost_input + self.metrics.cost_output
            
            self.metrics.end_time = time.time()
            self.metrics.total_time = self.metrics.end_time - self.metrics.start_time
            self.metrics.success = True
            
            log.info(f"[{self.model_name}] âœ“ åˆ†æå®Œæˆ")
            log.info(f"[{self.model_name}] è€—æ—¶: {self.metrics.total_time:.1f}ç§’")
            log.info(f"[{self.model_name}] Tokens: {self.metrics.input_tokens} è¾“å…¥, {self.metrics.output_tokens} è¾“å‡º")
            log.info(f"[{self.model_name}] æˆæœ¬: ${self.metrics.total_cost:.6f}")
            
            return result, self.metrics
            
        except Exception as e:
            self.metrics.end_time = time.time()
            self.metrics.total_time = self.metrics.end_time - self.metrics.start_time
            self.metrics.success = False
            self.metrics.error_message = str(e)
            log.error(f"[{self.model_name}] åˆ†æå¤±è´¥: {e}")
            raise


def build_prompts(video1_summary: Dict, video2_summary: Dict) -> Tuple[str, str]:
    """æ„å»ºåˆ†ææç¤ºè¯"""
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œä¸“é—¨ä»äº‹è§†é¢‘ä¾µæƒåˆ†æå’Œç›¸ä¼¼åº¦æ£€æµ‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä»”ç»†è§‚çœ‹å¹¶åˆ†æä¸¤ä¸ªè§†é¢‘çš„å†…å®¹
2. ä»å¤šä¸ªç»´åº¦æ¯”å¯¹ä¸¤ä¸ªè§†é¢‘çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§
3. æä¾›å®¢è§‚ã€è¯¦ç»†çš„åˆ†ææ•°æ®å’Œè¯æ®
4. **ä¸åšä¾µæƒç»“è®ºåˆ¤æ–­**ï¼Œåªæä¾›æ•°æ®åˆ†æåŸºç¡€

åˆ†æç»´åº¦åŒ…æ‹¬ä½†ä¸é™äºï¼š
- è§†è§‰å†…å®¹ï¼šåœºæ™¯ã€ç”»é¢æ„å›¾ã€è‰²å½©é£æ ¼ã€é•œå¤´è¯­è¨€
- éŸ³é¢‘å†…å®¹ï¼šèƒŒæ™¯éŸ³ä¹ã€é…éŸ³ã€éŸ³æ•ˆ
- æ–‡å­—å†…å®¹ï¼šå­—å¹•ã€æ ‡é¢˜ã€æ–‡æ¡ˆ
- å™äº‹ç»“æ„ï¼šæ•…äº‹çº¿ã€æƒ…èŠ‚å‘å±•ã€èŠ‚å¥
- åˆ›ä½œå…ƒç´ ï¼šç‰¹æ•ˆã€è½¬åœºã€å‰ªè¾‘æ‰‹æ³•
- æŠ€æœ¯å‚æ•°ï¼šåˆ†è¾¨ç‡ã€æ—¶é•¿ã€æ ¼å¼

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼Œç»“æ„å¦‚ä¸‹ï¼š
{
  "similarity_analysis": {
    "overall_similarity_score": <0-100çš„ç›¸ä¼¼åº¦è¯„åˆ†>,
    "visual_similarity": {
      "score": <0-100>,
      "description": "è§†è§‰ç›¸ä¼¼åº¦æè¿°",
      "evidence": ["è¯æ®1", "è¯æ®2", ...]
    },
    "audio_similarity": {
      "score": <0-100>,
      "description": "éŸ³é¢‘ç›¸ä¼¼åº¦æè¿°",
      "evidence": ["è¯æ®1", "è¯æ®2", ...]
    },
    "text_similarity": {
      "score": <0-100>,
      "description": "æ–‡å­—ç›¸ä¼¼åº¦æè¿°",
      "evidence": ["è¯æ®1", "è¯æ®2", ...]
    },
    "narrative_similarity": {
      "score": <0-100>,
      "description": "å™äº‹ç»“æ„ç›¸ä¼¼åº¦æè¿°",
      "evidence": ["è¯æ®1", "è¯æ®2", ...]
    }
  },
  "difference_analysis": {
    "visual_differences": ["å·®å¼‚1", "å·®å¼‚2", ...],
    "audio_differences": ["å·®å¼‚1", "å·®å¼‚2", ...],
    "text_differences": ["å·®å¼‚1", "å·®å¼‚2", ...],
    "narrative_differences": ["å·®å¼‚1", "å·®å¼‚2", ...],
    "technical_differences": ["å·®å¼‚1", "å·®å¼‚2", ...]
  },
  "transformation_analysis": {
    "modifications": ["ä¿®æ”¹1", "ä¿®æ”¹2", ...],
    "additions": ["æ–°å¢å†…å®¹1", "æ–°å¢å†…å®¹2", ...],
    "deletions": ["åˆ é™¤å†…å®¹1", "åˆ é™¤å†…å®¹2", ...],
    "rearrangements": ["é‡æ–°æ’åˆ—1", "é‡æ–°æ’åˆ—2", ...]
  },
  "content_overlap": {
    "shared_scenes": ["å…±åŒåœºæ™¯æè¿°1", "å…±åŒåœºæ™¯æè¿°2", ...],
    "shared_dialogues": ["å…±åŒå¯¹è¯1", "å…±åŒå¯¹è¯2", ...],
    "shared_visual_elements": ["å…±åŒè§†è§‰å…ƒç´ 1", "å…±åŒè§†è§‰å…ƒç´ 2", ...]
  },
  "metadata_comparison": {
    "duration_comparison": "æ—¶é•¿å¯¹æ¯”æè¿°",
    "quality_comparison": "ç”»è´¨å¯¹æ¯”æè¿°",
    "format_comparison": "æ ¼å¼å¯¹æ¯”æè¿°"
  },
  "summary": {
    "key_findings": ["å…³é”®å‘ç°1", "å…³é”®å‘ç°2", ...],
    "data_quality_notes": "æ•°æ®è´¨é‡è¯´æ˜"
  }
}

æ³¨æ„ï¼š
1. æ‰€æœ‰åˆ†æ•°ä½¿ç”¨ 0-100 çš„èŒƒå›´
2. è¯æ®å’Œæè¿°è¦å…·ä½“ã€å®¢è§‚
3. ä¸è¦ä½¿ç”¨"ä¾µæƒ"ã€"æŠ„è¢­"ç­‰ç»“è®ºæ€§è¯æ±‡
4. ä¸“æ³¨äºå¯è§‚æµ‹çš„äº‹å®å’Œæ•°æ®"""
    
    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªè§†é¢‘çš„ç›¸ä¼¼åº¦å’Œå·®å¼‚ã€‚

**è§†é¢‘1åŸºæœ¬ä¿¡æ¯ï¼š**
- ID: {video1_summary.get('video_id', 'N/A')}
- æ ‡é¢˜: {video1_summary.get('title', 'N/A')}
- ä½œè€…: {video1_summary.get('author', 'N/A')}
- æ—¶é•¿: {video1_summary.get('duration', 0) / 1000:.1f}ç§’

**è§†é¢‘2åŸºæœ¬ä¿¡æ¯ï¼š**
- ID: {video2_summary.get('video_id', 'N/A')}
- æ ‡é¢˜: {video2_summary.get('title', 'N/A')}
- ä½œè€…: {video2_summary.get('author', 'N/A')}
- æ—¶é•¿: {video2_summary.get('duration', 0) / 1000:.1f}ç§’

è¯·æŒ‰ç…§ç³»ç»ŸæŒ‡ä»¤ä¸­å®šä¹‰çš„ JSON æ ¼å¼ï¼Œæä¾›å®Œæ•´çš„åˆ†æç»“æœã€‚"""
    
    return system_prompt, user_prompt


def validate_result(result: Dict[str, Any], model_name: str) -> Dict[str, Any]:
    """éªŒè¯åˆ†æç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ"""
    validation = {
        "model_name": model_name,
        "is_valid": True,
        "missing_fields": [],
        "invalid_scores": [],
        "completeness_score": 0,
        "notes": []
    }
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = [
        "similarity_analysis",
        "difference_analysis",
        "transformation_analysis",
        "content_overlap",
        "metadata_comparison",
        "summary"
    ]
    
    for field in required_fields:
        if field not in result:
            validation["missing_fields"].append(field)
            validation["is_valid"] = False
    
    # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†æ•°
    if "similarity_analysis" in result:
        sim = result["similarity_analysis"]
        score_fields = ["overall_similarity_score", "visual_similarity", "audio_similarity", 
                       "text_similarity", "narrative_similarity"]
        for field in score_fields:
            if field == "overall_similarity_score":
                score = sim.get(field, -1)
            else:
                score = sim.get(field, {}).get("score", -1)
            
            if score < 0 or score > 100:
                validation["invalid_scores"].append(f"{field}: {score}")
                validation["is_valid"] = False
    
    # è®¡ç®—å®Œæ•´æ€§å¾—åˆ†
    total_fields = len(required_fields)
    present_fields = total_fields - len(validation["missing_fields"])
    validation["completeness_score"] = int((present_fields / total_fields) * 100)
    
    # æ·»åŠ æ³¨é‡Š
    if validation["is_valid"]:
        validation["notes"].append("ç»“æœç»“æ„å®Œæ•´ï¼Œç¬¦åˆé¢„æœŸ")
    else:
        if validation["missing_fields"]:
            validation["notes"].append(f"ç¼ºå°‘å­—æ®µ: {', '.join(validation['missing_fields'])}")
        if validation["invalid_scores"]:
            validation["notes"].append(f"æ— æ•ˆè¯„åˆ†: {', '.join(validation['invalid_scores'])}")
    
    return validation


def main():
    """ä¸»å‡½æ•°"""
    # è§†é¢‘æ–‡ä»¶è·¯å¾„
    video1_path = Path(__file__).resolve().parent / "output" / "7521959446235548985" / "v1.mp4"
    video2_path = Path(__file__).resolve().parent / "output" / "7523787273016839434" / "7523787273016839434.mp4"
    
    # æ‘˜è¦æ–‡ä»¶è·¯å¾„
    summary1_path = video1_path.parent / "summary.json"
    summary2_path = video2_path.parent / "summary.json"
    
    # è¾“å‡ºç›®å½•
    output_dir = Path(__file__).resolve().parent / "output"
    
    print("\n" + "=" * 80)
    print("å¤šæ¨¡å‹è§†é¢‘æ¯”å¯¹åˆ†æå·¥å…·")
    print("å¯¹æ¯” Gemini Flash 2.5 å’Œ Qwen3 VL æ¨¡å‹")
    print("=" * 80 + "\n")
    
    # éªŒè¯æ–‡ä»¶
    for path in [video1_path, video2_path, summary1_path, summary2_path]:
        if not path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    
    # åŠ è½½æ‘˜è¦
    with open(summary1_path) as f:
        video1_summary = json.load(f)
    with open(summary2_path) as f:
        video2_summary = json.load(f)
    
    # åŠ è½½ API Keys
    api_keys = load_api_keys()
    print(f"âœ“ Gemini API Key: {api_keys['gemini'][:20]}...")
    print(f"âœ“ OpenRouter API Key: {api_keys['openrouter'][:20]}...\n")
    
    # æ„å»ºæç¤ºè¯
    system_prompt, user_prompt = build_prompts(video1_summary, video2_summary)
    
    # å®šä¹‰è¦æµ‹è¯•çš„æ¨¡å‹
    models_to_test = []
    
    # 1. Gemini Flash 2.5
    if api_keys["gemini"]:
        models_to_test.append(("gemini", "gemini-2.5-flash", api_keys["gemini"]))
    
    # 2. Qwen3 VL 32B
    if api_keys["openrouter"]:
        models_to_test.append(("openrouter", "qwen/qwen3-vl-32b-instruct", api_keys["openrouter"]))
    
    # 3. Qwen3 VL 235B
    if api_keys["openrouter"]:
        models_to_test.append(("openrouter", "qwen/qwen3-vl-235b-a22b-instruct", api_keys["openrouter"]))
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    all_metrics = []
    all_validations = []
    
    # è¿è¡Œæµ‹è¯•
    for i, (provider, model_name, api_key) in enumerate(models_to_test, 1):
        print("=" * 80)
        print(f"æµ‹è¯• {i}/{len(models_to_test)}: {model_name}")
        print("=" * 80 + "\n")
        
        try:
            if provider == "gemini":
                comparator = GeminiComparator(api_key, model_name)
            else:
                comparator = OpenRouterComparator(api_key, model_name)
            
            result, metrics = comparator.analyze(
                video1_path, video2_path,
                video1_summary, video2_summary,
                system_prompt, user_prompt
            )
            
            # éªŒè¯ç»“æœ
            validation = validate_result(result, model_name)
            
            all_results.append({
                "model": model_name,
                "provider": provider,
                "result": result
            })
            all_metrics.append(metrics.to_dict())
            all_validations.append(validation)
            
            # ä¿å­˜å•ä¸ªæ¨¡å‹çš„ç»“æœ
            output_file = output_dir / f"comparison_{model_name.replace('/', '_')}.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"\nâœ“ ç»“æœå·²ä¿å­˜: {output_file.name}\n")
            
        except Exception as e:
            log.error(f"æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            all_metrics.append(ModelMetrics(model_name).to_dict())
            all_validations.append({
                "model_name": model_name,
                "is_valid": False,
                "error": str(e)
            })
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 80)
    print("å¯¹æ¯”æŠ¥å‘Š")
    print("=" * 80 + "\n")
    
    comparison_report = {
        "timestamp": datetime.now().isoformat(),
        "models_tested": len(models_to_test),
        "metrics_comparison": all_metrics,
        "validation_results": all_validations,
        "summary": {
            "fastest_model": None,
            "most_cost_effective": None,
            "highest_quality": None
        }
    }
    
    # æ‰¾å‡ºæœ€å¿«çš„æ¨¡å‹
    successful_metrics = [m for m in all_metrics if m["status"]["success"]]
    if successful_metrics:
        fastest = min(successful_metrics, key=lambda x: x["timing"]["total_time_seconds"])
        comparison_report["summary"]["fastest_model"] = fastest["model_name"]
        
        # æ‰¾å‡ºæœ€ç»æµçš„æ¨¡å‹
        cheapest = min(successful_metrics, key=lambda x: x["cost"]["total_cost_usd"])
        comparison_report["summary"]["most_cost_effective"] = cheapest["model_name"]
        
        # æ‰¾å‡ºè´¨é‡æœ€é«˜çš„æ¨¡å‹ï¼ˆåŸºäºå®Œæ•´æ€§ï¼‰
        validations_with_scores = [(v, m) for v, m in zip(all_validations, all_metrics) 
                                   if m["status"]["success"]]
        if validations_with_scores:
            best_quality = max(validations_with_scores, 
                             key=lambda x: x[0].get("completeness_score", 0))
            comparison_report["summary"]["highest_quality"] = best_quality[1]["model_name"]
    
    # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
    report_file = output_dir / "model_comparison_report.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(comparison_report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}\n")
    
    # æ‰“å°æ‘˜è¦
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼š\n")
    for metrics in all_metrics:
        print(f"æ¨¡å‹: {metrics['model_name']}")
        print(f"  - çŠ¶æ€: {'âœ… æˆåŠŸ' if metrics['status']['success'] else 'âŒ å¤±è´¥'}")
        if metrics['status']['success']:
            print(f"  - æ€»è€—æ—¶: {metrics['timing']['total_time_seconds']}ç§’")
            print(f"  - Tokens: {metrics['tokens']['input_tokens']} è¾“å…¥ / {metrics['tokens']['output_tokens']} è¾“å‡º")
            print(f"  - æˆæœ¬: ${metrics['cost']['total_cost_usd']:.6f}")
        else:
            print(f"  - é”™è¯¯: {metrics['status']['error_message']}")
        print()
    
    print("\nğŸ“‹ è´¨é‡éªŒè¯ï¼š\n")
    for validation in all_validations:
        print(f"æ¨¡å‹: {validation['model_name']}")
        print(f"  - æœ‰æ•ˆæ€§: {'âœ… æœ‰æ•ˆ' if validation.get('is_valid', False) else 'âŒ æ— æ•ˆ'}")
        print(f"  - å®Œæ•´æ€§: {validation.get('completeness_score', 0)}%")
        if validation.get('notes'):
            for note in validation['notes']:
                print(f"  - {note}")
        print()
    
    if comparison_report["summary"]["fastest_model"]:
        print("\nğŸ† æœ€ä½³æ¨¡å‹ï¼š\n")
        print(f"âš¡ æœ€å¿«: {comparison_report['summary']['fastest_model']}")
        print(f"ğŸ’° æœ€ç»æµ: {comparison_report['summary']['most_cost_effective']}")
        print(f"ğŸ¯ è´¨é‡æœ€é«˜: {comparison_report['summary']['highest_quality']}")
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
