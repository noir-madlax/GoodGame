#!/usr/bin/env python3
"""
è§†é¢‘æŠ„è¢­åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ - ä½¿ç”¨ Gemini 2.0 Flash Thinking ç”Ÿæˆä¸“ä¸šæŠ¥å‘Šå¹¶è¾“å‡ºä¸º PDF
"""
import os
import sys
import json
from pathlib import Path
from typing import Dict, Any
from datetime import datetime

# ç®€åŒ–çš„æ—¥å¿—ç±»
class SimpleLogger:
    """ç®€åŒ–çš„æ—¥å¿—ç±»"""
    def info(self, msg):
        print(f"[INFO] {msg}")
    
    def error(self, msg, exc_info=False):
        print(f"[ERROR] {msg}")
        if exc_info:
            import traceback
            traceback.print_exc()

log = SimpleLogger()

try:
    from google import genai
    from google.genai import types
except ImportError:
    log.error("éœ€è¦å®‰è£… google-genai: pip install google-genai")
    sys.exit(1)

try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import cm
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.enums import TA_LEFT, TA_CENTER, TA_JUSTIFY
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle
    from reportlab.lib import colors
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
except ImportError:
    log.error("éœ€è¦å®‰è£… reportlab: pip install reportlab")
    sys.exit(1)


# Gemini é…ç½® - ä½¿ç”¨ Thinking æ¨¡å‹ç”Ÿæˆæ›´ä¸“ä¸šçš„æŠ¥å‘Š
GEMINI_MODEL = "gemini-2.0-flash-thinking-exp"


def load_api_key_from_env() -> str:
    """ä» .env æ–‡ä»¶åŠ è½½ Gemini API Key"""
    # å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    for env_var in ["GEMINI_API_KEY_ANALYZE", "GEMINI_API_KEY"]:
        api_key = os.getenv(env_var, "")
        if api_key:
            return api_key
    
    # å°è¯•ä»å¤šä¸ªä½ç½®æŸ¥æ‰¾ .env æ–‡ä»¶
    env_paths = [
        Path(__file__).resolve().parent / ".env",
        Path(__file__).resolve().parents[1] / ".env",
        Path(__file__).resolve().parents[2] / ".env",
        Path(__file__).resolve().parents[3] / ".env",
    ]
    
    for env_path in env_paths:
        if env_path.exists():
            log.info(f"ä» {env_path} åŠ è½½ç¯å¢ƒå˜é‡")
            with open(env_path) as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("GEMINI_API_KEY_ANALYZE=") or line.startswith("GEMINI_API_KEY="):
                        api_key = line.split("=", 1)[1].strip().strip('"').strip("'")
                        if api_key:
                            return api_key
    
    raise RuntimeError("æœªæ‰¾åˆ° GEMINI_API_KEY æˆ– GEMINI_API_KEY_ANALYZE ç¯å¢ƒå˜é‡")


class VideoReportGenerator:
    """è§†é¢‘åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            api_key: Gemini APIå¯†é’¥
        """
        self.api_key = api_key
        self.client = genai.Client(api_key=api_key)
        self.model = GEMINI_MODEL
    
    def generate_report_text(
        self,
        analysis: Dict[str, Any]
    ) -> str:
        """ä½¿ç”¨ Gemini ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
        
        Args:
            analysis: è§†é¢‘å¯¹æ¯”åˆ†æç»“æœ
            
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡æœ¬
        """
        log.info("å¼€å§‹ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬...")
        
        # æ„å»ºæç¤ºè¯
        system_prompt = self._build_system_prompt()
        user_prompt = self._build_user_prompt(analysis)
        
        # é…ç½®ç”Ÿæˆå‚æ•°
        config = types.GenerateContentConfig(
            temperature=0.3,
            max_output_tokens=8000,
            system_instruction=system_prompt,
        )
        
        # è°ƒç”¨ Gemini API
        log.info(f"è°ƒç”¨ Gemini {self.model} æ¨¡å‹ç”ŸæˆæŠ¥å‘Š...")
        
        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=user_prompt,
                config=config,
            )
            
            # æå–å“åº”æ–‡æœ¬
            text = getattr(response, "text", None) or ""
            if not text:
                # å°è¯•ä» candidates æå–
                try:
                    cand = (getattr(response, "candidates", None) or [None])[0]
                    content = getattr(cand, "content", None)
                    if hasattr(content, "parts"):
                        text = "".join(getattr(p, "text", "") for p in content.parts)
                except Exception:
                    pass
            
            if not text:
                raise RuntimeError("Gemini è¿”å›ç©ºå“åº”")
            
            log.info("âœ“ æŠ¥å‘Šæ–‡æœ¬ç”Ÿæˆå®Œæˆ")
            return text
        
        except Exception as e:
            log.error(f"ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬å¤±è´¥: {e}", exc_info=True)
            raise
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„çŸ¥è¯†äº§æƒæ³•å¾‹é¡¾é—®å’Œè§†é¢‘å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿æ’°å†™è§†é¢‘æŠ„è¢­å’Œæ¬è¿åˆ†ææŠ¥å‘Šã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åŸºäºæä¾›çš„å®Œæ•´è§†é¢‘å¯¹æ¯”åˆ†ææ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šã€è¯¦å°½çš„è§†é¢‘æŠ„è¢­/æ¬è¿åˆ†ææŠ¥å‘Š
2. æŠ¥å‘Šå¿…é¡»æ¶µç›–æ‰€æœ‰åŸå§‹æ•°æ®ä¸­çš„ç»†èŠ‚ï¼ŒåŒ…æ‹¬æ‰€æœ‰è¯„åˆ†ã€æè¿°ã€è¯æ®åˆ—è¡¨ã€å·®å¼‚é¡¹ã€ä¿®æ”¹åˆ†æç­‰
3. ä¸å¾—æ¦‚æ‹¬ã€ç®€åŒ–æˆ–é—æ¼ä»»ä½•åŸå§‹æ•°æ®ä¸­çš„ä¿¡æ¯
4. ä¿æŒåŸå§‹åˆ†æçš„é¢—ç²’åº¦å’Œç»†èŠ‚å±‚æ¬¡

æ ¸å¿ƒè¦æ±‚ï¼ˆæå…¶é‡è¦ï¼‰ï¼š
- **ä¿ç•™æ‰€æœ‰è¯æ®åˆ—è¡¨**ï¼šæ¯ä¸ªç»´åº¦çš„ evidence åˆ—è¡¨å¿…é¡»å®Œæ•´å‘ˆç°ï¼Œé€æ¡åˆ—å‡º
- **ä¿ç•™æ‰€æœ‰æè¿°**ï¼šæ¯ä¸ªåˆ†æç»´åº¦çš„ description å¿…é¡»å®Œæ•´å¼•ç”¨æˆ–æ”¹å†™
- **ä¿ç•™æ‰€æœ‰å·®å¼‚é¡¹**ï¼šdifference_analysis ä¸­çš„æ‰€æœ‰åˆ—è¡¨é¡¹å¿…é¡»å®Œæ•´å‘ˆç°
- **ä¿ç•™æ‰€æœ‰ä¿®æ”¹åˆ†æ**ï¼šmodification_analysis çš„æ‰€æœ‰å­—æ®µå¿…é¡»è¯¦ç»†è¯´æ˜
- **ä¿ç•™å®Œæ•´çš„ä¾µæƒè¯„ä¼°**ï¼šreasoningã€key_indicatorsã€mitigating_factorsã€aggravating_factors å¿…é¡»å®Œæ•´å‘ˆç°

æŠ¥å‘Šç»“æ„è¦æ±‚ï¼š
1. æŠ¥å‘Šæ ‡é¢˜å’Œæ—¥æœŸ
2. æ‰§è¡Œæ‘˜è¦ï¼ˆç®€è¦æ¦‚è¿°æ ¸å¿ƒç»“è®ºå’Œé£é™©ç­‰çº§ï¼‰
3. è§†é¢‘ä¿¡æ¯æ¦‚è§ˆ
   - åŸå§‹è§†é¢‘ä¿¡æ¯
   - ç–‘ä¼¼æŠ„è¢­/æ¬è¿è§†é¢‘ä¿¡æ¯
   - åˆ†ææ—¶é—´
4. ç›¸ä¼¼åº¦åˆ†æ
   - å†…å®¹ç›¸ä¼¼åº¦ï¼ˆè¯„åˆ†ã€æè¿°ã€æ‰€æœ‰è¯æ®é¡¹ï¼‰
   - è§†è§‰ç›¸ä¼¼åº¦ï¼ˆè¯„åˆ†ã€æè¿°ã€æ‰€æœ‰è¯æ®é¡¹ï¼‰
   - éŸ³é¢‘ç›¸ä¼¼åº¦ï¼ˆè¯„åˆ†ã€æè¿°ã€æ‰€æœ‰è¯æ®é¡¹ï¼‰
   - æ—¶é—´ç»“æ„ç›¸ä¼¼åº¦ï¼ˆè¯„åˆ†ã€æè¿°ã€æ‰€æœ‰è¯æ®é¡¹ï¼‰
5. å·®å¼‚åˆ†æ
   - å†…å®¹å·®å¼‚ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - è§†è§‰å·®å¼‚ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - éŸ³é¢‘å·®å¼‚ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
6. ä¿®æ”¹åˆ†æ
   - æ£€æµ‹åˆ°çš„ä¿®æ”¹ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - è£å‰ªåˆ†æï¼ˆå®Œæ•´æè¿°ï¼‰
   - é•œåƒåˆ†æï¼ˆå®Œæ•´æè¿°ï¼‰
   - å˜é€Ÿåˆ†æï¼ˆå®Œæ•´æè¿°ï¼‰
   - æ°´å°å˜åŒ–ï¼ˆå®Œæ•´æè¿°ï¼‰
   - è°ƒè‰²åˆ†æï¼ˆå®Œæ•´æè¿°ï¼‰
   - å…¶ä»–ä¿®æ”¹ï¼ˆå®Œæ•´æè¿°ï¼‰
7. åˆ›ä½œæ€§è¯„ä¼°
   - æ˜¯å¦æœ‰å®è´¨æ€§åˆ›ä½œ
   - åˆ›ä½œæ€§è¯„åˆ†
   - è¯¦ç»†æè¿°å’Œè¯æ®
8. ä¾µæƒè¯„ä¼°
   - ç»¼åˆç›¸ä¼¼åº¦è¯„åˆ†
   - é£é™©ç­‰çº§å’Œé£é™©è¯„åˆ†
   - æ¨ç†è¿‡ç¨‹ï¼ˆå®Œæ•´å¼•ç”¨ï¼‰
   - å…³é”®æŒ‡æ ‡ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - å‡è½»å› ç´ ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - åŠ é‡å› ç´ ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
9. ç»“è®ºå’Œå»ºè®®
   - æ˜¯å¦æ¶‰å«ŒæŠ„è¢­
   - ç½®ä¿¡åº¦
   - ç»¼åˆæ€»ç»“
   - æ ¸å¿ƒå‘ç°ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰
   - å»ºè®®ï¼ˆåˆ—å‡ºæ‰€æœ‰é¡¹ï¼‰

å†™ä½œé£æ ¼ï¼š
- ä½¿ç”¨æ­£å¼ã€ä¸“ä¸šçš„æ³•å¾‹å’ŒæŠ€æœ¯æŠ¥å‘Šè¯­æ°”
- é€é¡¹åˆ—ä¸¾è¯æ®å’Œå‘ç°ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·åˆ—è¡¨
- ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œä½†è®ºè¿°è¦æœ‰åŠ›ä¸”æœ‰è¯´æœåŠ›
- é¿å…ä½¿ç”¨ç¬¬ä¸€äººç§°
- ä½¿ç”¨ä¸­æ–‡æ’°å†™ï¼Œè¡¨è¾¾å‡†ç¡®ã€æµç•…ã€ä¸“ä¸š

ç‰¹åˆ«å¼ºè°ƒï¼š
- ä½ çš„ä»»åŠ¡æ˜¯å°†ç»“æ„åŒ–çš„ JSON æ•°æ®è½¬åŒ–ä¸ºæµç•…çš„æŠ¥å‘Šæ–‡æœ¬ï¼Œè€Œä¸æ˜¯é‡æ–°åˆ†ææˆ–æ¦‚æ‹¬
- æ‰€æœ‰æ•°å€¼ã€è¯æ®ã€æè¿°éƒ½å¿…é¡»æ¥è‡ªåŸå§‹æ•°æ®ï¼Œä¸å¾—è‡ªè¡Œåˆ›ä½œæˆ–çœç•¥
- æŠ¥å‘Šçš„é•¿åº¦å’Œç»†èŠ‚åº”ä¸åŸå§‹æ•°æ®çš„ä¸°å¯Œç¨‹åº¦ç›¸åŒ¹é…

è¯·ç›´æ¥è¾“å‡ºæŠ¥å‘Šæ­£æ–‡ï¼Œä¸è¦åŒ…å« Markdown æ ¼å¼æ ‡è®°ã€‚"""
    
    def _build_user_prompt(
        self,
        analysis: Dict[str, Any]
    ) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯ - æä¾›å®Œæ•´çš„ JSON æ•°æ®
        
        Args:
            analysis: å®Œæ•´çš„è§†é¢‘å¯¹æ¯”åˆ†æç»“æœ
            
        Returns:
            ç”¨æˆ·æç¤ºè¯ï¼ˆåŒ…å«å®Œæ•´çš„ JSON æ•°æ®ï¼‰
        """
        # å°† JSON æ•°æ®æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
        analysis_json = json.dumps(analysis, ensure_ascii=False, indent=2)
        
        # æå–å…³é”®ä¿¡æ¯
        video_info = analysis.get("video_info", {})
        original_video = video_info.get("original_video", "è§†é¢‘1")
        suspected_video = video_info.get("suspected_video", "è§†é¢‘2")
        
        return f"""è¯·åŸºäºä»¥ä¸‹è§†é¢‘å¯¹æ¯”åˆ†æçš„å®Œæ•´æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šã€è¯¦å°½çš„è§†é¢‘æŠ„è¢­/æ¬è¿åˆ†ææŠ¥å‘Šã€‚

é‡è¦æç¤ºï¼š
1. ä»¥ä¸‹æä¾›çš„æ˜¯å®Œæ•´çš„ JSON åˆ†ææ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰ç»´åº¦çš„è¯„åˆ†ã€æè¿°ã€è¯æ®åˆ—è¡¨ã€å·®å¼‚åˆ†æã€ä¿®æ”¹åˆ†æç­‰
2. ä½ å¿…é¡»å°†è¿™äº›ç»“æ„åŒ–æ•°æ®è½¬åŒ–ä¸ºæµç•…ã€ä¸“ä¸šçš„æŠ¥å‘Šæ–‡æœ¬
3. ä¸å¾—é—æ¼ä»»ä½•æ•°æ®å­—æ®µæˆ–åˆ—è¡¨é¡¹
4. ä¿æŒåŸå§‹æ•°æ®çš„ç»†èŠ‚é¢—ç²’åº¦å’Œä¸“ä¸šæ·±åº¦

==================== è§†é¢‘å¯¹æ¯”åˆ†ææ•°æ® ====================

è§†é¢‘ä¿¡æ¯ï¼š
- åŸå§‹è§†é¢‘ï¼š{original_video}
- ç–‘ä¼¼æŠ„è¢­/æ¬è¿è§†é¢‘ï¼š{suspected_video}
- åˆ†æç±»å‹ï¼šè§†é¢‘å†…å®¹æŠ„è¢­å’Œæ¬è¿æ£€æµ‹

å®Œæ•´åˆ†ææ•°æ®ï¼ˆJSONï¼‰ï¼š
{analysis_json}

==================== æŠ¥å‘Šæ’°å†™è¦æ±‚ ====================

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æ’°å†™æŠ¥å‘Šï¼Œç¡®ä¿æ¶µç›–æ‰€æœ‰ä¸Šè¿° JSON æ•°æ®ä¸­çš„ä¿¡æ¯ï¼š

1. æŠ¥å‘Šæ ‡é¢˜å’Œæ—¥æœŸ

2. æ‰§è¡Œæ‘˜è¦
   - ç®€è¦è¯´æ˜æŠ¥å‘Šç›®çš„
   - æ¦‚è¿°æ ¸å¿ƒç»“è®ºå’Œé£é™©ç­‰çº§

3. è§†é¢‘ä¿¡æ¯æ¦‚è§ˆ
   - åŸå§‹è§†é¢‘åç§°
   - ç–‘ä¼¼æŠ„è¢­/æ¬è¿è§†é¢‘åç§°
   - åˆ†ææ—¶é—´

4. ç›¸ä¼¼åº¦åˆ†æ
   4.1 å†…å®¹ç›¸ä¼¼åº¦
       - è¯„åˆ†ï¼ˆscoreï¼‰
       - å®Œæ•´æè¿°ï¼ˆdescriptionï¼‰
       - æ‰€æœ‰è¯æ®é¡¹ï¼ˆevidenceï¼‰ï¼šé€æ¡åˆ—å‡º
   
   4.2 è§†è§‰ç›¸ä¼¼åº¦
       - è¯„åˆ†ï¼ˆscoreï¼‰
       - å®Œæ•´æè¿°ï¼ˆdescriptionï¼‰
       - æ‰€æœ‰è¯æ®é¡¹ï¼ˆevidenceï¼‰ï¼šé€æ¡åˆ—å‡º
   
   4.3 éŸ³é¢‘ç›¸ä¼¼åº¦
       - è¯„åˆ†ï¼ˆscoreï¼‰
       - å®Œæ•´æè¿°ï¼ˆdescriptionï¼‰
       - æ‰€æœ‰è¯æ®é¡¹ï¼ˆevidenceï¼‰ï¼šé€æ¡åˆ—å‡º
   
   4.4 æ—¶é—´ç»“æ„ç›¸ä¼¼åº¦
       - è¯„åˆ†ï¼ˆscoreï¼‰
       - å®Œæ•´æè¿°ï¼ˆdescriptionï¼‰
       - æ‰€æœ‰è¯æ®é¡¹ï¼ˆevidenceï¼‰ï¼šé€æ¡åˆ—å‡º

5. å·®å¼‚åˆ†æ
   - å†…å®¹å·®å¼‚ï¼ˆcontent_differencesï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - è§†è§‰å·®å¼‚ï¼ˆvisual_differencesï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - éŸ³é¢‘å·®å¼‚ï¼ˆaudio_differencesï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹

6. ä¿®æ”¹åˆ†æ
   - æ£€æµ‹åˆ°çš„ä¿®æ”¹ï¼ˆdetected_modificationsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - è£å‰ªï¼ˆcroppingï¼‰ï¼šå®Œæ•´æè¿°
   - é•œåƒï¼ˆmirroringï¼‰ï¼šå®Œæ•´æè¿°
   - å˜é€Ÿï¼ˆspeed_changeï¼‰ï¼šå®Œæ•´æè¿°
   - æ°´å°å˜åŒ–ï¼ˆwatermark_changesï¼‰ï¼šå®Œæ•´æè¿°
   - è°ƒè‰²ï¼ˆcolor_gradingï¼‰ï¼šå®Œæ•´æè¿°
   - å…¶ä»–ä¿®æ”¹ï¼ˆother_modificationsï¼‰ï¼šå®Œæ•´æè¿°

7. åˆ›ä½œæ€§è¯„ä¼°
   - æ˜¯å¦æœ‰å®è´¨æ€§åˆ›ä½œï¼ˆhas_substantial_creativityï¼‰
   - åˆ›ä½œæ€§è¯„åˆ†ï¼ˆcreativity_scoreï¼‰
   - è¯¦ç»†æè¿°ï¼ˆdescriptionï¼‰
   - è¯æ®åˆ—è¡¨ï¼ˆevidenceï¼‰ï¼šé€æ¡åˆ—å‡º

8. ä¾µæƒè¯„ä¼°
   - ç»¼åˆç›¸ä¼¼åº¦è¯„åˆ†ï¼ˆoverall_similarity_scoreï¼‰
   - é£é™©ç­‰çº§ï¼ˆrisk_levelï¼‰å’Œé£é™©è¯„åˆ†ï¼ˆrisk_scoreï¼‰
   - æ¨ç†è¿‡ç¨‹ï¼ˆreasoningï¼‰ï¼šå®Œæ•´å¼•ç”¨
   - å…³é”®æŒ‡æ ‡ï¼ˆkey_indicatorsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - å‡è½»å› ç´ ï¼ˆmitigating_factorsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - åŠ é‡å› ç´ ï¼ˆaggravating_factorsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹

9. ç»“è®ºå’Œå»ºè®®
   - æ˜¯å¦æ¶‰å«ŒæŠ„è¢­ï¼ˆis_plagiarismï¼‰
   - ç½®ä¿¡åº¦ï¼ˆconfidence_levelï¼‰
   - ç»¼åˆæ€»ç»“ï¼ˆsummaryï¼‰
   - æ ¸å¿ƒå‘ç°ï¼ˆkey_findingsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹
   - å»ºè®®ï¼ˆrecommendationsï¼‰ï¼šåˆ—å‡ºæ‰€æœ‰é¡¹

è¯·å¼€å§‹æ’°å†™æŠ¥å‘Šã€‚è®°ä½ï¼šå¿…é¡»ä¿ç•™æ‰€æœ‰æ•°æ®ç»†èŠ‚ï¼Œä¸å¾—æ¦‚æ‹¬æˆ–çœç•¥ã€‚"""


def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    # å°è¯•ä½¿ç”¨ç³»ç»Ÿä¸­æ–‡å­—ä½“
    font_paths = [
        "/System/Library/Fonts/PingFang.ttc",  # macOS
        "/System/Library/Fonts/STHeiti Light.ttc",  # macOS
        "/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf",  # Linux
        "C:\\Windows\\Fonts\\simhei.ttf",  # Windows
        "C:\\Windows\\Fonts\\simsun.ttc",  # Windows
    ]
    
    for font_path in font_paths:
        if Path(font_path).exists():
            try:
                pdfmetrics.registerFont(TTFont('Chinese', font_path))
                log.info(f"ä½¿ç”¨ä¸­æ–‡å­—ä½“: {font_path}")
                return 'Chinese'
            except Exception as e:
                log.error(f"æ³¨å†Œå­—ä½“å¤±è´¥ {font_path}: {e}")
                continue
    
    log.error("æœªæ‰¾åˆ°å¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆå¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡ï¼‰")
    return 'Helvetica'


def create_pdf_report(
    report_text: str,
    analysis: Dict[str, Any],
    output_path: Path,
):
    """åˆ›å»º PDF æŠ¥å‘Š
    
    Args:
        report_text: æŠ¥å‘Šæ–‡æœ¬
        analysis: åˆ†æç»“æœ
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    log.info("å¼€å§‹ç”Ÿæˆ PDF æŠ¥å‘Š...")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    chinese_font = setup_chinese_font()
    
    # åˆ›å»º PDF æ–‡æ¡£
    doc = SimpleDocTemplate(
        str(output_path),
        pagesize=A4,
        rightMargin=2*cm,
        leftMargin=2*cm,
        topMargin=2*cm,
        bottomMargin=2*cm,
    )
    
    # åˆ›å»ºæ ·å¼
    styles = getSampleStyleSheet()
    
    # æ ‡é¢˜æ ·å¼
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Title'],
        fontName=chinese_font,
        fontSize=24,
        textColor=colors.HexColor('#1a1a1a'),
        spaceAfter=30,
        alignment=TA_CENTER,
    )
    
    # æ ‡é¢˜2æ ·å¼
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading1'],
        fontName=chinese_font,
        fontSize=16,
        textColor=colors.HexColor('#2c3e50'),
        spaceAfter=12,
        spaceBefore=20,
    )
    
    # æ­£æ–‡æ ·å¼
    body_style = ParagraphStyle(
        'CustomBody',
        parent=styles['BodyText'],
        fontName=chinese_font,
        fontSize=11,
        leading=18,
        alignment=TA_JUSTIFY,
        spaceAfter=12,
    )
    
    # æ„å»ºæ–‡æ¡£å†…å®¹
    story = []
    
    # æ ‡é¢˜
    story.append(Paragraph("è§†é¢‘æŠ„è¢­ä¸æ¬è¿åˆ†ææŠ¥å‘Š", title_style))
    story.append(Spacer(1, 0.5*cm))
    
    # æ—¥æœŸ
    date_text = f"æŠ¥å‘Šæ—¥æœŸï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}"
    story.append(Paragraph(date_text, body_style))
    story.append(Spacer(1, 1*cm))
    
    # æ·»åŠ è§†é¢‘ä¿¡æ¯è¡¨æ ¼
    video_info = analysis.get("video_info", {})
    original_video = video_info.get("original_video", "N/A")
    suspected_video = video_info.get("suspected_video", "N/A")
    analysis_date = video_info.get("analysis_date", "N/A")
    
    story.append(Paragraph("è§†é¢‘ä¿¡æ¯", heading_style))
    story.append(Spacer(1, 0.3*cm))
    
    video_data = [
        ["é¡¹ç›®", "å†…å®¹"],
        ["åŸå§‹è§†é¢‘", original_video],
        ["ç–‘ä¼¼æŠ„è¢­è§†é¢‘", suspected_video],
        ["åˆ†ææ—¶é—´", analysis_date],
    ]
    
    video_table = Table(video_data, colWidths=[4*cm, 13*cm])
    video_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#3498db')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), chinese_font),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('FONTNAME', (0, 1), (-1, -1), chinese_font),
        ('FONTSIZE', (0, 1), (-1, -1), 10),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
    ]))
    
    story.append(video_table)
    story.append(Spacer(1, 1*cm))
    
    # æ·»åŠ å…³é”®æŒ‡æ ‡è¡¨æ ¼
    infringement = analysis.get("infringement_assessment", {})
    
    story.append(Paragraph("å…³é”®æŒ‡æ ‡", heading_style))
    story.append(Spacer(1, 0.3*cm))
    
    metrics_data = [
        ["æŒ‡æ ‡", "æ•°å€¼"],
        ["å†…å®¹ç›¸ä¼¼åº¦", f"{analysis.get('content_similarity', {}).get('score', 0)}/100"],
        ["è§†è§‰ç›¸ä¼¼åº¦", f"{analysis.get('visual_similarity', {}).get('score', 0)}/100"],
        ["éŸ³é¢‘ç›¸ä¼¼åº¦", f"{analysis.get('audio_similarity', {}).get('score', 0)}/100"],
        ["æ—¶é—´ç»“æ„ç›¸ä¼¼åº¦", f"{analysis.get('temporal_similarity', {}).get('score', 0)}/100"],
        ["ç»¼åˆç›¸ä¼¼åº¦", f"{infringement.get('overall_similarity_score', 0)}/100"],
        ["é£é™©ç­‰çº§", infringement.get('risk_level', 'N/A')],
        ["é£é™©è¯„åˆ†", f"{infringement.get('risk_score', 0)}/100"],
    ]
    
    metrics_table = Table(metrics_data, colWidths=[6*cm, 11*cm])
    metrics_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#e74c3c')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), chinese_font),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.lightgrey),
        ('FONTNAME', (0, 1), (-1, -1), chinese_font),
        ('FONTSIZE', (0, 1), (-1, -1), 10),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
    ]))
    
    story.append(metrics_table)
    story.append(Spacer(1, 1*cm))
    
    # æ·»åŠ åˆ†é¡µï¼Œåˆ†éš”è¡¨æ ¼å’ŒæŠ¥å‘Šæ–‡æœ¬
    story.append(PageBreak())
    
    # === æŠ¥å‘Šæ­£æ–‡ ===
    story.append(Paragraph("è¯¦ç»†åˆ†ææŠ¥å‘Š", heading_style))
    story.append(Spacer(1, 0.5*cm))
    
    # åˆ†å‰²æŠ¥å‘Šæ–‡æœ¬å¹¶æ·»åŠ åˆ°æ–‡æ¡£
    paragraphs = report_text.split('\n\n')
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # è·³è¿‡æŠ¥å‘Šæ–‡æœ¬ä¸­çš„æ ‡é¢˜ï¼ˆå·²ç»åœ¨ä¸Šé¢æ·»åŠ äº†ï¼‰
        if para.startswith('##') or 'è§†é¢‘æŠ„è¢­' in para or 'åˆ†ææŠ¥å‘Š' in para:
            continue
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯æ ‡é¢˜ï¼ˆç®€å•è§„åˆ™ï¼šä»¥"ã€"å¼€å¤´æˆ–åŒ…å«ç‰¹å®šå…³é”®è¯ï¼‰
        is_heading = (
            para.startswith('ã€') or 
            (para.startswith('**') and para.endswith('**')) or
            any(keyword in para for keyword in ['æ‰§è¡Œæ‘˜è¦', 'ç›¸ä¼¼åº¦åˆ†æ', 'å·®å¼‚åˆ†æ', 
                                                 'ä¿®æ”¹åˆ†æ', 'åˆ›ä½œæ€§è¯„ä¼°', 'ä¾µæƒè¯„ä¼°', 
                                                 'ç»“è®º', 'å»ºè®®'])
        )
        
        if is_heading:
            # ç§»é™¤ Markdown æ ‡è®°
            clean_para = para.replace('**', '').replace('*', '').replace('ã€', '').replace('ã€‘', '')
            story.append(Paragraph(clean_para, heading_style))
        else:
            # ç§»é™¤ Markdown æ ‡è®°
            clean_para = para.replace('**', '').replace('*', '')
            # å¤„ç†è¿‡é•¿çš„æ®µè½
            if len(clean_para) > 1000:
                # æŒ‰å¥å­åˆ†å‰²
                sentences = clean_para.replace('ã€‚', 'ã€‚\n').split('\n')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if sentence:
                        story.append(Paragraph(sentence, body_style))
            else:
                story.append(Paragraph(clean_para, body_style))
    
    # ç”Ÿæˆ PDF
    doc.build(story)
    log.info(f"âœ“ PDF æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    # ç›®å½•è·¯å¾„
    script_dir = Path(__file__).resolve().parent
    output_dir = script_dir / "output"
    
    # è¾“å…¥æ–‡ä»¶
    analysis_json = output_dir / "video_comparison_analysis.json"
    
    # è¾“å‡ºæ–‡ä»¶
    report_text_file = output_dir / "video_analysis_report.txt"
    report_pdf_file = output_dir / "video_analysis_report.pdf"
    
    print("\n" + "=" * 80)
    print("è§†é¢‘æŠ„è¢­åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ - åŸºäº Gemini 2.0 Flash Thinking")
    print("=" * 80 + "\n")
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    if not analysis_json.exists():
        raise FileNotFoundError(f"åˆ†æç»“æœä¸å­˜åœ¨: {analysis_json}")
    
    print(f"âœ“ åŠ è½½åˆ†æç»“æœ: {analysis_json.name}\n")
    
    # åŠ è½½åˆ†æç»“æœ
    with open(analysis_json, encoding="utf-8") as f:
        analysis = json.load(f)
    
    # åŠ è½½ API Key
    api_key = load_api_key_from_env()
    print(f"âœ“ API Key: {api_key[:20]}...\n")
    
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = VideoReportGenerator(api_key=api_key)
    
    try:
        # æ­¥éª¤ 1: ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
        print("æ­¥éª¤ 1: ä½¿ç”¨ Gemini ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬")
        print("-" * 80)
        report_text = generator.generate_report_text(analysis=analysis)
        print()
        
        # ä¿å­˜æŠ¥å‘Šæ–‡æœ¬
        with open(report_text_file, "w", encoding="utf-8") as f:
            f.write(report_text)
        print(f"âœ“ æŠ¥å‘Šæ–‡æœ¬å·²ä¿å­˜: {report_text_file}\n")
        
        # æ­¥éª¤ 2: ç”Ÿæˆ PDF æŠ¥å‘Š
        print("æ­¥éª¤ 2: ç”Ÿæˆ PDF æŠ¥å‘Š")
        print("-" * 80)
        create_pdf_report(
            report_text=report_text,
            analysis=analysis,
            output_path=report_pdf_file,
        )
        print()
        
        # æ‰“å°æŠ¥å‘Šé¢„è§ˆ
        print("=" * 80)
        print("æŠ¥å‘Šé¢„è§ˆï¼ˆå‰500å­—ï¼‰")
        print("=" * 80 + "\n")
        print(report_text[:500] + "...\n")
        
        print("=" * 80)
        print("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
        print("=" * 80 + "\n")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡æœ¬: {report_text_file}")
        print(f"ğŸ“‹ PDF æŠ¥å‘Š: {report_pdf_file}\n")
        
    except Exception as e:
        log.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()
