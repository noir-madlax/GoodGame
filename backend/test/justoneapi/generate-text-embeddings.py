"""
å•†å“æ–‡æœ¬å‘é‡åŒ–è„šæœ¬
ä½¿ç”¨ OpenAI text-embedding-3-small æ¨¡å‹ç”Ÿæˆå•†å“åç§°çš„å‘é‡

ä½¿ç”¨é¡µé¢: ç‹¬ç«‹æµ‹è¯•è„šæœ¬
åŠŸèƒ½:
  1. è·å–æ‰€æœ‰å•†å“åç§°
  2. è°ƒç”¨ OpenAI Embedding API ç”Ÿæˆå‘é‡
  3. å­˜å‚¨åˆ° gg_taobao_product_embeddings è¡¨

æ³¨æ„:
  - éœ€è¦é…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡
  - å¦‚æœæ²¡æœ‰ OPENAI_API_KEYï¼Œå¯ä»¥ä½¿ç”¨ OPENROUTER_API_KEY (é€šè¿‡ OpenRouter è°ƒç”¨ OpenAI)
  - text-embedding-3-small ç”Ÿæˆ 1536 ç»´å‘é‡
  - ä»·æ ¼: $0.02 / 1M tokens
"""

import os
import time
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client, Client
from openai import OpenAI

# ==================== é…ç½®åŒºåŸŸ ====================
# Embedding æ¨¡å‹
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSIONS = 1536

# æ‰¹å¤„ç†å¤§å° (OpenAI æ”¯æŒæ‰¹é‡è¯·æ±‚)
BATCH_SIZE = 50

# è¯·æ±‚é—´éš” (ç§’)
REQUEST_DELAY = 0.5


def load_clients() -> tuple:
    """åŠ è½½ Supabase å’Œ OpenAI å®¢æˆ·ç«¯"""
    env_path = Path(__file__).parent.parent.parent / ".env"
    load_dotenv(env_path)
    
    # Supabase
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")
    
    if not supabase_url or not supabase_key:
        raise ValueError("æœªæ‰¾åˆ° SUPABASE_URL æˆ– SUPABASE_KEY")
    
    supabase = create_client(supabase_url, supabase_key)
    print(f"âœ… æˆåŠŸè¿æ¥ Supabase")
    
    # OpenAI - ä¼˜å…ˆä½¿ç”¨ OPENAI_API_KEYï¼Œå¦åˆ™ä½¿ç”¨ OPENROUTER_API_KEY
    openai_key = os.getenv("OPENAI_API_KEY")
    openrouter_key = os.getenv("OPENROUTER_API_KEY")
    
    if openai_key:
        # ç›´æ¥ä½¿ç”¨ OpenAI
        openai_client = OpenAI(api_key=openai_key)
        print(f"âœ… ä½¿ç”¨ OpenAI API")
    elif openrouter_key:
        # é€šè¿‡ OpenRouter è°ƒç”¨ OpenAI
        openai_client = OpenAI(
            api_key=openrouter_key,
            base_url="https://openrouter.ai/api/v1"
        )
        print(f"âœ… ä½¿ç”¨ OpenRouter API (è°ƒç”¨ OpenAI)")
    else:
        raise ValueError("æœªæ‰¾åˆ° OPENAI_API_KEY æˆ– OPENROUTER_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
    
    return supabase, openai_client


def get_products_without_embeddings(supabase: Client) -> list:
    """è·å–è¿˜æ²¡æœ‰ç”Ÿæˆå‘é‡çš„å•†å“"""
    # è·å–æ‰€æœ‰å•†å“
    products_result = supabase.table("gg_taobao_products").select(
        "id, item_id, item_name"
    ).execute()
    
    # è·å–å·²æœ‰å‘é‡çš„å•†å“ ID
    embeddings_result = supabase.table("gg_taobao_product_embeddings").select(
        "product_id"
    ).eq("embedding_type", "text").execute()
    
    existing_ids = {row["product_id"] for row in embeddings_result.data}
    
    # è¿‡æ»¤å‡ºæœªç”Ÿæˆå‘é‡çš„å•†å“
    products = [
        p for p in products_result.data 
        if p["id"] not in existing_ids and p["item_name"]
    ]
    
    return products


def generate_embeddings_batch(openai_client: OpenAI, texts: list) -> list:
    """
    æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡
    
    å‚æ•°:
        openai_client: OpenAI å®¢æˆ·ç«¯
        texts: æ–‡æœ¬åˆ—è¡¨
    
    è¿”å›:
        list: å‘é‡åˆ—è¡¨ (ä¸è¾“å…¥é¡ºåºå¯¹åº”)
    """
    response = openai_client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=texts
    )
    
    # æŒ‰ index æ’åºç¡®ä¿é¡ºåºæ­£ç¡®
    embeddings = [None] * len(texts)
    for item in response.data:
        embeddings[item.index] = item.embedding
    
    return embeddings


def save_embeddings(supabase: Client, embeddings_data: list) -> None:
    """ä¿å­˜å‘é‡åˆ°æ•°æ®åº“"""
    if not embeddings_data:
        return
    
    # æ‰¹é‡æ’å…¥
    supabase.table("gg_taobao_product_embeddings").upsert(
        embeddings_data,
        on_conflict="product_id,embedding_type"
    ).execute()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ”¢ å•†å“æ–‡æœ¬å‘é‡åŒ– (OpenAI text-embedding-3-small)")
    print("=" * 70)
    
    # 1. åŠ è½½å®¢æˆ·ç«¯
    supabase, openai_client = load_clients()
    
    # 2. è·å–å¾…å¤„ç†å•†å“
    print(f"\nğŸ“‹ æ­£åœ¨è·å–å¾…å¤„ç†å•†å“...")
    products = get_products_without_embeddings(supabase)
    print(f"   å…± {len(products)} ä¸ªå•†å“å¾…å¤„ç†")
    
    if not products:
        print("\nâœ… æ‰€æœ‰å•†å“å·²å®Œæˆå‘é‡åŒ–ï¼")
        return
    
    # 3. åˆ†æ‰¹å¤„ç†
    print(f"\nğŸš€ å¼€å§‹ç”Ÿæˆå‘é‡ (æ‰¹å¤§å°: {BATCH_SIZE})...")
    
    total_processed = 0
    total_tokens = 0
    
    for i in range(0, len(products), BATCH_SIZE):
        batch = products[i:i + BATCH_SIZE]
        
        # æå–æ–‡æœ¬
        texts = [p["item_name"] for p in batch]
        
        try:
            # ç”Ÿæˆå‘é‡
            embeddings = generate_embeddings_batch(openai_client, texts)
            
            # æ„å»ºæ•°æ®
            embeddings_data = []
            for j, product in enumerate(batch):
                if embeddings[j]:
                    embeddings_data.append({
                        "product_id": product["id"],
                        "item_id": product["item_id"],
                        "embedding_type": "text",
                        "embedding_model": EMBEDDING_MODEL,
                        "embedding": embeddings[j],
                        "source_text": product["item_name"]
                    })
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            save_embeddings(supabase, embeddings_data)
            
            total_processed += len(batch)
            print(f"   âœ… å·²å¤„ç† {total_processed}/{len(products)} ä¸ªå•†å“")
            
            # è¯·æ±‚é—´éš”
            time.sleep(REQUEST_DELAY)
            
        except Exception as e:
            print(f"   âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            time.sleep(2)  # å‡ºé”™åç­‰å¾…æ›´é•¿æ—¶é—´
    
    # 4. ç»Ÿè®¡
    print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
    print(f"   å¤„ç†å•†å“æ•°: {total_processed}")
    
    # éªŒè¯
    result = supabase.table("gg_taobao_product_embeddings").select(
        "id", count="exact"
    ).eq("embedding_type", "text").execute()
    
    print(f"   æ•°æ®åº“å‘é‡æ•°: {result.count}")
    
    print("\n" + "=" * 70)
    print("âœ… å‘é‡åŒ–å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()

