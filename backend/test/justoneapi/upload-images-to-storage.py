"""
ä¸Šä¼ å•†å“å›¾ç‰‡åˆ° Supabase Storage
å¹¶æ›´æ–° gg_taobao_product_images è¡¨çš„ storage_path å­—æ®µ

ä½¿ç”¨é¡µé¢: ç‹¬ç«‹æµ‹è¯•è„šæœ¬
åŠŸèƒ½:
  1. è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶
  2. ä¸Šä¼ åˆ° Supabase Storage (bucket: product-images)
  3. æ›´æ–°æ•°æ®åº“ä¸­çš„ storage_path å­—æ®µ
"""

import os
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client, Client
from concurrent.futures import ThreadPoolExecutor, as_completed
import mimetypes

# ==================== é…ç½®åŒºåŸŸ ====================
# æºæ•°æ®ç›®å½•
SOURCE_DIR = Path(__file__).parent / "output" / "search-item-list" / "20251202_144931"
IMAGES_DIR = SOURCE_DIR / "images"

# Storage bucket åç§°
BUCKET_NAME = "product-images"

# å¹¶å‘ä¸Šä¼ çº¿ç¨‹æ•°
MAX_WORKERS = 5


def load_supabase_client() -> Client:
    """åŠ è½½ Supabase å®¢æˆ·ç«¯"""
    env_path = Path(__file__).parent.parent.parent / ".env"
    load_dotenv(env_path)
    
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")
    
    if not url or not key:
        raise ValueError(f"æœªæ‰¾åˆ° SUPABASE_URL æˆ– SUPABASE_KEY")
    
    print(f"âœ… æˆåŠŸè¿æ¥ Supabase")
    return create_client(url, key)


def ensure_bucket_exists(supabase: Client) -> None:
    """ç¡®ä¿ Storage bucket å­˜åœ¨"""
    try:
        # å°è¯•è·å– bucket ä¿¡æ¯
        buckets = supabase.storage.list_buckets()
        bucket_names = [b.name for b in buckets]
        
        if BUCKET_NAME not in bucket_names:
            # åˆ›å»º bucket (å…¬å¼€è®¿é—®)
            supabase.storage.create_bucket(
                BUCKET_NAME,
                options={"public": True}
            )
            print(f"ğŸ“¦ å·²åˆ›å»º Storage bucket: {BUCKET_NAME}")
        else:
            print(f"ğŸ“¦ Storage bucket å·²å­˜åœ¨: {BUCKET_NAME}")
            
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ bucket æ—¶å‡ºé”™: {e}")


def get_images_to_upload(supabase: Client) -> list:
    """
    è·å–éœ€è¦ä¸Šä¼ çš„å›¾ç‰‡åˆ—è¡¨
    åªè·å– storage_path ä¸ºç©ºæˆ–ä¸ä»¥ 'product-images/' å¼€å¤´çš„è®°å½•
    """
    # æŸ¥è¯¢æ‰€æœ‰å›¾ç‰‡è®°å½•
    result = supabase.table("gg_taobao_product_images").select(
        "id, item_id, image_type, image_index, storage_path"
    ).execute()
    
    images_to_upload = []
    for row in result.data:
        # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        item_id = row["item_id"]
        image_type = row["image_type"]
        image_index = row["image_index"]
        
        if image_type == "main":
            local_path = IMAGES_DIR / str(item_id) / "main.jpg"
        else:
            local_path = IMAGES_DIR / str(item_id) / f"{image_index}.jpg"
        
        # åªä¸Šä¼ æœ¬åœ°å­˜åœ¨ä¸”æœªä¸Šä¼ è¿‡çš„å›¾ç‰‡
        storage_path = row.get("storage_path") or ""
        if local_path.exists() and not storage_path.startswith("product-images/"):
            images_to_upload.append({
                "id": row["id"],
                "item_id": item_id,
                "image_type": image_type,
                "image_index": image_index,
                "local_path": local_path
            })
    
    return images_to_upload


def upload_single_image(supabase: Client, image_info: dict) -> dict:
    """
    ä¸Šä¼ å•å¼ å›¾ç‰‡åˆ° Storage
    
    è¿”å›:
        dict: {"id": ..., "success": bool, "storage_path": str or None}
    """
    item_id = image_info["item_id"]
    image_type = image_info["image_type"]
    image_index = image_info["image_index"]
    local_path = image_info["local_path"]
    
    # æ„å»º Storage è·¯å¾„
    if image_type == "main":
        storage_path = f"{item_id}/main.jpg"
    else:
        storage_path = f"{item_id}/{image_index}.jpg"
    
    try:
        # è¯»å–æ–‡ä»¶
        with open(local_path, "rb") as f:
            file_data = f.read()
        
        # ä¸Šä¼ åˆ° Storage
        result = supabase.storage.from_(BUCKET_NAME).upload(
            path=storage_path,
            file=file_data,
            file_options={"content-type": "image/jpeg", "upsert": "true"}
        )
        
        # è¿”å›å®Œæ•´è·¯å¾„
        full_path = f"{BUCKET_NAME}/{storage_path}"
        return {
            "id": image_info["id"],
            "success": True,
            "storage_path": full_path
        }
        
    except Exception as e:
        error_msg = str(e)
        # å¦‚æœæ˜¯é‡å¤ä¸Šä¼ é”™è¯¯ï¼Œä¹Ÿç®—æˆåŠŸ
        if "Duplicate" in error_msg or "already exists" in error_msg:
            full_path = f"{BUCKET_NAME}/{storage_path}"
            return {
                "id": image_info["id"],
                "success": True,
                "storage_path": full_path
            }
        return {
            "id": image_info["id"],
            "success": False,
            "storage_path": None,
            "error": error_msg
        }


def update_storage_paths(supabase: Client, results: list) -> None:
    """æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­çš„ storage_path"""
    success_results = [r for r in results if r["success"]]
    
    if not success_results:
        print("   æ²¡æœ‰éœ€è¦æ›´æ–°çš„è®°å½•")
        return
    
    # åˆ†æ‰¹æ›´æ–°
    batch_size = 50
    updated_count = 0
    
    for i in range(0, len(success_results), batch_size):
        batch = success_results[i:i + batch_size]
        
        for result in batch:
            try:
                supabase.table("gg_taobao_product_images").update({
                    "storage_path": result["storage_path"]
                }).eq("id", result["id"]).execute()
                updated_count += 1
            except Exception as e:
                print(f"   âš ï¸ æ›´æ–°å¤±è´¥ ID={result['id']}: {e}")
        
        print(f"   ğŸ“ å·²æ›´æ–° {updated_count}/{len(success_results)} æ¡è®°å½•")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ“¤ ä¸Šä¼ å•†å“å›¾ç‰‡åˆ° Supabase Storage")
    print("=" * 70)
    
    # 1. åŠ è½½ Supabase å®¢æˆ·ç«¯
    supabase = load_supabase_client()
    
    # 2. ç¡®ä¿ bucket å­˜åœ¨
    ensure_bucket_exists(supabase)
    
    # 3. è·å–éœ€è¦ä¸Šä¼ çš„å›¾ç‰‡åˆ—è¡¨
    print(f"\nğŸ“‹ æ­£åœ¨è·å–å¾…ä¸Šä¼ å›¾ç‰‡åˆ—è¡¨...")
    images_to_upload = get_images_to_upload(supabase)
    print(f"   å…± {len(images_to_upload)} å¼ å›¾ç‰‡å¾…ä¸Šä¼ ")
    
    if not images_to_upload:
        print("\nâœ… æ‰€æœ‰å›¾ç‰‡å·²ä¸Šä¼ å®Œæˆï¼")
        return
    
    # 4. å¹¶è¡Œä¸Šä¼ å›¾ç‰‡
    print(f"\nğŸš€ å¼€å§‹ä¸Šä¼  (ä½¿ç”¨ {MAX_WORKERS} ä¸ªçº¿ç¨‹)...")
    
    results = []
    success_count = 0
    fail_count = 0
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(upload_single_image, supabase, img): img
            for img in images_to_upload
        }
        
        for i, future in enumerate(as_completed(futures), 1):
            result = future.result()
            results.append(result)
            
            if result["success"]:
                success_count += 1
            else:
                fail_count += 1
                print(f"   âŒ ä¸Šä¼ å¤±è´¥: {result.get('error', 'Unknown error')}")
            
            if i % 50 == 0 or i == len(images_to_upload):
                print(f"   ğŸ“· è¿›åº¦: {i}/{len(images_to_upload)} (æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count})")
    
    # 5. æ›´æ–°æ•°æ®åº“
    print(f"\nğŸ“ æ­£åœ¨æ›´æ–°æ•°æ®åº“...")
    update_storage_paths(supabase, results)
    
    print("\n" + "=" * 70)
    print("âœ… ä¸Šä¼ å®Œæˆï¼")
    print(f"   æˆåŠŸ: {success_count} å¼ ")
    print(f"   å¤±è´¥: {fail_count} å¼ ")
    print("=" * 70)


if __name__ == "__main__":
    main()

