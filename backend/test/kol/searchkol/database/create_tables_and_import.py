#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ›å»ºæ•°æ®åº“è¡¨å¹¶å¯¼å…¥æœç´¢ç”¨æˆ·æ•°æ®

è¡¨è®¾è®¡ï¼š
1. gg_douyin_user_search - æœç´¢ç”¨æˆ·åŸºç¡€ä¿¡æ¯è¡¨
2. gg_xingtu_kol_mapping - UIDåˆ°æ˜Ÿå›¾KOL IDçš„æ˜ å°„è¡¨
3. gg_xingtu_kol_base_info - æ˜Ÿå›¾KOLåŸºç¡€ä¿¡æ¯è¡¨
4. gg_xingtu_kol_audience - æ˜Ÿå›¾KOLå—ä¼—ç”»åƒè¡¨
5. gg_xingtu_kol_price - æ˜Ÿå›¾KOLæœåŠ¡æŠ¥ä»·è¡¨
6. gg_xingtu_kol_content - æ˜Ÿå›¾KOLå†…å®¹å®šä½è¡¨
7. gg_xingtu_kol_conversion - æ˜Ÿå›¾KOLè½¬åŒ–èƒ½åŠ›è¡¨
"""

import os
import json
from pathlib import Path
from datetime import datetime
from supabase import create_client, Client

# Supabaseé…ç½®
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    from dotenv import load_dotenv
    backend_dir = Path(__file__).parent.parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… ä» {env_path} åŠ è½½ç¯å¢ƒå˜é‡")
    
    global SUPABASE_URL, SUPABASE_KEY
    SUPABASE_URL = os.getenv('SUPABASE_URL')
    SUPABASE_KEY = os.getenv('SUPABASE_KEY')
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("æœªæ‰¾åˆ° SUPABASE_URL æˆ– SUPABASE_KEY")


# SQLå»ºè¡¨è¯­å¥
CREATE_TABLES_SQL = """
-- 1. æœç´¢ç”¨æˆ·åŸºç¡€ä¿¡æ¯è¡¨
CREATE TABLE IF NOT EXISTS gg_douyin_user_search (
    uid TEXT PRIMARY KEY,                    -- ç”¨æˆ·UIDï¼ˆæŠ–éŸ³æ•°å­—IDï¼‰
    sec_uid TEXT,                            -- åŠ å¯†ç”¨æˆ·ID
    nickname TEXT,                           -- æ˜µç§°
    unique_id TEXT,                          -- æŠ–éŸ³å·
    gender INTEGER,                          -- æ€§åˆ«ï¼ˆ0=æœªçŸ¥ï¼Œ1=ç”·ï¼Œ2=å¥³ï¼‰
    follower_count BIGINT,                   -- ç²‰ä¸æ•°
    verification_type INTEGER,               -- è®¤è¯ç±»å‹ï¼ˆ0=æ— ï¼Œ1=ä¸ªäººï¼Œ2=ä¼ä¸šï¼‰
    avatar_url TEXT,                         -- å¤´åƒURL
    signature TEXT,                          -- ä¸ªæ€§ç­¾å
    live_status INTEGER,                     -- ç›´æ’­çŠ¶æ€
    
    -- æ‰©å±•å­—æ®µï¼ˆJSONæ ¼å¼ï¼‰
    extra_info JSONB,                        -- å…¶ä»–å­—æ®µï¼ˆdisplay_info, user_tagsç­‰ï¼‰
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„user_infoæ•°æ®
    
    -- æœç´¢æ¥æºä¿¡æ¯
    search_keyword TEXT,                     -- æœç´¢å…³é”®è¯
    search_date TIMESTAMP,                   -- æœç´¢æ—¶é—´
    
    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_user_search_nickname ON gg_douyin_user_search(nickname);
CREATE INDEX IF NOT EXISTS idx_user_search_follower ON gg_douyin_user_search(follower_count DESC);
CREATE INDEX IF NOT EXISTS idx_user_search_keyword ON gg_douyin_user_search(search_keyword);
CREATE INDEX IF NOT EXISTS idx_user_search_date ON gg_douyin_user_search(search_date);

COMMENT ON TABLE gg_douyin_user_search IS 'æŠ–éŸ³æœç´¢ç”¨æˆ·åŸºç¡€ä¿¡æ¯è¡¨';
COMMENT ON COLUMN gg_douyin_user_search.uid IS 'ç”¨æˆ·UIDï¼ˆä¸»é”®ï¼‰';
COMMENT ON COLUMN gg_douyin_user_search.follower_count IS 'ç²‰ä¸æ•°é‡';
COMMENT ON COLUMN gg_douyin_user_search.extra_info IS 'æ‰©å±•ä¿¡æ¯JSON';
COMMENT ON COLUMN gg_douyin_user_search.raw_data IS 'å®Œæ•´åŸå§‹æ•°æ®JSON';


-- 2. UIDåˆ°æ˜Ÿå›¾KOL IDçš„æ˜ å°„è¡¨
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_mapping (
    id SERIAL PRIMARY KEY,
    uid TEXT NOT NULL UNIQUE,                -- æŠ–éŸ³ç”¨æˆ·UID
    kol_id TEXT,                             -- æ˜Ÿå›¾KOL ID
    is_xingtu_kol BOOLEAN DEFAULT FALSE,     -- æ˜¯å¦ä¸ºæ˜Ÿå›¾KOL
    
    -- æŸ¥è¯¢ä¿¡æ¯
    check_date TIMESTAMP,                    -- æŸ¥è¯¢æ—¶é—´
    error_message TEXT,                      -- å¦‚æœä¸æ˜¯KOLï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
    
    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_mapping_uid ON gg_xingtu_kol_mapping(uid);
CREATE INDEX IF NOT EXISTS idx_kol_mapping_kol_id ON gg_xingtu_kol_mapping(kol_id);
CREATE INDEX IF NOT EXISTS idx_kol_mapping_is_xingtu ON gg_xingtu_kol_mapping(is_xingtu_kol);

COMMENT ON TABLE gg_xingtu_kol_mapping IS 'UIDåˆ°æ˜Ÿå›¾KOL IDçš„æ˜ å°„è¡¨';
COMMENT ON COLUMN gg_xingtu_kol_mapping.is_xingtu_kol IS 'æ˜¯å¦ä¸ºæ˜Ÿå›¾KOL';


-- 3. æ˜Ÿå›¾KOLåŸºç¡€ä¿¡æ¯è¡¨ï¼ˆå¯¹åº”æ¥å£1.2ï¼‰
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_base_info (
    kol_id TEXT PRIMARY KEY,                 -- æ˜Ÿå›¾KOL ID
    kol_name TEXT,                           -- KOLåç§°
    kol_avatar TEXT,                         -- å¤´åƒURL
    fans_count BIGINT,                       -- ç²‰ä¸æ•°
    aweme_count INTEGER,                     -- ä½œå“æ•°
    vertical_category TEXT,                  -- å‚ç›´é¢†åŸŸ
    tags TEXT[],                             -- æ ‡ç­¾æ•°ç»„
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„æ¥å£è¿”å›æ•°æ®
    
    -- å…ƒæ•°æ®
    fetch_date TIMESTAMP,                    -- è·å–æ—¶é—´
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_base_fans ON gg_xingtu_kol_base_info(fans_count DESC);
CREATE INDEX IF NOT EXISTS idx_kol_base_category ON gg_xingtu_kol_base_info(vertical_category);

COMMENT ON TABLE gg_xingtu_kol_base_info IS 'æ˜Ÿå›¾KOLåŸºç¡€ä¿¡æ¯è¡¨';


-- 4. æ˜Ÿå›¾KOLå—ä¼—ç”»åƒè¡¨ï¼ˆå¯¹åº”æ¥å£1.3ï¼‰
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_audience (
    id SERIAL PRIMARY KEY,
    kol_id TEXT NOT NULL UNIQUE,            -- æ˜Ÿå›¾KOL ID
    
    -- æ€§åˆ«åˆ†å¸ƒ
    gender_distribution JSONB,               -- æ€§åˆ«åˆ†å¸ƒæ•°æ®
    
    -- å¹´é¾„åˆ†å¸ƒ
    age_distribution JSONB,                  -- å¹´é¾„åˆ†å¸ƒæ•°æ®
    
    -- åœ°åŸŸåˆ†å¸ƒ
    region_distribution JSONB,               -- åœ°åŸŸåˆ†å¸ƒæ•°æ®
    
    -- å…´è¶£æ ‡ç­¾
    interest_tags JSONB,                     -- å…´è¶£æ ‡ç­¾æ•°æ®
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„æ¥å£è¿”å›æ•°æ®
    
    -- å…ƒæ•°æ®
    fetch_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_audience_kol_id ON gg_xingtu_kol_audience(kol_id);

COMMENT ON TABLE gg_xingtu_kol_audience IS 'æ˜Ÿå›¾KOLå—ä¼—ç”»åƒè¡¨';


-- 5. æ˜Ÿå›¾KOLæœåŠ¡æŠ¥ä»·è¡¨ï¼ˆå¯¹åº”æ¥å£1.4ï¼‰
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_price (
    id SERIAL PRIMARY KEY,
    kol_id TEXT NOT NULL UNIQUE,            -- æ˜Ÿå›¾KOL ID
    
    -- è§†é¢‘æŠ¥ä»·
    video_price_min DECIMAL(10,2),           -- è§†é¢‘æŠ¥ä»·æœ€ä½ä»·
    video_price_max DECIMAL(10,2),           -- è§†é¢‘æŠ¥ä»·æœ€é«˜ä»·
    
    -- ç›´æ’­æŠ¥ä»·
    live_price_min DECIMAL(10,2),            -- ç›´æ’­æŠ¥ä»·æœ€ä½ä»·
    live_price_max DECIMAL(10,2),            -- ç›´æ’­æŠ¥ä»·æœ€é«˜ä»·
    
    -- å›¾æ–‡æŠ¥ä»·
    image_price_min DECIMAL(10,2),           -- å›¾æ–‡æŠ¥ä»·æœ€ä½ä»·
    image_price_max DECIMAL(10,2),           -- å›¾æ–‡æŠ¥ä»·æœ€é«˜ä»·
    
    -- å†å²è®¢å•
    order_count INTEGER,                     -- å†å²è®¢å•æ•°
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„æ¥å£è¿”å›æ•°æ®
    
    -- å…ƒæ•°æ®
    fetch_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_price_kol_id ON gg_xingtu_kol_price(kol_id);
CREATE INDEX IF NOT EXISTS idx_kol_price_video ON gg_xingtu_kol_price(video_price_min, video_price_max);

COMMENT ON TABLE gg_xingtu_kol_price IS 'æ˜Ÿå›¾KOLæœåŠ¡æŠ¥ä»·è¡¨';


-- 6. æ˜Ÿå›¾KOLå†…å®¹å®šä½è¡¨ï¼ˆå¯¹åº”æ¥å£1.5ï¼‰
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_content (
    id SERIAL PRIMARY KEY,
    kol_id TEXT NOT NULL UNIQUE,            -- æ˜Ÿå›¾KOL ID
    
    -- å‚ç›´é¢†åŸŸ
    vertical_field TEXT,                     -- å‚ç›´é¢†åŸŸ
    
    -- å†…å®¹é£æ ¼
    content_style TEXT[],                    -- å†…å®¹é£æ ¼æ ‡ç­¾
    
    -- åˆä½œæ¡ˆä¾‹
    cooperation_cases JSONB,                 -- åˆä½œæ¡ˆä¾‹æ•°æ®
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„æ¥å£è¿”å›æ•°æ®
    
    -- å…ƒæ•°æ®
    fetch_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_content_kol_id ON gg_xingtu_kol_content(kol_id);
CREATE INDEX IF NOT EXISTS idx_kol_content_field ON gg_xingtu_kol_content(vertical_field);

COMMENT ON TABLE gg_xingtu_kol_content IS 'æ˜Ÿå›¾KOLå†…å®¹å®šä½è¡¨';


-- 7. æ˜Ÿå›¾KOLè½¬åŒ–èƒ½åŠ›è¡¨ï¼ˆå¯¹åº”æ¥å£1.6ï¼‰
CREATE TABLE IF NOT EXISTS gg_xingtu_kol_conversion (
    id SERIAL PRIMARY KEY,
    kol_id TEXT NOT NULL UNIQUE,            -- æ˜Ÿå›¾KOL ID
    
    -- è½¬åŒ–èƒ½åŠ›
    conversion_rate DECIMAL(5,2),            -- è½¬åŒ–ç‡
    
    -- äº’åŠ¨æ•°æ®
    interaction_data JSONB,                  -- äº’åŠ¨æ•°æ®
    
    -- GMVèƒ½åŠ›
    gmv_ability JSONB,                       -- GMVèƒ½åŠ›æ•°æ®
    
    -- å®Œæ•´åŸå§‹æ•°æ®
    raw_data JSONB,                          -- å®Œæ•´çš„æ¥å£è¿”å›æ•°æ®
    
    -- å…ƒæ•°æ®
    fetch_date TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX IF NOT EXISTS idx_kol_conversion_kol_id ON gg_xingtu_kol_conversion(kol_id);
CREATE INDEX IF NOT EXISTS idx_kol_conversion_rate ON gg_xingtu_kol_conversion(conversion_rate DESC);

COMMENT ON TABLE gg_xingtu_kol_conversion IS 'æ˜Ÿå›¾KOLè½¬åŒ–èƒ½åŠ›è¡¨';
"""


def load_all_users_from_searches():
    """åŠ è½½æ‰€æœ‰æœç´¢ç»“æœä¸­çš„ç”¨æˆ·æ•°æ®"""
    script_dir = Path(__file__).parent.parent
    
    # æ”¶é›†æ‰€æœ‰ç”¨æˆ·æ•°æ®
    all_users = {}
    
    # 1. åŠ è½½"æŠ¤è‚¤"æœç´¢ç»“æœ
    output_dir1 = script_dir / "output"
    if output_dir1.exists():
        print(f"\nğŸ“‚ å¤„ç†ç›®å½•: {output_dir1}")
        users = load_users_from_directory(output_dir1, "æŠ¤è‚¤")
        print(f"   æ‰¾åˆ° {len(users)} ä¸ªç”¨æˆ·")
        for uid, user in users.items():
            if uid not in all_users:
                all_users[uid] = user
    
    # 2. åŠ è½½"æŠ¤è‚¤ è¾¾äºº åšä¸»"æœç´¢ç»“æœ
    output_dirs = list(script_dir.glob("output_kol_full_*"))
    for output_dir in output_dirs:
        print(f"\nğŸ“‚ å¤„ç†ç›®å½•: {output_dir}")
        users = load_users_from_directory(output_dir, "æŠ¤è‚¤ è¾¾äºº åšä¸»")
        print(f"   æ‰¾åˆ° {len(users)} ä¸ªç”¨æˆ·")
        for uid, user in users.items():
            if uid not in all_users:
                all_users[uid] = user
    
    print(f"\nâœ… æ€»å…±æ‰¾åˆ° {len(all_users)} ä¸ªå”¯ä¸€ç”¨æˆ·")
    return list(all_users.values())


def load_users_from_directory(output_dir: Path, keyword: str):
    """ä»æŒ‡å®šç›®å½•åŠ è½½ç”¨æˆ·æ•°æ®"""
    detail_dir = output_dir / "detail"
    
    users = {}
    
    if not detail_dir.exists():
        return users
    
    # éå†æ‰€æœ‰pageæ–‡ä»¶
    page_files = sorted(detail_dir.glob("page_*_request_response.json"))
    
    for page_file in page_files:
        with open(page_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        response = data.get('response', {})
        response_data = response.get('data', {})
        inner_data = response_data.get('data', [])
        
        if not isinstance(inner_data, list):
            continue
        
        for item in inner_data:
            user_info = item.get('user_info', {})
            uid = user_info.get('uid')
            
            if not uid:
                continue
            
            # å‡†å¤‡æ ¸å¿ƒå­—æ®µ
            user_record = {
                'uid': str(uid),
                'sec_uid': user_info.get('sec_uid'),
                'nickname': user_info.get('nickname'),
                'unique_id': user_info.get('unique_id'),
                'gender': user_info.get('gender'),
                'follower_count': user_info.get('follower_count'),
                'verification_type': user_info.get('verification_type'),
                'avatar_url': user_info.get('avatar_thumb', {}).get('url_list', [None])[0],
                'signature': user_info.get('signature'),
                'live_status': user_info.get('live_status'),
                
                # æ‰©å±•ä¿¡æ¯
                'extra_info': {
                    'display_info': user_info.get('display_info'),
                    'user_tags': user_info.get('user_tags'),
                    'versatile_display': user_info.get('versatile_display'),
                    'weibo_verify': user_info.get('weibo_verify'),
                    'custom_verify': user_info.get('custom_verify'),
                    'enterprise_verify_reason': user_info.get('enterprise_verify_reason'),
                },
                
                # å®Œæ•´åŸå§‹æ•°æ®
                'raw_data': user_info,
                
                # æœç´¢ä¿¡æ¯
                'search_keyword': keyword,
                'search_date': datetime.now().isoformat()
            }
            
            users[uid] = user_record
    
    return users


def import_users_to_supabase(users: list):
    """å¯¼å…¥ç”¨æˆ·æ•°æ®åˆ°Supabase"""
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    print(f"\nğŸ“¤ å¼€å§‹å¯¼å…¥ {len(users)} ä¸ªç”¨æˆ·åˆ°æ•°æ®åº“...")
    
    # åˆ†æ‰¹å¯¼å…¥ï¼ˆæ¯æ‰¹100æ¡ï¼‰
    batch_size = 100
    total_imported = 0
    total_updated = 0
    total_errors = 0
    
    for i in range(0, len(users), batch_size):
        batch = users[i:i+batch_size]
        
        try:
            # ä½¿ç”¨upsertï¼ˆæ’å…¥æˆ–æ›´æ–°ï¼‰
            response = supabase.table('gg_douyin_user_search').upsert(
                batch,
                on_conflict='uid'
            ).execute()
            
            batch_count = len(batch)
            total_imported += batch_count
            
            print(f"   âœ… æ‰¹æ¬¡ {i//batch_size + 1}: å¯¼å…¥ {batch_count} æ¡æ•°æ®")
            
        except Exception as e:
            total_errors += len(batch)
            print(f"   âŒ æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: {e}")
    
    print(f"\nâœ… å¯¼å…¥å®Œæˆï¼")
    print(f"   æˆåŠŸ: {total_imported} æ¡")
    print(f"   å¤±è´¥: {total_errors} æ¡")
    
    return total_imported, total_errors


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("åˆ›å»ºæ•°æ®åº“è¡¨å¹¶å¯¼å…¥æœç´¢ç”¨æˆ·æ•°æ®")
    print("=" * 60)
    
    # 1. åŠ è½½ç¯å¢ƒå˜é‡
    print("\n1ï¸âƒ£ åŠ è½½ç¯å¢ƒå˜é‡...")
    load_env()
    print(f"âœ… Supabase URL: {SUPABASE_URL[:30]}...")
    
    # 2. åˆ›å»ºè¡¨ç»“æ„ï¼ˆé€šè¿‡MCPå®Œæˆï¼‰
    print("\n2ï¸âƒ£ æ•°æ®åº“è¡¨ç»“æ„å·²è®¾è®¡")
    print("   è¯·ä½¿ç”¨MCPå·¥å…·æ‰§è¡Œå»ºè¡¨SQL")
    print("   å»ºè¡¨SQLå·²ä¿å­˜åˆ°æœ¬æ–‡ä»¶çš„ CREATE_TABLES_SQL å˜é‡ä¸­")
    
    # 3. åŠ è½½ç”¨æˆ·æ•°æ®
    print("\n3ï¸âƒ£ åŠ è½½ç”¨æˆ·æ•°æ®...")
    users = load_all_users_from_searches()
    
    if not users:
        print("âŒ æœªæ‰¾åˆ°ç”¨æˆ·æ•°æ®")
        return
    
    # 4. å¯¼å…¥æ•°æ®åˆ°Supabase
    print("\n4ï¸âƒ£ å¯¼å…¥æ•°æ®åˆ°Supabase...")
    imported, errors = import_users_to_supabase(users)
    
    # 5. éªŒè¯æ•°æ®
    print("\n5ï¸âƒ£ éªŒè¯å¯¼å…¥ç»“æœ...")
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    try:
        # æŸ¥è¯¢æ€»æ•°
        response = supabase.table('gg_douyin_user_search').select('uid', count='exact').execute()
        count = response.count
        print(f"âœ… æ•°æ®åº“ä¸­å…±æœ‰ {count} æ¡ç”¨æˆ·è®°å½•")
        
        # æŸ¥è¯¢ç²‰ä¸æ•°TOP 5
        response = supabase.table('gg_douyin_user_search').select('nickname, follower_count').order('follower_count', desc=True).limit(5).execute()
        print(f"\nğŸ“Š ç²‰ä¸æ•° TOP 5:")
        for user in response.data:
            print(f"   {user['nickname']}: {user['follower_count']:,} ç²‰ä¸")
    
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
    
    print(f"\n{'='*60}")
    print("âœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()

