#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†æ1-22é¡µæŠ¤è‚¤è¾¾äººæ•°æ®çš„è¶‹åŠ¿å˜åŒ–
"""

import os
import json
from pathlib import Path
from collections import defaultdict


def categorize_user(follower_count):
    """æ ¹æ®ç²‰ä¸æ•°åˆ†ç±»ç”¨æˆ·"""
    if follower_count > 1_000_000:
        return 'å¤´éƒ¨è¾¾äºº (>100ä¸‡)'
    elif follower_count >= 100_000:
        return 'è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)'
    elif follower_count >= 10_000:
        return 'å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)'
    else:
        return 'ç´ äºº (<1ä¸‡)'


def main():
    """ä¸»å‡½æ•°ï¼šç»Ÿè®¡åˆ†æ1-22é¡µæ•°æ®è¶‹åŠ¿"""
    
    print("=" * 60)
    print("æŠ¤è‚¤è¾¾äººæ•°æ®è¶‹åŠ¿åˆ†æï¼ˆç¬¬1-22é¡µï¼‰")
    print("=" * 60)
    
    # å®šä½åˆ° detail ç›®å½•
    script_dir = Path(__file__).parent.parent
    detail_dir = script_dir / "output" / "detail"
    
    # æ”¶é›†æ‰€æœ‰é¡µé¢æ•°æ®
    all_uids = set()
    page_stats = []
    global_duplicates = 0
    
    for page_num in range(1, 23):
        page_file = detail_dir / f'page_{page_num}_request_response.json'
        
        if not page_file.exists():
            print(f"âš ï¸ ç¬¬{page_num}é¡µæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
        
        with open(page_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–ç”¨æˆ·åˆ—è¡¨
        response = data.get('response', {})
        response_data = response.get('data', {})
        inner_data = response_data.get('data', [])
        user_list = inner_data if isinstance(inner_data, list) else []
        
        # ç»Ÿè®¡æœ¬é¡µ
        page_categories = {
            'å¤´éƒ¨è¾¾äºº (>100ä¸‡)': 0,
            'è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)': 0,
            'å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)': 0,
            'ç´ äºº (<1ä¸‡)': 0
        }
        
        page_duplicates = 0
        
        for user in user_list:
            user_info = user.get('user_info', {})
            uid = user_info.get('uid', '')
            follower_count = user_info.get('follower_count', 0)
            
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if uid in all_uids:
                page_duplicates += 1
                global_duplicates += 1
            else:
                if uid:
                    all_uids.add(uid)
            
            # åˆ†ç±»ç»Ÿè®¡
            category = categorize_user(follower_count)
            page_categories[category] += 1
        
        # ä¿å­˜æœ¬é¡µç»Ÿè®¡
        total = len(user_list)
        page_stats.append({
            'page': page_num,
            'total': total,
            'new': total - page_duplicates,
            'duplicates': page_duplicates,
            'categories': page_categories,
            'percentages': {
                cat: (count / total * 100) if total > 0 else 0
                for cat, count in page_categories.items()
            }
        })
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   æ€»é¡µæ•°: {len(page_stats)}")
    print(f"   å”¯ä¸€ç”¨æˆ·æ•°: {len(all_uids)}")
    print(f"   å…¨å±€é‡å¤æ•°: {global_duplicates}")
    
    # åˆ†æ®µç»Ÿè®¡ï¼ˆå‰ã€ä¸­ã€åï¼‰
    print(f"\nğŸ“ˆ åˆ†æ®µè¶‹åŠ¿åˆ†æ:")
    
    segments = [
        ("ç¬¬1-7é¡µï¼ˆå‰æ®µï¼‰", page_stats[0:7]),
        ("ç¬¬8-15é¡µï¼ˆä¸­æ®µï¼‰", page_stats[7:15]),
        ("ç¬¬16-22é¡µï¼ˆåæ®µï¼‰", page_stats[15:22])
    ]
    
    for segment_name, segment_data in segments:
        if not segment_data:
            continue
        
        print(f"\n{segment_name}:")
        
        # è®¡ç®—å¹³å‡å€¼
        avg_categories = defaultdict(float)
        avg_duplicates = 0
        
        for stat in segment_data:
            for cat, pct in stat['percentages'].items():
                avg_categories[cat] += pct
            avg_duplicates += stat['duplicates']
        
        pages_count = len(segment_data)
        for cat in avg_categories:
            avg_categories[cat] /= pages_count
        avg_duplicates /= pages_count
        
        print(f"  å¤´éƒ¨è¾¾äººå æ¯”: {avg_categories['å¤´éƒ¨è¾¾äºº (>100ä¸‡)']:.1f}%")
        print(f"  è…°éƒ¨è¾¾äººå æ¯”: {avg_categories['è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)']:.1f}%")
        print(f"  å°¾éƒ¨è¾¾äººå æ¯”: {avg_categories['å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)']:.1f}%")
        print(f"  ç´ äººå æ¯”: {avg_categories['ç´ äºº (<1ä¸‡)']:.1f}%")
        print(f"  å¹³å‡é‡å¤æ•°: {avg_duplicates:.1f}")
    
    # é€é¡µè¯¦ç»†ç»Ÿè®¡
    print(f"\nğŸ“‹ é€é¡µè¯¦ç»†ç»Ÿè®¡:")
    print(f"{'é¡µç ':<6} {'æ€»æ•°':<6} {'æ–°å¢':<6} {'é‡å¤':<6} {'å¤´éƒ¨%':<8} {'è…°éƒ¨%':<8} {'å°¾éƒ¨%':<8} {'ç´ äºº%':<8}")
    print("-" * 70)
    
    for stat in page_stats:
        pct = stat['percentages']
        print(f"{stat['page']:<6} {stat['total']:<6} {stat['new']:<6} {stat['duplicates']:<6} "
              f"{pct['å¤´éƒ¨è¾¾äºº (>100ä¸‡)']:<8.1f} {pct['è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)']:<8.1f} "
              f"{pct['å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)']:<8.1f} {pct['ç´ äºº (<1ä¸‡)']:<8.1f}")
    
    # è¶‹åŠ¿åˆ†æç»“è®º
    print(f"\nğŸ” è¶‹åŠ¿åˆ†æç»“è®º:")
    
    # æ¯”è¾ƒå‰åæ®µ
    first_segment = segments[0][1]
    last_segment = segments[2][1]
    
    first_avg = defaultdict(float)
    last_avg = defaultdict(float)
    
    for stat in first_segment:
        for cat, pct in stat['percentages'].items():
            first_avg[cat] += pct
    for cat in first_avg:
        first_avg[cat] /= len(first_segment)
    
    for stat in last_segment:
        for cat, pct in stat['percentages'].items():
            last_avg[cat] += pct
    for cat in last_avg:
        last_avg[cat] /= len(last_segment)
    
    print(f"\n1. å¤´éƒ¨è¾¾äººï¼ˆ>100ä¸‡ç²‰ä¸ï¼‰:")
    change = last_avg['å¤´éƒ¨è¾¾äºº (>100ä¸‡)'] - first_avg['å¤´éƒ¨è¾¾äºº (>100ä¸‡)']
    if change > 0:
        print(f"   âœ… åæ®µæ¯”å‰æ®µå¢åŠ äº† {change:.1f}%ï¼Œè¯´æ˜è¶Šå¾€åå¤´éƒ¨è¾¾äººè¶Šå¤š")
    else:
        print(f"   âŒ åæ®µæ¯”å‰æ®µå‡å°‘äº† {abs(change):.1f}%ï¼Œè¯´æ˜è¶Šå¾€åå¤´éƒ¨è¾¾äººè¶Šå°‘")
    
    print(f"\n2. è…°éƒ¨è¾¾äººï¼ˆ10ä¸‡-100ä¸‡ç²‰ä¸ï¼‰:")
    change = last_avg['è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)'] - first_avg['è…°éƒ¨è¾¾äºº (10ä¸‡~100ä¸‡)']
    if change > 0:
        print(f"   âœ… åæ®µæ¯”å‰æ®µå¢åŠ äº† {change:.1f}%ï¼Œè¯´æ˜è¶Šå¾€åè…°éƒ¨è¾¾äººè¶Šå¤š")
    else:
        print(f"   âŒ åæ®µæ¯”å‰æ®µå‡å°‘äº† {abs(change):.1f}%ï¼Œè¯´æ˜è¶Šå¾€åè…°éƒ¨è¾¾äººè¶Šå°‘")
    
    print(f"\n3. å°¾éƒ¨è¾¾äººï¼ˆ1ä¸‡-10ä¸‡ç²‰ä¸ï¼‰:")
    change = last_avg['å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)'] - first_avg['å°¾éƒ¨è¾¾äºº (1ä¸‡~10ä¸‡)']
    if change > 0:
        print(f"   âœ… åæ®µæ¯”å‰æ®µå¢åŠ äº† {change:.1f}%ï¼Œè¯´æ˜è¶Šå¾€åå°¾éƒ¨è¾¾äººè¶Šå¤š")
    else:
        print(f"   âŒ åæ®µæ¯”å‰æ®µå‡å°‘äº† {abs(change):.1f}%ï¼Œè¯´æ˜è¶Šå¾€åå°¾éƒ¨è¾¾äººè¶Šå°‘")
    
    print(f"\n4. ç´ äººï¼ˆ<1ä¸‡ç²‰ä¸ï¼‰:")
    change = last_avg['ç´ äºº (<1ä¸‡)'] - first_avg['ç´ äºº (<1ä¸‡)']
    if change > 0:
        print(f"   âœ… åæ®µæ¯”å‰æ®µå¢åŠ äº† {change:.1f}%ï¼Œè¯´æ˜è¶Šå¾€åç´ äººè¶Šå¤š")
    else:
        print(f"   âŒ åæ®µæ¯”å‰æ®µå‡å°‘äº† {abs(change):.1f}%ï¼Œè¯´æ˜è¶Šå¾€åç´ äººè¶Šå°‘")
    
    print(f"\n5. é‡å¤æ•°æ®:")
    first_dup = sum(s['duplicates'] for s in first_segment) / len(first_segment)
    last_dup = sum(s['duplicates'] for s in last_segment) / len(last_segment)
    if global_duplicates > 0:
        print(f"   âš ï¸ å­˜åœ¨ {global_duplicates} ä¸ªé‡å¤ç”¨æˆ·ï¼ˆè·¨é¡µé‡å¤ï¼‰")
        print(f"   å‰æ®µå¹³å‡é‡å¤: {first_dup:.1f} ä¸ª/é¡µ")
        print(f"   åæ®µå¹³å‡é‡å¤: {last_dup:.1f} ä¸ª/é¡µ")
    else:
        print(f"   âœ… æ²¡æœ‰é‡å¤æ•°æ®")
    
    print(f"\n{'='*60}")


if __name__ == "__main__":
    main()

