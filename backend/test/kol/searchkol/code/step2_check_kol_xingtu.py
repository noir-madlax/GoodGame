#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Step 2: ä»æœç´¢åˆ°çš„ç”¨æˆ·ä¸­æ£€æŸ¥å“ªäº›æ˜¯æ˜Ÿå›¾KOL
ä» gg_douyin_user_search è¡¨ä¸­ç­›é€‰10W-50Wç²‰ä¸çš„åˆçº§KOLï¼ŒéªŒè¯æ˜¯å¦æ˜¯æ˜Ÿå›¾KOL

ä¸šåŠ¡æµç¨‹:
1. ä»æ•°æ®åº“æŸ¥è¯¢10W-50Wç²‰ä¸çš„ç”¨æˆ·
2. è°ƒç”¨æ˜Ÿå›¾æ¥å£éªŒè¯æ˜¯å¦æ˜¯KOL
3. ç»Ÿè®¡KOLæ¯”ä¾‹å’Œåˆ†å¸ƒ
4. ä¿å­˜ç»“æœåˆ°outputç›®å½•
"""

import os
import sys
import json
import requests
import time
import argparse
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# è®¾ç½®åç«¯ç›®å½•è·¯å¾„
# å½“å‰æ–‡ä»¶: .../backend/test/kol/searchkol/code/step2_check_kol_xingtu.py
# backendç›®å½•: code -> searchkol -> kol -> test -> backend (å‘ä¸Š4çº§)
# ä½†searchkolä¸‹è¿˜æœ‰codeï¼Œæ‰€ä»¥æ˜¯: code(1) -> searchkol(2) -> kol(3) -> test(4) -> backend(5)
backend_dir = Path(__file__).resolve().parent.parent.parent.parent.parent


def load_api_key():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½TikHub API Key"""
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError(f"ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    return api_key


def get_api_base_url(use_china_domain: bool = True) -> str:
    """
    è·å–APIåŸºç¡€URL
    
    Args:
        use_china_domain: æ˜¯å¦ä½¿ç”¨ä¸­å›½åŠ é€ŸåŸŸå
        
    Returns:
        APIåŸºç¡€URL
    """
    if use_china_domain:
        return "https://api.tikhub.dev/api/v1"
    else:
        return "https://api.tikhub.io/api/v1"


def load_cookie():
    """
    ä»cookieæ–‡ä»¶åŠ è½½Cookie
    
    æ”¯æŒä¸¤ç§æ ¼å¼:
    1. JSONæ ¼å¼ (æµè§ˆå™¨æ’ä»¶å¯¼å‡ºçš„æ ¼å¼)
    2. çº¯æ–‡æœ¬æ ¼å¼ (key=value; key2=value2; ...)
    
    Returns:
        Cookieå­—ç¬¦ä¸²
    """
    cookie_path = backend_dir / 'test' / 'kol' / 'cookie'
    
    if not cookie_path.exists():
        return None
    
    try:
        with open(cookie_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯JSONæ ¼å¼
            if content.startswith('[') or content.startswith('{'):
                cookie_list = json.loads(content)
                
                # è½¬æ¢JSONæ ¼å¼ä¸ºcookieå­—ç¬¦ä¸²
                if isinstance(cookie_list, list):
                    cookie_parts = []
                    for cookie_item in cookie_list:
                        if 'name' in cookie_item and 'value' in cookie_item:
                            name = cookie_item['name']
                            value = cookie_item['value']
                            # è·³è¿‡ç©ºåç§°çš„cookie
                            if name:
                                cookie_parts.append(f"{name}={value}")
                    
                    cookie_str = '; '.join(cookie_parts)
                    return cookie_str
                else:
                    return None
            else:
                # çº¯æ–‡æœ¬æ ¼å¼ï¼Œç›´æ¥è¿”å›
                return content
    except Exception as e:
        print(f"   âš ï¸ CookieåŠ è½½å¤±è´¥: {e}")
        return None


def get_xingtu_kol_id(api_key: str, sec_user_id: str, cookie: str = None, use_china_domain: bool = True) -> dict:
    """
    æ¥å£1.1: é€šè¿‡æŠ–éŸ³sec_user_idè·å–æ˜Ÿå›¾KOL ID
    
    æ¥å£æ–‡æ¡£: https://api.tikhub.io/#/Douyin-Xingtu-API/get_xingtu_kolid_by_sec_user_id
    
    Args:
        api_key: APIå¯†é’¥
        sec_user_id: æŠ–éŸ³ç”¨æˆ·çš„sec_user_id
        cookie: æŠ–éŸ³Cookie (å¯é€‰ä½†æ¨è)
        use_china_domain: æ˜¯å¦ä½¿ç”¨ä¸­å›½åŠ é€ŸåŸŸå (é»˜è®¤Trueï¼Œä½¿ç”¨api.tikhub.dev)
        
    Returns:
        APIå“åº”æ•°æ®
    """
    base_url = get_api_base_url(use_china_domain)
    endpoint = "/douyin/xingtu/get_xingtu_kolid_by_sec_user_id"
    url = f"{base_url}{endpoint}"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    # æ·»åŠ Cookieï¼ˆå¦‚æœæœ‰ï¼‰
    if cookie:
        headers['Cookie'] = cookie
    
    params = {
        'sec_user_id': sec_user_id
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            return result
        else:
            error_text = response.text
            try:
                error_json = response.json()
                return {
                    "error": f"HTTP {response.status_code}",
                    "message": error_text[:500],
                    "detail": error_json
                }
            except:
                return {
                    "error": f"HTTP {response.status_code}",
                    "message": error_text[:500]
                }
            
    except Exception as e:
        return {"error": str(e)}


def get_kol_audience_portrait(api_key: str, kol_id: str, cookie: str = None, use_china_domain: bool = True) -> dict:
    """
    æ¥å£1.3: è·å–KOLå—ä¼—ç”»åƒ âœ… (å·²éªŒè¯å¯ç”¨)
    
    åŒ…å«: æ€§åˆ«ã€å¹´é¾„ã€åœ°åŸŸã€å…´è¶£æ ‡ç­¾ç­‰
    """
    base_url = get_api_base_url(use_china_domain)
    endpoint = "/douyin/xingtu/kol_audience_portrait_v1"
    url = f"{base_url}{endpoint}"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    if cookie:
        headers['Cookie'] = cookie
    
    # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼ˆé©¼å³°å‘½åï¼‰
    params = {
        'kolId': kol_id
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": f"HTTP {response.status_code}",
                "message": response.text[:500]
            }
            
    except Exception as e:
        return {"error": str(e)}


def get_kol_cp_info(api_key: str, kol_id: str, cookie: str = None, use_china_domain: bool = True) -> dict:
    """
    æ¥å£1.5: è·å–KOLæ€§ä»·æ¯”èƒ½åŠ›ï¼ˆCP Infoï¼‰âœ… (å·²éªŒè¯å¯ç”¨)
    
    åŒ…å«: é¢„æœŸCPEã€CPMã€æ’­æ”¾é‡ã€çƒ­é—¨ä½œå“ç­‰
    """
    base_url = get_api_base_url(use_china_domain)
    endpoint = "/douyin/xingtu/kol_cp_info_v1"
    url = f"{base_url}{endpoint}"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    if cookie:
        headers['Cookie'] = cookie
    
    # ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åï¼ˆé©¼å³°å‘½åï¼‰
    params = {
        'kolId': kol_id
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": f"HTTP {response.status_code}",
                "message": response.text[:500]
            }
            
    except Exception as e:
        return {"error": str(e)}


def fetch_users_from_db(follower_min: int = 100001, follower_max: int = 500000, limit: int = 10):
    """
    ä»æ•°æ®åº“æŸ¥è¯¢æŒ‡å®šç²‰ä¸èŒƒå›´çš„ç”¨æˆ·
    
    ä½¿ç”¨ Supabase REST API ç›´æ¥æŸ¥è¯¢ï¼ˆä¸éœ€è¦å®‰è£…supabaseåŒ…ï¼‰
    
    Args:
        follower_min: æœ€å°ç²‰ä¸æ•°
        follower_max: æœ€å¤§ç²‰ä¸æ•°
        limit: è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        ç”¨æˆ·åˆ—è¡¨
    """
    print(f"ğŸ“Š ä»æ•°æ®åº“æŸ¥è¯¢ç²‰ä¸æ•° {follower_min:,} - {follower_max:,} çš„ç”¨æˆ·...")
    
    # ä»ç¯å¢ƒå˜é‡åŠ è½½ Supabase é…ç½®
    env_path = backend_dir / '.env'
    if env_path.exists():
        load_dotenv(env_path)
    
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        print("âŒ SUPABASE_URL æˆ– SUPABASE_KEY æœªè®¾ç½®")
        return []
    
    # æ„å»º REST API URL
    # Supabase REST APIæ ¼å¼: {url}/rest/v1/{table}?{filters}
    # PostgREST èŒƒå›´æŸ¥è¯¢ä½¿ç”¨ and è¿æ¥å¤šä¸ªæ¡ä»¶
    rest_url = f"{supabase_url}/rest/v1/gg_douyin_user_search"
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    # PostgREST range query: follower_count=gte.100001&follower_count=lte.500000
    # ä½†Python dictä¸æ”¯æŒé‡å¤keyï¼Œæ‰€ä»¥æ‰‹åŠ¨æ„å»ºURL
    query_string = (
        f"select=uid,sec_uid,nickname,follower_count,signature,avatar_url,verification_type,gender"
        f"&follower_count=gte.{follower_min}"
        f"&follower_count=lte.{follower_max}"
        f"&order=follower_count.desc"
        f"&limit={limit}"
    )
    
    full_url = f"{rest_url}?{query_string}"
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'apikey': supabase_key,
        'Authorization': f'Bearer {supabase_key}'
    }
    
    try:
        # å‘é€è¯·æ±‚
        response = requests.get(full_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            users = response.json()
            print(f"âœ… æŸ¥è¯¢åˆ° {len(users)} ä¸ªç”¨æˆ·")
            return users
        else:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: HTTP {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text[:200]}")
            return []
    
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¼‚å¸¸: {e}")
        return []


def check_single_user_xingtu_status(user: dict, api_key: str, cookie: str = None) -> dict:
    """
    æ£€æŸ¥å•ä¸ªç”¨æˆ·çš„æ˜Ÿå›¾KOLçŠ¶æ€å¹¶è·å–ç”»åƒ
    
    Args:
        user: ç”¨æˆ·ä¿¡æ¯
        api_key: APIå¯†é’¥
        cookie: æŠ–éŸ³Cookie (å¯é€‰ä½†æ¨è)
        
    Returns:
        åŒ…å«æ‰€æœ‰æ¥å£æ•°æ®çš„å­—å…¸
    """
    uid = user.get('uid', '')
    sec_uid = user.get('sec_uid', '')
    nickname = user.get('nickname', 'Unknown')
    follower_count = user.get('follower_count', 0)
    
    print(f"\n{'='*70}")
    print(f"æ£€æŸ¥ç”¨æˆ·: {nickname} (UID: {uid})")
    print(f"ç²‰ä¸æ•°: {follower_count:,}")
    print(f"{'='*70}")
    
    result = {
        "uid": uid,
        "sec_uid": sec_uid,
        "nickname": nickname,
        "follower_count": follower_count,
        "signature": user.get('signature', ''),
        "avatar_url": user.get('avatar_url', ''),
        "verification_type": user.get('verification_type', 0),
        "gender": user.get('gender', 0),
        "check_timestamp": datetime.now().isoformat()
    }
    
    # Step 1: è·å–æ˜Ÿå›¾KOL ID
    print(f"ğŸ“¡ æ£€æŸ¥æ˜¯å¦ä¸ºæ˜Ÿå›¾KOL...")
    print(f"   sec_uid: {sec_uid[:50]}...")
    
    kol_id_response = get_xingtu_kol_id(api_key, sec_uid, cookie)
    
    # ä¿å­˜åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
    result['kol_id_response'] = kol_id_response
    
    if kol_id_response.get('error'):
        print(f"   âŒ è·å–KOL IDå¤±è´¥: {kol_id_response.get('error')}")
        result['error'] = f"è·å–KOL IDå¤±è´¥: {kol_id_response.get('error')}"
        result['is_xingtu_kol'] = False
        return result
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ˜Ÿå›¾KOL
    data_content = kol_id_response.get('data', {})
    kol_id = data_content.get('id', '')
    
    if not kol_id:
        print(f"   âš ï¸ éæ˜Ÿå›¾KOLï¼ˆæœªæ‰¾åˆ°kol_idï¼‰")
        result['is_xingtu_kol'] = False
        return result
    
    print(f"   âœ… æ˜¯æ˜Ÿå›¾KOLï¼KOL ID: {kol_id}")
    result['is_xingtu_kol'] = True
    result['kol_id'] = kol_id
    
    # Step 2: è·å–KOLç”»åƒæ•°æ®
    print(f"\nğŸ“Š è·å–æ˜Ÿå›¾KOLç”»åƒæ•°æ®...")
    
    xingtu_data = {}
    
    # 2.1 å—ä¼—ç”»åƒ
    print(f"   [1/2] è·å–å—ä¼—ç”»åƒ...")
    audience = get_kol_audience_portrait(api_key, kol_id, cookie)
    if not audience.get('error'):
        print(f"   âœ… å—ä¼—ç”»åƒè·å–æˆåŠŸ")
        xingtu_data['audience_portrait'] = audience
    else:
        print(f"   âŒ å—ä¼—ç”»åƒè·å–å¤±è´¥: {audience.get('error')}")
        xingtu_data['audience_portrait'] = audience
    
    time.sleep(0.5)
    
    # 2.2 æ€§ä»·æ¯”ä¿¡æ¯
    print(f"   [2/2] è·å–æ€§ä»·æ¯”ä¿¡æ¯...")
    cp_info = get_kol_cp_info(api_key, kol_id, cookie)
    if not cp_info.get('error'):
        print(f"   âœ… æ€§ä»·æ¯”ä¿¡æ¯è·å–æˆåŠŸ")
        xingtu_data['cp_info'] = cp_info
    else:
        print(f"   âŒ æ€§ä»·æ¯”ä¿¡æ¯è·å–å¤±è´¥: {cp_info.get('error')}")
        xingtu_data['cp_info'] = cp_info
    
    result['xingtu_data'] = xingtu_data
    
    # ç»Ÿè®¡æˆåŠŸç‡
    success_count = sum(1 for v in xingtu_data.values() if not v.get('error'))
    total_count = len(xingtu_data)
    
    print(f"\nğŸ“ˆ æ•°æ®è·å–å®Œæˆ: {success_count}/{total_count} ä¸ªæ¥å£æˆåŠŸ")
    
    return result


def extract_distribution_by_type(distributions: list, target_type: int) -> dict:
    """
    ä»distributionsæ•°ç»„ä¸­æå–æŒ‡å®šç±»å‹çš„åˆ†å¸ƒæ•°æ®
    
    Args:
        distributions: distributionsæ•°ç»„
        target_type: ç›®æ ‡ç±»å‹ï¼ˆ1=æ€§åˆ«, 2=å¹´é¾„, 64=åœ°åŸŸ, 512=å…´è¶£ï¼‰
    
    Returns:
        åˆ†å¸ƒæ•°æ®å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
    """
    for dist in distributions:
        if dist.get('type') == target_type:
            return {
                "type": dist.get('type'),
                "type_display": dist.get('type_display'),
                "description": dist.get('description'),
                "distribution_list": dist.get('distribution_list', []),
                "image": dist.get('image', [])
            }
    
    return None


def save_kol_mapping_to_db(result: dict) -> bool:
    """
    å°†UIDåˆ°KOL IDçš„æ˜ å°„å…³ç³»å†™å…¥æ•°æ®åº“
    
    ä½¿ç”¨Supabase REST APIè¿›è¡ŒUPSERTæ“ä½œ
    
    Args:
        result: ç”¨æˆ·æ£€æŸ¥ç»“æœ
        
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    # åŠ è½½ç¯å¢ƒå˜é‡
    env_path = backend_dir / '.env'
    if env_path.exists():
        load_dotenv(env_path)
    
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        print("   âš ï¸ æ•°æ®åº“é…ç½®æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ•°æ®åº“å†™å…¥")
        return False
    
    # æ„å»ºæ•°æ®
    data = {
        "uid": result['uid'],
        "kol_id": result.get('kol_id'),
        "is_xingtu_kol": result.get('is_xingtu_kol', False),
        "check_date": datetime.now().isoformat(),
        "error_message": result.get('error'),
        "updated_at": datetime.now().isoformat()
    }
    
    # å‘é€è¯·æ±‚ - ä½¿ç”¨UPSERTè¯­æ³•
    # Supabaseçš„UPSERTéœ€è¦åœ¨URLä¸­æŒ‡å®šon_conflictå‚æ•°
    url = f"{supabase_url}/rest/v1/gg_xingtu_kol_mapping?on_conflict=uid"
    headers = {
        'apikey': supabase_key,
        'Authorization': f'Bearer {supabase_key}',
        'Content-Type': 'application/json',
        'Prefer': 'resolution=merge-duplicates,return=minimal'  # UPSERTæ¨¡å¼
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=10)
        
        if response.status_code in [200, 201, 204]:
            print(f"   âœ… æ˜ å°„æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
            return True
        else:
            print(f"   âŒ æ˜ å°„æ•°æ®ä¿å­˜å¤±è´¥: HTTP {response.status_code}")
            print(f"      {response.text[:200]}")
            return False
    
    except Exception as e:
        print(f"   âŒ æ•°æ®åº“å†™å…¥å¼‚å¸¸: {e}")
        return False


def save_kol_audience_to_db(kol_id: str, audience_response: dict) -> bool:
    """
    å°†KOLå—ä¼—ç”»åƒæ•°æ®å†™å…¥æ•°æ®åº“
    
    è§£ædistributionsæ•°ç»„ï¼ŒæŒ‰ç±»å‹åˆ†ç±»å­˜å‚¨
    
    Args:
        kol_id: æ˜Ÿå›¾KOL ID
        audience_response: å—ä¼—ç”»åƒæ¥å£è¿”å›æ•°æ®
        
    Returns:
        æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    # åŠ è½½ç¯å¢ƒå˜é‡
    env_path = backend_dir / '.env'
    if env_path.exists():
        load_dotenv(env_path)
    
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_KEY')
    
    if not supabase_url or not supabase_key:
        return False
    
    # æå–æ•°æ®
    audience_data = audience_response.get('data', {})
    distributions = audience_data.get('distributions', [])
    
    # æå–å„ç±»åˆ†å¸ƒæ•°æ®
    gender_dist = extract_distribution_by_type(distributions, 1)    # æ€§åˆ«
    age_dist = extract_distribution_by_type(distributions, 2)       # å¹´é¾„
    region_dist = extract_distribution_by_type(distributions, 64)   # åœ°åŸŸ
    interest_dist = extract_distribution_by_type(distributions, 512) # å…´è¶£
    
    # æ„å»ºæ•°æ®
    data = {
        "kol_id": kol_id,
        "gender_distribution": gender_dist,
        "age_distribution": age_dist,
        "region_distribution": region_dist,
        "interest_tags": interest_dist,
        "raw_data": audience_data,
        "fetch_date": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }
    
    # å‘é€è¯·æ±‚ - ä½¿ç”¨UPSERTè¯­æ³•
    # Supabaseçš„UPSERTéœ€è¦åœ¨URLä¸­æŒ‡å®šon_conflictå‚æ•°
    url = f"{supabase_url}/rest/v1/gg_xingtu_kol_audience?on_conflict=kol_id"
    headers = {
        'apikey': supabase_key,
        'Authorization': f'Bearer {supabase_key}',
        'Content-Type': 'application/json',
        'Prefer': 'resolution=merge-duplicates,return=minimal'  # UPSERTæ¨¡å¼
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=10)
        
        if response.status_code in [200, 201, 204]:
            print(f"   âœ… å—ä¼—ç”»åƒå·²ä¿å­˜åˆ°æ•°æ®åº“")
            return True
        else:
            print(f"   âŒ å—ä¼—ç”»åƒä¿å­˜å¤±è´¥: HTTP {response.status_code}")
            print(f"      {response.text[:200]}")
            return False
    
    except Exception as e:
        print(f"   âŒ å—ä¼—ç”»åƒå†™å…¥å¼‚å¸¸: {e}")
        return False


def process_users(users: list, api_key: str, cookie: str = None, save_to_db: bool = True):
    """
    æ‰¹é‡å¤„ç†ç”¨æˆ·çš„æ˜Ÿå›¾KOLéªŒè¯
    
    Args:
        users: ç”¨æˆ·åˆ—è¡¨
        api_key: APIå¯†é’¥
        cookie: æŠ–éŸ³Cookie (å¯é€‰ä½†æ¨è)
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆé»˜è®¤Trueï¼‰
        
    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    results = []
    total = len(users)
    
    print(f"\n{'='*70}")
    print(f"ğŸš€ å¼€å§‹æ£€æŸ¥ {total} ä¸ªç”¨æˆ·çš„æ˜Ÿå›¾KOLçŠ¶æ€")
    print(f"{'='*70}")
    
    xingtu_kol_count = 0
    non_xingtu_count = 0
    error_count = 0
    db_save_success_count = 0
    db_save_failed_count = 0
    
    for idx, user in enumerate(users, 1):
        print(f"\n[{idx}/{total}]")
        
        result = check_single_user_xingtu_status(user, api_key, cookie)
        results.append(result)
        
        # ç»Ÿè®¡
        if result.get('is_xingtu_kol'):
            xingtu_kol_count += 1
        elif result.get('error'):
            error_count += 1
        else:
            non_xingtu_count += 1
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_db:
            print(f"\nğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...")
            
            # 1. ä¿å­˜æ˜ å°„å…³ç³»ï¼ˆæ‰€æœ‰ç”¨æˆ·éƒ½è¦ä¿å­˜ï¼‰
            if save_kol_mapping_to_db(result):
                db_save_success_count += 1
            else:
                db_save_failed_count += 1
            
            # 2. å¦‚æœæ˜¯æ˜Ÿå›¾KOLï¼Œä¿å­˜å—ä¼—ç”»åƒ
            if result.get('is_xingtu_kol'):
                xingtu_data = result.get('xingtu_data', {})
                
                # ä¿å­˜å—ä¼—ç”»åƒ
                if 'audience_portrait' in xingtu_data:
                    audience = xingtu_data['audience_portrait']
                    if not audience.get('error'):
                        save_kol_audience_to_db(result['kol_id'], audience)
        
        # æ¯ä¸ªç”¨æˆ·ä¹‹é—´é—´éš”1ç§’
        if idx < total:
            time.sleep(1)
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*70}")
    print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
    print(f"{'='*70}")
    print(f"æ€»è®¡ç”¨æˆ·æ•°: {total}")
    print(f"æ˜Ÿå›¾KOL: {xingtu_kol_count} ({xingtu_kol_count/total*100:.1f}%)")
    print(f"éæ˜Ÿå›¾KOL: {non_xingtu_count} ({non_xingtu_count/total*100:.1f}%)")
    print(f"æ£€æŸ¥å¤±è´¥: {error_count} ({error_count/total*100:.1f}%)")
    
    if save_to_db:
        print(f"\næ•°æ®åº“å†™å…¥ç»Ÿè®¡:")
        print(f"æˆåŠŸ: {db_save_success_count}")
        print(f"å¤±è´¥: {db_save_failed_count}")
    
    return results


def save_results(results: list, output_dir: str, follower_range: str):
    """
    ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
    
    Args:
        results: ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        follower_range: ç²‰ä¸èŒƒå›´æè¿°ï¼ˆå¦‚ "10w-50w"ï¼‰
    """
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # 1. ä¿å­˜å®Œæ•´æ•°æ®
    full_data_file = os.path.join(output_dir, f'step2_xingtu_kol_check_{follower_range}_{timestamp}.json')
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_users = len(results)
    xingtu_kols = [r for r in results if r.get('is_xingtu_kol')]
    xingtu_kol_count = len(xingtu_kols)
    
    output_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "follower_range": follower_range,
            "total_users_checked": total_users,
            "xingtu_kol_count": xingtu_kol_count,
            "xingtu_kol_rate": f"{xingtu_kol_count/total_users*100:.2f}%" if total_users > 0 else "0%",
            "data_source": "TikHub Xingtu API",
            "database_table": "gg_douyin_user_search"
        },
        "summary": {
            "total": total_users,
            "is_xingtu_kol": xingtu_kol_count,
            "non_xingtu_kol": sum(1 for r in results if not r.get('is_xingtu_kol') and not r.get('error')),
            "check_failed": sum(1 for r in results if r.get('error'))
        },
        "results": results
    }
    
    with open(full_data_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: {full_data_file}")
    
    # 2. ä¿å­˜æ˜Ÿå›¾KOLåˆ—è¡¨ï¼ˆä»…åŒ…å«æ˜¯æ˜Ÿå›¾KOLçš„ç”¨æˆ·ï¼‰
    if xingtu_kols:
        kol_only_file = os.path.join(output_dir, f'step2_xingtu_kol_only_{follower_range}_{timestamp}.json')
        
        kol_only_data = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "follower_range": follower_range,
                "total_xingtu_kols": xingtu_kol_count,
                "data_source": "TikHub Xingtu API"
            },
            "xingtu_kols": xingtu_kols
        }
        
        with open(kol_only_file, 'w', encoding='utf-8') as f:
            json.dump(kol_only_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ˜Ÿå›¾KOLåˆ—è¡¨å·²ä¿å­˜åˆ°: {kol_only_file}")
    
    # 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report_file = os.path.join(output_dir, f'step2_analysis_report_{follower_range}_{timestamp}.md')
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# æ˜Ÿå›¾KOLæ£€æŸ¥åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**ç²‰ä¸èŒƒå›´**: {follower_range}\n\n")
        f.write(f"## ğŸ“Š æ€»ä½“ç»Ÿè®¡\n\n")
        f.write(f"- æ£€æŸ¥ç”¨æˆ·æ€»æ•°: {total_users}\n")
        f.write(f"- æ˜Ÿå›¾KOLæ•°é‡: {xingtu_kol_count} ({xingtu_kol_count/total_users*100:.2f}%)\n")
        f.write(f"- éæ˜Ÿå›¾ç”¨æˆ·: {sum(1 for r in results if not r.get('is_xingtu_kol') and not r.get('error'))} ({sum(1 for r in results if not r.get('is_xingtu_kol') and not r.get('error'))/total_users*100:.2f}%)\n")
        f.write(f"- æ£€æŸ¥å¤±è´¥: {sum(1 for r in results if r.get('error'))} ({sum(1 for r in results if r.get('error'))/total_users*100:.2f}%)\n\n")
        
        if xingtu_kols:
            f.write(f"## âœ… æ˜Ÿå›¾KOLåˆ—è¡¨\n\n")
            f.write(f"| åºå· | æ˜µç§° | UID | ç²‰ä¸æ•° | KOL ID |\n")
            f.write(f"|------|------|-----|--------|--------|\n")
            
            for idx, kol in enumerate(xingtu_kols, 1):
                nickname = kol.get('nickname', '')
                uid = kol.get('uid', '')
                follower_count = kol.get('follower_count', 0)
                kol_id = kol.get('kol_id', '')
                
                f.write(f"| {idx} | {nickname} | {uid} | {follower_count:,} | {kol_id} |\n")
        
        f.write(f"\n---\n\n")
        f.write(f"*æ•°æ®æ¥æº: gg_douyin_user_search è¡¨*\n")
    
    print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return full_data_file, kol_only_file if xingtu_kols else None, report_file


def main():
    """ä¸»å‡½æ•°"""
    
    # å‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='ä»æ•°æ®åº“ç”¨æˆ·ä¸­æ£€æŸ¥æ˜Ÿå›¾KOLçŠ¶æ€')
    parser.add_argument('--limit', type=int, default=3, help='å¤„ç†ç”¨æˆ·æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤3ï¼‰')
    parser.add_argument('--follower-min', type=int, default=100001, help='æœ€å°ç²‰ä¸æ•°ï¼ˆé»˜è®¤100001ï¼‰')
    parser.add_argument('--follower-max', type=int, default=500000, help='æœ€å¤§ç²‰ä¸æ•°ï¼ˆé»˜è®¤500000ï¼‰')
    parser.add_argument('--save-db', action='store_true', default=True, help='æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆé»˜è®¤Trueï¼‰')
    parser.add_argument('--no-save-db', dest='save_db', action='store_false', help='ä¸ä¿å­˜åˆ°æ•°æ®åº“')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("Step 2: ä»ç”¨æˆ·ä¸­æ£€æŸ¥æ˜Ÿå›¾KOLçŠ¶æ€")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\n1ï¸âƒ£ åŠ è½½é…ç½®...")
    try:
        api_key = load_api_key()
        print(f"âœ… API Keyå·²åŠ è½½")
    except ValueError as e:
        print(f"âŒ {e}")
        return
    
    # åŠ è½½Cookie
    cookie = load_cookie()
    if cookie:
        print(f"âœ… Cookieå·²åŠ è½½ (é•¿åº¦: {len(cookie)} å­—ç¬¦)")
    else:
        print("âš ï¸ CookieæœªåŠ è½½ï¼Œå¯èƒ½å½±å“éƒ¨åˆ†æ¥å£è°ƒç”¨")
    
    # 2. ä»æ•°æ®åº“æŸ¥è¯¢ç”¨æˆ·
    print(f"\n2ï¸âƒ£ ä»æ•°æ®åº“æŸ¥è¯¢ç”¨æˆ·...")
    print(f"   ç²‰ä¸èŒƒå›´: {args.follower_min:,} - {args.follower_max:,}")
    print(f"   æŸ¥è¯¢æ•°é‡: {args.limit}")
    
    users = fetch_users_from_db(
        follower_min=args.follower_min,
        follower_max=args.follower_max,
        limit=args.limit
    )
    
    if not users:
        print("âŒ æœªæŸ¥è¯¢åˆ°ç”¨æˆ·ï¼Œç¨‹åºé€€å‡º")
        return
    
    # 3. æ£€æŸ¥æ˜Ÿå›¾KOLçŠ¶æ€
    print(f"\n3ï¸âƒ£ å¼€å§‹æ£€æŸ¥æ˜Ÿå›¾KOLçŠ¶æ€...")
    print(f"   æ•°æ®åº“å†™å…¥: {'âœ… å¯ç”¨' if args.save_db else 'âŒ ç¦ç”¨'}")
    results = process_users(users, api_key, cookie, save_to_db=args.save_db)
    
    # 4. ä¿å­˜ç»“æœ
    print(f"\n4ï¸âƒ£ ä¿å­˜ç»“æœ...")
    
    # è¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent.parent
    timestamp_dir = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = script_dir / "output" / f"step2_kol_check_{timestamp_dir}"
    
    # ç²‰ä¸èŒƒå›´æ ‡è¯†
    follower_range = f"{args.follower_min//10000}w-{args.follower_max//10000}w"
    
    save_results(results, str(output_dir), follower_range)
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()

