"""
æ‰¹é‡è·å–æŠ¤è‚¤ä¿å…»è¾¾äººçš„è§†é¢‘ä¿¡æ¯
ä½¿ç”¨ TikHub API çš„ fetch_multi_video_v2 æ¥å£ä¸€æ¬¡è·å–50ä¸ªè§†é¢‘
"""
import os
import json
import requests
from datetime import datetime
from typing import Dict, List, Set
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ (ä»backendç›®å½•åŠ è½½.env)
# å½“å‰æ–‡ä»¶: backend/test/kol/xingtu-searchkol-æƒé™å¼€é€šäº†/code/fetch_batch_videos.py
# ç›®æ ‡æ–‡ä»¶: backend/.env
env_path = Path(__file__).parent.parent.parent.parent.parent / ".env"
load_dotenv(env_path)

# ===== é…ç½® =====
API_BASE_URL = "https://api.tikhub.dev"  # å¤§é™†ç”¨æˆ·ä½¿ç”¨æ­¤åŸŸå
API_KEY = os.getenv("tikhub_API_KEY")  # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥

# è¾“å…¥è¾“å‡ºè·¯å¾„
INPUT_DIR = Path(__file__).parent.parent / "output" / "keyword_æŠ¤è‚¤ä¿å…»" / "detail"
OUTPUT_DIR = Path(__file__).parent.parent / "output" / "keyword_æŠ¤è‚¤ä¿å…»" / "batch_videos"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# è§†é¢‘ç±»å‹æ˜ å°„ (video_tag)
VIDEO_TAG_MAP = {
    3: "é«˜æ’­æ”¾ä½œå“(ç™¾ä¸‡çº§)",
    4: "å¸¦è´§ä½œå“",
    5: "çƒ­é—¨ä½œå“(åä¸‡çº§)",
    6: "è¿‘æœŸä½œå“"
}


class VideoInfo:
    """è§†é¢‘ä¿¡æ¯ç±»ï¼Œç”¨äºè®°å½•è§†é¢‘çš„å…³è”ä¿¡æ¯"""
    def __init__(self, item_id: str, author_id: str, author_name: str, video_tag: int, source: str):
        self.item_id = item_id  # è§†é¢‘ID
        self.author_id = author_id  # è¾¾äººID
        self.author_name = author_name  # è¾¾äººæ˜µç§°
        self.video_tag = video_tag  # è§†é¢‘ç±»å‹æ ‡ç­¾
        self.video_type = VIDEO_TAG_MAP.get(video_tag, "æœªçŸ¥ç±»å‹")  # è§†é¢‘ç±»å‹æè¿°
        self.source = source  # æ¥æºï¼šitems æˆ– last_10_items
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "item_id": self.item_id,
            "author_id": self.author_id,
            "author_name": self.author_name,
            "video_tag": self.video_tag,
            "video_type": self.video_type,
            "source": self.source
        }


def collect_video_ids_from_files() -> Dict[str, VideoInfo]:
    """
    ä»æ‰€æœ‰raw_page JSONæ–‡ä»¶ä¸­æ”¶é›†è§†é¢‘ID
    è¿”å›ï¼š{item_id: VideoInfo} å­—å…¸ï¼Œè‡ªåŠ¨å»é‡
    """
    video_dict: Dict[str, VideoInfo] = {}  # ä½¿ç”¨å­—å…¸è‡ªåŠ¨å»é‡
    processed_files = 0
    
    # éå†æ‰€æœ‰raw_page JSONæ–‡ä»¶
    for json_file in sorted(INPUT_DIR.glob("raw_page_*.json")):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰authorsæ•°æ®
            if 'data' not in data or 'authors' not in data['data']:
                continue
            
            authors = data['data']['authors']
            processed_files += 1
            
            # éå†æ¯ä¸ªè¾¾äºº
            for author in authors:
                # è·å–è¾¾äººåŸºç¡€ä¿¡æ¯
                attr = author.get('attribute_datas', {})
                author_id = attr.get('id') or attr.get('star_id', '')
                author_name = attr.get('nick_name', 'æœªçŸ¥è¾¾äºº')
                
                if not author_id:
                    continue
                
                # 1. ä» items (ä»£è¡¨ä½œå“) æå–è§†é¢‘ID
                items = author.get('items', [])
                for item in items:
                    item_id = item.get('item_id')
                    video_tag = item.get('video_tag', 0)
                    
                    if item_id and item_id not in video_dict:  # å»é‡
                        video_dict[item_id] = VideoInfo(
                            item_id=item_id,
                            author_id=author_id,
                            author_name=author_name,
                            video_tag=video_tag,
                            source="ä»£è¡¨ä½œå“(items)"
                        )
                
                # 2. ä» last_10_items (æœ€è¿‘ä½œå“) æå–è§†é¢‘ID
                last_10_items_str = attr.get('last_10_items', '[]')
                try:
                    last_10_items = json.loads(last_10_items_str)
                    for item in last_10_items:
                        item_id = item.get('item_id')
                        
                        if item_id and item_id not in video_dict:  # å»é‡
                            video_dict[item_id] = VideoInfo(
                                item_id=item_id,
                                author_id=author_id,
                                author_name=author_name,
                                video_tag=6,  # last_10_items å½’ç±»ä¸º"è¿‘æœŸä½œå“"
                                source="æœ€è¿‘10ä¸ªä½œå“(last_10_items)"
                            )
                except json.JSONDecodeError:
                    pass  # å¿½ç•¥è§£æé”™è¯¯
        
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {json_file.name} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"âœ… å·²å¤„ç† {processed_files} ä¸ªJSONæ–‡ä»¶")
    print(f"âœ… å…±æ”¶é›†åˆ° {len(video_dict)} ä¸ªä¸é‡å¤çš„è§†é¢‘ID")
    
    return video_dict


def select_50_videos(video_dict: Dict[str, VideoInfo]) -> List[VideoInfo]:
    """
    ä»æ”¶é›†çš„è§†é¢‘ä¸­é€‰æ‹©50ä¸ª
    ä¼˜å…ˆé€‰æ‹©ä¸åŒè¾¾äººçš„ä»£è¡¨ä½œå“ï¼Œç¡®ä¿å¤šæ ·æ€§
    """
    # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šä»£è¡¨ä½œå“ > æœ€è¿‘ä½œå“
    items_videos = [v for v in video_dict.values() if v.source == "ä»£è¡¨ä½œå“(items)"]
    last10_videos = [v for v in video_dict.values() if v.source == "æœ€è¿‘10ä¸ªä½œå“(last_10_items)"]
    
    selected = []
    seen_authors = set()  # è®°å½•å·²é€‰æ‹©çš„è¾¾äººï¼Œä¿è¯å¤šæ ·æ€§
    
    # ç¬¬ä¸€è½®ï¼šæ¯ä¸ªè¾¾äººé€‰1ä¸ªä»£è¡¨ä½œå“
    for video in items_videos:
        if len(selected) >= 50:
            break
        if video.author_id not in seen_authors:
            selected.append(video)
            seen_authors.add(video.author_id)
    
    # ç¬¬äºŒè½®ï¼šå¦‚æœä¸è¶³50ä¸ªï¼Œç»§ç»­æ·»åŠ ä»£è¡¨ä½œå“
    for video in items_videos:
        if len(selected) >= 50:
            break
        if video not in selected:
            selected.append(video)
    
    # ç¬¬ä¸‰è½®ï¼šå¦‚æœè¿˜ä¸è¶³50ä¸ªï¼Œæ·»åŠ æœ€è¿‘ä½œå“
    for video in last10_videos:
        if len(selected) >= 50:
            break
        if video not in selected:
            selected.append(video)
    
    print(f"\nâœ… å·²é€‰æ‹© {len(selected)} ä¸ªè§†é¢‘")
    print(f"   - æ¶‰åŠ {len(seen_authors)} ä¸ªä¸åŒçš„è¾¾äºº")
    
    # ç»Ÿè®¡è§†é¢‘ç±»å‹åˆ†å¸ƒ
    type_count = {}
    for video in selected:
        type_count[video.video_type] = type_count.get(video.video_type, 0) + 1
    
    print(f"   - è§†é¢‘ç±»å‹åˆ†å¸ƒï¼š")
    for vtype, count in sorted(type_count.items()):
        print(f"     * {vtype}: {count}ä¸ª")
    
    return selected


def call_tikhub_api(video_list: List[VideoInfo]):
    """
    è°ƒç”¨ TikHub API çš„ fetch_multi_video_v2 æ¥å£
    æ‰¹é‡è·å–50ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯
    """
    # APIç«¯ç‚¹
    endpoint = f"{API_BASE_URL}/api/v1/douyin/app/v3/fetch_multi_video_v2"
    
    # å‡†å¤‡è¯·æ±‚å‚æ•°
    aweme_ids = [video.item_id for video in video_list]  # è§†é¢‘IDåˆ—è¡¨
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    # æ ¹æ®APIæ–‡æ¡£ï¼Œç›´æ¥å‘é€åˆ—è¡¨ä½œä¸ºè¯·æ±‚ä½“
    payload = aweme_ids
    
    print(f"\nğŸ”„ æ­£åœ¨è°ƒç”¨ TikHub API...")
    print(f"   - è¯·æ±‚URL: {endpoint}")
    print(f"   - è§†é¢‘æ•°é‡: {len(aweme_ids)}")
    print(f"   - å‰5ä¸ªID: {aweme_ids[:5]}")
    
    try:
        # å‘é€POSTè¯·æ±‚ï¼Œç›´æ¥å‘é€åˆ—è¡¨ä½œä¸ºJSON
        response = requests.post(endpoint, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        # ä¿å­˜åŸå§‹APIå“åº”
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        raw_output_file = OUTPUT_DIR / f"api_response_raw_{timestamp}.json"
        with open(raw_output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"âœ… APIåŸå§‹å“åº”å·²ä¿å­˜: {raw_output_file}")
        
        # ä¿å­˜è§†é¢‘å…³è”ä¿¡æ¯ï¼ˆå“ªä¸ªè§†é¢‘å±äºå“ªä¸ªè¾¾äººï¼‰
        mapping_file = OUTPUT_DIR / f"video_author_mapping_{timestamp}.json"
        mapping_data = {
            "total_count": len(video_list),
            "videos": [v.to_dict() for v in video_list]
        }
        with open(mapping_file, 'w', encoding='utf-8') as f:
            json.dump(mapping_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… è§†é¢‘-è¾¾äººå…³è”ä¿¡æ¯å·²ä¿å­˜: {mapping_file}")
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        generate_summary_report(result, video_list, timestamp)
        
        return result
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e, 'response') and e.response is not None:
            print(f"   å“åº”å†…å®¹: {e.response.text}")
        return None


def generate_summary_report(api_result: dict, video_list: List[VideoInfo], timestamp: str):
    """
    ç”Ÿæˆå¯è¯»çš„æ±‡æ€»æŠ¥å‘Š
    """
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("æŠ¤è‚¤ä¿å…»è¾¾äººè§†é¢‘æ‰¹é‡è·å–æŠ¥å‘Š")
    report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("=" * 80)
    report_lines.append("")
    
    # 1. APIè¯·æ±‚æ¦‚å†µ
    report_lines.append("## 1. APIè¯·æ±‚æ¦‚å†µ")
    report_lines.append(f"   - è¯·æ±‚è§†é¢‘æ•°é‡: {len(video_list)}")
    report_lines.append(f"   - APIå“åº”çŠ¶æ€: {api_result.get('code', 'N/A')}")
    report_lines.append(f"   - APIæ¶ˆæ¯: {api_result.get('message_zh', 'N/A')}")
    report_lines.append("")
    
    # 2. è§†é¢‘-è¾¾äººå…³è”ä¿¡æ¯
    report_lines.append("## 2. è§†é¢‘-è¾¾äººå…³è”ä¿¡æ¯")
    report_lines.append("")
    
    # æŒ‰è¾¾äººåˆ†ç»„
    author_groups = {}
    for video in video_list:
        if video.author_id not in author_groups:
            author_groups[video.author_id] = {
                "name": video.author_name,
                "videos": []
            }
        author_groups[video.author_id]["videos"].append(video)
    
    report_lines.append(f"   æ¶‰åŠè¾¾äººæ•°é‡: {len(author_groups)}")
    report_lines.append("")
    
    for idx, (author_id, info) in enumerate(author_groups.items(), 1):
        report_lines.append(f"   ã€è¾¾äºº {idx}ã€‘{info['name']} (ID: {author_id})")
        for video in info['videos']:
            report_lines.append(f"      - {video.item_id} | {video.video_type} | {video.source}")
        report_lines.append("")
    
    # 3. è§†é¢‘ç±»å‹ç»Ÿè®¡
    report_lines.append("## 3. è§†é¢‘ç±»å‹åˆ†å¸ƒ")
    type_stats = {}
    for video in video_list:
        type_stats[video.video_type] = type_stats.get(video.video_type, 0) + 1
    
    for vtype, count in sorted(type_stats.items()):
        percentage = (count / len(video_list)) * 100
        report_lines.append(f"   - {vtype}: {count}ä¸ª ({percentage:.1f}%)")
    report_lines.append("")
    
    # 4. APIè¿”å›çš„è§†é¢‘æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'data' in api_result:
        data = api_result['data']
        if isinstance(data, dict) and 'aweme_list' in data:
            aweme_list = data['aweme_list']
            report_lines.append(f"## 4. APIè¿”å›çš„è§†é¢‘æ•°æ®")
            report_lines.append(f"   - æˆåŠŸè¿”å›è§†é¢‘æ•°: {len(aweme_list)}")
            report_lines.append("")
        elif isinstance(data, list):
            report_lines.append(f"## 4. APIè¿”å›çš„è§†é¢‘æ•°æ®")
            report_lines.append(f"   - æˆåŠŸè¿”å›è§†é¢‘æ•°: {len(data)}")
            report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("æŠ¥å‘Šç»“æŸ")
    report_lines.append("=" * 80)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = OUTPUT_DIR / f"summary_report_{timestamp}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_lines))
    
    print(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
    print("\n" + "\n".join(report_lines[:30]))  # æ‰“å°å‰30è¡Œ


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("æŠ¤è‚¤ä¿å…»è¾¾äººè§†é¢‘æ‰¹é‡è·å–å·¥å…·")
    print("=" * 80)
    print("")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not API_KEY:
        print(f"âŒ é”™è¯¯: æœªè®¾ç½® tikhub_API_KEY ç¯å¢ƒå˜é‡")
        print(f"   å°è¯•åŠ è½½çš„.envè·¯å¾„: {env_path}")
        print(f"   .envæ–‡ä»¶æ˜¯å¦å­˜åœ¨: {env_path.exists()}")
        return
    
    print(f"âœ… APIå¯†é’¥å·²åŠ è½½ (é•¿åº¦: {len(API_KEY)} å­—ç¬¦)")
    
    # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰è§†é¢‘ID
    print("\nã€æ­¥éª¤1ã€‘æ”¶é›†è§†é¢‘ID...")
    video_dict = collect_video_ids_from_files()
    
    if not video_dict:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘IDï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶")
        return
    
    # æ­¥éª¤2: é€‰æ‹©50ä¸ªè§†é¢‘
    print("\nã€æ­¥éª¤2ã€‘é€‰æ‹©50ä¸ªè§†é¢‘...")
    selected_videos = select_50_videos(video_dict)
    
    if len(selected_videos) < 50:
        print(f"âš ï¸  è­¦å‘Š: åªæ‰¾åˆ° {len(selected_videos)} ä¸ªè§†é¢‘ï¼Œå°‘äº50ä¸ª")
    
    # æ­¥éª¤3: è°ƒç”¨APIè·å–è§†é¢‘ä¿¡æ¯
    print("\nã€æ­¥éª¤3ã€‘è°ƒç”¨APIè·å–è§†é¢‘ä¿¡æ¯...")
    api_result = call_tikhub_api(selected_videos)
    
    if api_result:
        print("\nâœ… æ‰€æœ‰æ­¥éª¤å®Œæˆï¼")
    else:
        print("\nâŒ APIè°ƒç”¨å¤±è´¥")


if __name__ == "__main__":
    main()

