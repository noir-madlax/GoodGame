#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†ææ‰¹é‡è·å–çš„KOLè§†é¢‘æ•°æ®ï¼Œç”¨äºè¯„ä¼°å¸¦è´§èƒ½åŠ›

åŠŸèƒ½ï¼š
1. è¯»å– final_video_details.json
2. ç»Ÿè®¡è§†é¢‘å„é¡¹æŒ‡æ ‡åˆ†å¸ƒ
3. åˆ†æå¸¦è´§è§†é¢‘è´¨é‡ç›¸å…³ç‰¹å¾
4. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

ç›®æ ‡ï¼šè¯„ä¼°KOLæ˜¯å¦èƒ½äº§å‡ºé«˜è´¨é‡å¸¦è´§è§†é¢‘
"""

import os
import json
from pathlib import Path
from collections import Counter, defaultdict
from datetime import datetime
from dotenv import load_dotenv

def load_env():
    current_dir = Path(__file__).parent
    backend_dir = current_dir.parent.parent.parent
    env_path = backend_dir / '.env'
    if env_path.exists():
        load_dotenv(env_path)

def load_video_data():
    """åŠ è½½è§†é¢‘æ•°æ®"""
    current_dir = Path(__file__).parent
    data_file = current_dir / "output" / "final_video_details.json"

    if not data_file.exists():
        print(f"Error: {data_file} not found")
        return []

    with open(data_file, "r", encoding="utf-8") as f:
        return json.load(f)

def analyze_video_metrics(videos):
    """åˆ†æè§†é¢‘å„é¡¹æŒ‡æ ‡"""
    print("=" * 80)
    print("ğŸ“Š è§†é¢‘æŒ‡æ ‡ç»Ÿè®¡åˆ†æ")
    print("=" * 80)

    metrics = {
        'play_count': [],
        'digg_count': [],
        'comment_count': [],
        'share_count': [],
        'collect_count': [],
        'video_duration': [],
        'video_width': [],
        'video_height': []
    }

    # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡
    for video in videos:
        stats = video.get('statistics', {})

        # æ’­æ”¾é‡ï¼ˆplay_countï¼‰
        play_count = stats.get('play_count', 0)
        if play_count and play_count > 0:
            metrics['play_count'].append(play_count)

        # ç‚¹èµæ•°
        digg_count = stats.get('digg_count', 0)
        if digg_count and digg_count > 0:
            metrics['digg_count'].append(digg_count)

        # è¯„è®ºæ•°
        comment_count = stats.get('comment_count', 0)
        if comment_count is not None:
            metrics['comment_count'].append(comment_count)

        # åˆ†äº«æ•°
        share_count = stats.get('share_count', 0)
        if share_count is not None:
            metrics['share_count'].append(share_count)

        # æ”¶è—æ•°
        collect_count = stats.get('collect_count', 0)
        if collect_count is not None:
            metrics['collect_count'].append(collect_count)

        # è§†é¢‘å°ºå¯¸ä¿¡æ¯
        video_info = video.get('raw_video_data', {}).get('video', {})
        if video_info:
            width = video_info.get('width')
            height = video_info.get('height')
            if width: metrics['video_width'].append(width)
            if height: metrics['video_height'].append(height)

    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    for metric_name, values in metrics.items():
        if not values:
            print(f"\n{metric_name}: æ— æœ‰æ•ˆæ•°æ®")
            continue

        print(f"\n{metric_name} ({len(values)} ä¸ªæœ‰æ•ˆå€¼):")
        print(f"  å¹³å‡å€¼: {sum(values) / len(values):.1f}")
        print(f"  ä¸­ä½æ•°: {sorted(values)[len(values)//2]}")
        print(f"  æœ€å¤§å€¼: {max(values)}")
        print(f"  æœ€å°å€¼: {min(values)}")
        print(f"  åˆ†å¸ƒåŒºé—´:")

        # åˆ†åŒºé—´ç»Ÿè®¡
        ranges = []
        if metric_name in ['play_count', 'digg_count', 'comment_count', 'share_count', 'collect_count']:
            if max(values) >= 10000:
                ranges = [(0, 1000), (1000, 10000), (10000, 100000), (100000, 1000000), (1000000, float('inf'))]
                range_labels = ['<1k', '1k-10k', '10k-100k', '100k-1M', '1M+']
            elif max(values) >= 1000:
                ranges = [(0, 100), (100, 1000), (1000, 10000), (10000, 100000), (100000, float('inf'))]
                range_labels = ['<100', '100-1k', '1k-10k', '10k-100k', '100k+']
            else:
                ranges = [(0, 10), (10, 100), (100, 1000), (1000, float('inf'))]
                range_labels = ['<10', '10-100', '100-1k', '1k+']
        else:
            ranges = [(0, 720), (720, 1080), (1080, 1440), (1440, float('inf'))]
            range_labels = ['<720p', '720-1080p', '1080-1440p', '1440p+']

        for (low, high), label in zip(ranges, range_labels):
            count = sum(1 for v in values if low <= v < high)
            if count > 0:
                print(f"    {label}: {count} ä¸ª ({count/len(values)*100:.1f}%)")

def analyze_author_distribution(videos):
    """åˆ†æä½œè€…åˆ†å¸ƒ"""
    print("\n" + "=" * 80)
    print("ğŸ‘¤ ä½œè€…åˆ†å¸ƒåˆ†æ")
    print("=" * 80)

    authors = []
    author_stats = defaultdict(lambda: {'videos': 0, 'total_plays': 0, 'total_diggs': 0})

    for video in videos:
        author = video.get('author', {})
        if author.get('uid'):
            authors.append(author)
            uid = author['uid']
            stats = video.get('statistics', {})

            author_stats[uid]['videos'] += 1
            author_stats[uid]['total_plays'] += stats.get('play_count', 0)
            author_stats[uid]['total_diggs'] += stats.get('digg_count', 0)
            author_stats[uid]['nickname'] = author.get('nickname', 'N/A')
            author_stats[uid]['unique_id'] = author.get('unique_id', 'N/A')

    print(f"\næ€»ä½œè€…æ•°: {len(set(a['uid'] for a in authors if a.get('uid')))}")
    print(f"æ€»è§†é¢‘æ•°: {len(videos)}")

    # æŒ‰è§†é¢‘æ•°æ’åº
    sorted_authors = sorted(author_stats.items(),
                           key=lambda x: x[1]['videos'], reverse=True)

    print("
ä½œè€…è´¡çŒ®æ’å (æŒ‰è§†é¢‘æ•°):")
    for i, (uid, stats) in enumerate(sorted_authors[:20], 1):
        avg_plays = stats['total_plays'] / stats['videos'] if stats['videos'] > 0 else 0
        avg_diggs = stats['total_diggs'] / stats['videos'] if stats['videos'] > 0 else 0
        print(f"  {i:2d}. {stats['nickname']} (@{stats['unique_id']}) - {stats['videos']} ä¸ªè§†é¢‘ - å¹³å‡æ’­æ”¾: {avg_plays:,.0f} - å¹³å‡ç‚¹èµ: {avg_diggs:,.0f}")

def analyze_content_features(videos):
    """åˆ†æå†…å®¹ç‰¹å¾"""
    print("\n" + "=" * 80)
    print("ğŸ“ å†…å®¹ç‰¹å¾åˆ†æ")
    print("=" * 80)

    # æè¿°é•¿åº¦ç»Ÿè®¡
    desc_lengths = []
    has_product_keywords = 0
    has_shopping_links = 0
    has_hashtags = 0

    product_keywords = ['è´­ä¹°', 'é“¾æ¥', 'è´­ä¹°', 'ä»·', 'å…ƒ', 'äº§å“', 'å•†å“', 'æ¨è', 'ç§è‰', 'è¯•ç”¨', 'ä¼˜æƒ ', 'æŠ˜æ‰£', 'é™æ—¶']

    for video in videos:
        desc = video.get('desc', '')
        if desc:
            desc_lengths.append(len(desc))

            # æ£€æŸ¥äº§å“ç›¸å…³å…³é”®è¯
            desc_lower = desc.lower()
            if any(keyword in desc_lower for keyword in product_keywords):
                has_product_keywords += 1

            # æ£€æŸ¥æ˜¯å¦æœ‰è´­ç‰©é“¾æ¥ (@ç¬¦å·åé€šå¸¸æ˜¯å“ç‰Œæˆ–äº§å“)
            if '@' in desc:
                has_shopping_links += 1

            # æ£€æŸ¥è¯é¢˜æ ‡ç­¾
            if '#' in desc:
                has_hashtags += 1

    if desc_lengths:
        print("
æè¿°é•¿åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡é•¿åº¦: {sum(desc_lengths) / len(desc_lengths):.1f} å­—ç¬¦")
        print(f"  æœ€é•¿æè¿°: {max(desc_lengths)} å­—ç¬¦")
        print(f"  æœ€çŸ­æè¿°: {min(desc_lengths)} å­—ç¬¦")

    print("
å†…å®¹ç‰¹å¾ç»Ÿè®¡:")
    print(f"  åŒ…å«äº§å“å…³é”®è¯: {has_product_keywords}/{len(videos)} ({has_product_keywords/len(videos)*100:.1f}%)")
    print(f"  åŒ…å«@ç¬¦å·(å¯èƒ½è´­ç‰©é“¾æ¥): {has_shopping_links}/{len(videos)} ({has_shopping_links/len(videos)*100:.1f}%)")
    print(f"  åŒ…å«è¯é¢˜æ ‡ç­¾#: {has_hashtags}/{len(videos)} ({has_hashtags/len(videos)*100:.1f}%)")

def analyze_engagement_quality(videos):
    """åˆ†æäº’åŠ¨è´¨é‡"""
    print("\n" + "=" * 80)
    print("ğŸ”¥ äº’åŠ¨è´¨é‡åˆ†æ")
    print("=" * 80)

    engagement_data = []

    for video in videos:
        stats = video.get('statistics', {})
        plays = stats.get('play_count', 0)
        diggs = stats.get('digg_count', 0)
        comments = stats.get('comment_count', 0)
        shares = stats.get('share_count', 0)
        collects = stats.get('collect_count', 0)

        if plays > 0:
            engagement_rate = (diggs + comments * 10 + shares * 20 + collects * 15) / plays
            engagement_data.append({
                'plays': plays,
                'engagement_rate': engagement_rate,
                'digg_rate': diggs / plays,
                'comment_rate': comments / plays,
                'share_rate': shares / plays,
                'collect_rate': collects / plays
            })

    if engagement_data:
        print(f"\næ€»æœ‰æ•ˆè§†é¢‘æ•°: {len(engagement_data)}")

        # æŒ‰æ’­æ”¾é‡åˆ†ç»„åˆ†æäº’åŠ¨ç‡
        play_ranges = [
            (0, 10000),
            (10000, 100000),
            (100000, 1000000),
            (1000000, float('inf'))
        ]

        print("
æŒ‰æ’­æ”¾é‡åŒºé—´åˆ†æäº’åŠ¨è´¨é‡:")
        for min_plays, max_plays in play_ranges:
            range_data = [d for d in engagement_data if min_plays <= d['plays'] < max_plays]

            if range_data:
                avg_engagement = sum(d['engagement_rate'] for d in range_data) / len(range_data)
                avg_digg_rate = sum(d['digg_rate'] for d in range_data) / len(range_data)
                avg_comment_rate = sum(d['comment_rate'] for d in range_data) / len(range_data)

                print(f"  {min_plays:,}-{max_plays if max_plays != float('inf') else 'âˆ'}:")
                print(f"    è§†é¢‘æ•°: {len(range_data)}")
                print(f"    å¹³å‡äº’åŠ¨ç‡: {avg_engagement:.4f}")
                print(f"    å¹³å‡ç‚¹èµç‡: {avg_digg_rate:.4f}")
                print(f"    å¹³å‡è¯„è®ºç‡: {avg_comment_rate:.4f}")

def generate_kol_ranking(videos):
    """ç”ŸæˆKOLå¸¦è´§èƒ½åŠ›æ’å"""
    print("\n" + "=" * 80)
    print("ğŸ† KOLå¸¦è´§èƒ½åŠ›è¯„ä¼°æ’å")
    print("=" * 80)

    kol_scores = defaultdict(lambda: {
        'videos': [],
        'total_plays': 0,
        'total_diggs': 0,
        'total_comments': 0,
        'total_shares': 0,
        'total_collects': 0,
        'avg_engagement': 0,
        'has_product_content': 0,
        'nickname': '',
        'unique_id': ''
    })

    for video in videos:
        author = video.get('author', {})
        uid = author.get('uid')
        if not uid:
            continue

        stats = video.get('statistics', {})
        plays = stats.get('play_count', 0)
        diggs = stats.get('digg_count', 0)
        comments = stats.get('comment_count', 0)
        shares = stats.get('share_count', 0)
        collects = stats.get('collect_count', 0)

        # è®¡ç®—åŸºç¡€åˆ†æ•°
        engagement_score = 0
        if plays > 0:
            engagement_score = (diggs/plays * 1 + comments/plays * 10 + shares/plays * 20 + collects/plays * 15)

        # å†…å®¹è´¨é‡åˆ†æ•°
        desc = video.get('desc', '').lower()
        content_score = 0
        if any(kw in desc for kw in ['è´­ä¹°', 'é“¾æ¥', 'ä»·', 'å…ƒ', 'äº§å“', 'æ¨è', 'ç§è‰']):
            content_score += 1
        if '@' in desc:
            content_score += 1
        if '#' in desc:
            content_score += 1

        # è§†é¢‘è´¨é‡åˆ†æ•°ï¼ˆåŸºäºæ’­æ”¾é‡ï¼‰
        quality_score = min(plays / 100000, 5)  # æœ€é«˜5åˆ†

        # æ€»åˆ†æ•°
        total_score = engagement_score * 0.4 + content_score * 0.3 + quality_score * 0.3

        kol_scores[uid]['videos'].append({
            'score': total_score,
            'plays': plays,
            'engagement': engagement_score
        })
        kol_scores[uid]['total_plays'] += plays
        kol_scores[uid]['total_diggs'] += diggs
        kol_scores[uid]['total_comments'] += comments
        kol_scores[uid]['total_shares'] += shares
        kol_scores[uid]['total_collects'] += collects
        kol_scores[uid]['nickname'] = author.get('nickname', 'N/A')
        kol_scores[uid]['unique_id'] = author.get('unique_id', 'N/A')

        # æ£€æŸ¥æ˜¯å¦æœ‰äº§å“å†…å®¹
        if content_score > 0:
            kol_scores[uid]['has_product_content'] += 1

    # è®¡ç®—å¹³å‡åˆ†æ•°
    for uid, data in kol_scores.items():
        videos_data = data['videos']
        if videos_data:
            data['avg_score'] = sum(v['score'] for v in videos_data) / len(videos_data)
            data['avg_engagement'] = sum(v['engagement'] for v in videos_data) / len(videos_data)
            data['video_count'] = len(videos_data)
        else:
            data['avg_score'] = 0
            data['avg_engagement'] = 0
            data['video_count'] = 0

    # æ’å
    ranking = sorted(kol_scores.items(),
                    key=lambda x: (x[1]['avg_score'], x[1]['video_count']),
                    reverse=True)

    print("\nKOLå¸¦è´§èƒ½åŠ›æ’å (TOP 20):")
    print(f"{'æ’å':<4} {'æ˜µç§°':<16} {'æŠ–éŸ³å·':<16} {'è§†é¢‘æ•°':<6} {'å¹³å‡åˆ†æ•°':<8} {'æ€»æ’­æ”¾':<10} {'äº§å“å†…å®¹':<8}")
    print("-" * 120)

    for i, (uid, data) in enumerate(ranking[:20], 1):
        nickname = data['nickname'][:15]  # é™åˆ¶é•¿åº¦
        unique_id = data['unique_id'][:15]
        video_count = data['video_count']
        avg_score = data['avg_score']
        total_plays = data['total_plays']
        has_product = data['has_product_content']

        print(f"{i:<4} {nickname:<16} {unique_id:<16} {video_count:<6} {avg_score:<8.2f} {total_plays:<10,} {has_product:<8}")

def save_analysis_report(videos):
    """ä¿å­˜åˆ†ææŠ¥å‘Š"""
    current_dir = Path(__file__).parent
    output_dir = current_dir / "output"
    output_dir.mkdir(exist_ok=True)

    report = {
        'analysis_time': datetime.now().isoformat(),
        'total_videos': len(videos),
        'summary': {
            'avg_play_count': sum(v.get('statistics', {}).get('play_count', 0) for v in videos) / len(videos),
            'avg_digg_count': sum(v.get('statistics', {}).get('digg_count', 0) for v in videos) / len(videos),
            'avg_comment_count': sum(v.get('statistics', {}).get('comment_count', 0) for v in videos) / len(videos),
        },
        'recommendations': [
            "ä¼˜å…ˆé€‰æ‹©å¹³å‡æ’­æ”¾é‡>10ä¸‡çš„KOL",
            "äº’åŠ¨ç‡>0.05çš„è§†é¢‘è´¨é‡è¾ƒå¥½",
            "åŒ…å«äº§å“å…³é”®è¯å’Œ@é“¾æ¥çš„è§†é¢‘æ›´é€‚åˆå¸¦è´§",
            "ç²‰ä¸åŸºç¡€å¥½çš„KOLæ›´å®¹æ˜“äº§å‡ºé«˜è´¨é‡å†…å®¹"
        ]
    }

    report_file = output_dir / "video_analysis_report.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    print("=" * 80)
    print("æŠ–éŸ³KOLå¸¦è´§è§†é¢‘è´¨é‡åˆ†æå·¥å…·")
    print("=" * 80)

    # åŠ è½½æ•°æ®
    videos = load_video_data()
    if not videos:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ•°æ®")
        return

    print(f"âœ… åŠ è½½äº† {len(videos)} ä¸ªè§†é¢‘æ•°æ®")

    # æ‰§è¡Œå„é¡¹åˆ†æ
    analyze_video_metrics(videos)
    analyze_author_distribution(videos)
    analyze_content_features(videos)
    analyze_engagement_quality(videos)
    generate_kol_ranking(videos)

    # ä¿å­˜æŠ¥å‘Š
    save_analysis_report(videos)

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    main()

