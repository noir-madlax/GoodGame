#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†æè§†é¢‘æ•°æ®è´¨é‡å’Œç»“æ„
"""

import json
import os
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Any

def analyze_video_data_quality():
    """åˆ†æè§†é¢‘æ•°æ®çš„è´¨é‡å’Œç»“æ„"""

    output_dir = Path(__file__).parent / "output"
    data_file = Path(__file__).parent.parent / "kol-video-fetcher" / "output" / "final_video_details.json"

    if not data_file.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return

    print("ğŸ” å¼€å§‹åˆ†æè§†é¢‘æ•°æ®è´¨é‡...")
    print("=" * 60)

    # 1. åŠ è½½æ•°æ®
    with open(data_file, 'r', encoding='utf-8') as f:
        videos = json.load(f)

    print(f"ğŸ“Š æ€»è§†é¢‘æ•°: {len(videos)}")
    print()

    # 2. æ£€æŸ¥åŸºæœ¬å­—æ®µå­˜åœ¨æ€§
    print("ğŸ“‹ å­—æ®µå­˜åœ¨æ€§ç»Ÿè®¡:")
    print("-" * 40)

    field_stats = defaultdict(int)
    total_videos = len(videos)

    for video in videos:
        for field in ['aweme_id', 'desc', 'statistics', 'author', 'video_url', 'cover_url']:
            if field in video and video[field]:
                field_stats[field] += 1

    for field, count in field_stats.items():
        percentage = (count / total_videos) * 100
        status = "âœ…" if percentage > 95 else "âš ï¸" if percentage > 80 else "âŒ"
        print("25")

    print()

    # 3. åˆ†æç»Ÿè®¡æ•°æ®
    print("ğŸ“ˆ ç»Ÿè®¡æ•°æ®å­—æ®µåˆ†æ:")
    print("-" * 40)

    stat_fields = [
        'digg_count', 'comment_count', 'share_count', 'collect_count',
        'play_count', 'forward_count', 'admire_count', 'download_count',
        'exposure_count', 'live_watch_count', 'lose_count', 'lose_comment_count'
    ]

    stat_stats = defaultdict(lambda: {'present': 0, 'zero': 0, 'non_zero': 0, 'values': []})

    for video in videos:
        stats = video.get('statistics', {})
        for field in stat_fields:
            value = stats.get(field, 0)
            if field in stats:
                stat_stats[field]['present'] += 1
                if value == 0:
                    stat_stats[field]['zero'] += 1
                else:
                    stat_stats[field]['non_zero'] += 1
                    stat_stats[field]['values'].append(value)

    for field in stat_fields:
        if stat_stats[field]['present'] > 0:
            present_pct = (stat_stats[field]['present'] / total_videos) * 100
            zero_pct = (stat_stats[field]['zero'] / stat_stats[field]['present']) * 100 if stat_stats[field]['present'] > 0 else 0
            non_zero_count = stat_stats[field]['non_zero']
            values = stat_stats[field]['values']

            status = "âœ…" if present_pct > 95 else "âš ï¸" if present_pct > 80 else "âŒ"

            print("30")
            if non_zero_count > 0:
                print("20")
            print()

    # 4. åˆ†æä½œè€…ä¿¡æ¯
    print("ğŸ‘¤ ä½œè€…ä¿¡æ¯åˆ†æ:")
    print("-" * 40)

    author_uids = []
    author_nicknames = []
    unique_authors = set()

    for video in videos:
        author = video.get('author', {})
        if isinstance(author, dict):
            uid = author.get('uid')
            nickname = author.get('nickname')
            if uid:
                author_uids.append(uid)
            if nickname:
                author_nicknames.append(nickname)
                unique_authors.add((uid, nickname))
        elif isinstance(author, str):
            # æœ‰äº›æ•°æ®ä¸­ author æ˜¯å­—ç¬¦ä¸²
            author_nicknames.append(author)
            unique_authors.add((None, author))

    print(f"ä½œè€… UID æ•°é‡: {len([x for x in author_uids if x])}")
    print(f"ä½œè€…æ˜µç§°æ•°é‡: {len(author_nicknames)}")
    print(f"å”¯ä¸€ä½œè€…æ•°: {len(unique_authors)}")
    print()

    # 5. åˆ†æè§†é¢‘æè¿°
    print("ğŸ“ è§†é¢‘æè¿°åˆ†æ:")
    print("-" * 40)

    desc_lengths = []
    has_hashtags = 0
    has_at_mentions = 0

    for video in videos:
        desc = video.get('desc', '')
        if desc:
            desc_lengths.append(len(desc))
            if '#' in desc:
                has_hashtags += 1
            if '@' in desc:
                has_at_mentions += 1

    if desc_lengths:
        print("20")
        print(f"æœ‰è¯é¢˜æ ‡ç­¾çš„è§†é¢‘: {has_hashtags} ({has_hashtags/len(videos)*100:.1f}%)")
        print(f"æœ‰@æåŠçš„è§†é¢‘: {has_at_mentions} ({has_at_mentions/len(videos)*100:.1f}%)")
    print()

    # 6. åˆ†æè§†é¢‘æ—¶é•¿ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    print("â±ï¸  è§†é¢‘æ—¶é•¿åˆ†æ:")
    print("-" * 40)

    durations = []
    for video in videos:
        raw_data = video.get('raw_video_data', {})
        duration = raw_data.get('duration')
        if duration:
            durations.append(duration / 1000)  # è½¬æ¢ä¸ºç§’

    if durations:
        print("20")
        print(f"æ—¶é•¿åˆ†å¸ƒ: å¹³å‡ {sum(durations)/len(durations):.1f}ç§’, èŒƒå›´ {min(durations):.1f}-{max(durations):.1f}ç§’")

        # æ—¶é•¿åˆ†å¸ƒç»Ÿè®¡
        duration_ranges = {
            '< 15ç§’': len([d for d in durations if d < 15]),
            '15-30ç§’': len([d for d in durations if 15 <= d < 30]),
            '30-60ç§’': len([d for d in durations if 30 <= d < 60]),
            '1-3åˆ†é’Ÿ': len([d for d in durations if 60 <= d < 180]),
            '> 3åˆ†é’Ÿ': len([d for d in durations if d >= 180])
        }

        print("æ—¶é•¿åˆ†å¸ƒ:")
        for range_name, count in duration_ranges.items():
            pct = (count / len(durations)) * 100
            print("15")
    print()

    # 7. åˆ†æäº’åŠ¨æ•ˆç‡æŒ‡æ ‡
    print("ğŸ“Š äº’åŠ¨æ•ˆç‡æŒ‡æ ‡é¢„è§ˆ:")
    print("-" * 40)

    # è®¡ç®—èµè¯„æ¯”ç­‰æŒ‡æ ‡
    interaction_metrics = []

    for video in videos:
        stats = video.get('statistics', {})
        digg = stats.get('digg_count', 0)
        comment = stats.get('comment_count', 0)
        share = stats.get('share_count', 0)
        collect = stats.get('collect_count', 0)

        if digg > 0:  # é¿å…é™¤é›¶
            like_comment_ratio = digg / comment if comment > 0 else digg
            engagement_rate = (comment + share + collect) / digg if digg > 0 else 0

            interaction_metrics.append({
                'digg': digg,
                'comment': comment,
                'share': share,
                'collect': collect,
                'like_comment_ratio': like_comment_ratio,
                'engagement_rate': engagement_rate
            })

    if interaction_metrics:
        # ç»Ÿè®¡èµè¯„æ¯”åˆ†å¸ƒ
        like_comment_ratios = [m['like_comment_ratio'] for m in interaction_metrics]

        print("25")
        print(f"èµè¯„æ¯”åˆ†å¸ƒ: å¹³å‡ {sum(like_comment_ratios)/len(like_comment_ratios):.1f}")

        # èµè¯„æ¯”åŒºé—´ç»Ÿè®¡
        ratio_ranges = {
            '< 10': len([r for r in like_comment_ratios if r < 10]),
            '10-50': len([r for r in like_comment_ratios if 10 <= r < 50]),
            '50-100': len([r for r in like_comment_ratios if 50 <= r < 100]),
            '100-500': len([r for r in like_comment_ratios if 100 <= r < 500]),
            '> 500': len([r for r in like_comment_ratios if r >= 500])
        }

        print("èµè¯„æ¯”åˆ†å¸ƒ:")
        for range_name, count in ratio_ranges.items():
            pct = (count / len(like_comment_ratios)) * 100
            print("15")

    # 8. ä¿å­˜åˆ†ææŠ¥å‘Š
    analysis_report = {
        'summary': {
            'total_videos': total_videos,
            'unique_authors': len(unique_authors),
            'data_completeness': {field: count/total_videos*100 for field, count in field_stats.items()},
            'statistics_fields': {field: stat_stats[field]['present']/total_videos*100 for field in stat_fields},
            'interaction_metrics_count': len(interaction_metrics)
        },
        'field_details': dict(field_stats),
        'statistics_details': dict(stat_stats),
        'author_distribution': {
            'uids_count': len([x for x in author_uids if x]),
            'nicknames_count': len(author_nicknames),
            'unique_authors': len(unique_authors)
        },
        'content_analysis': {
            'avg_desc_length': sum(desc_lengths)/len(desc_lengths) if desc_lengths else 0,
            'hashtags_ratio': has_hashtags/total_videos*100 if total_videos else 0,
            'mentions_ratio': has_at_mentions/total_videos*100 if total_videos else 0
        }
    }

    report_file = output_dir / "data_quality_analysis.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    print("=" * 60)
    print("âœ… æ•°æ®è´¨é‡åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    analyze_video_data_quality()

