#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆè¾¾äººè§†é¢‘æ•°æ®ä¸“ä¸šåˆ†ææŠ¥å‘Š

ç»“åˆ kol_video_ids.json (ç±»å‹æ˜ å°„) å’Œ final_video_details.json (è¯¦ç»†æ•°æ®)ï¼Œ
ç”Ÿæˆé’ˆå¯¹ 3 ç±»è§†é¢‘ï¼ˆçƒ­é—¨ã€æœ€æ–°ã€çˆ†æ¬¾ï¼‰çš„å¯¹æ¯”åˆ†æï¼Œä»¥åŠ 251 ä½è¾¾äººçš„ç»¼åˆèƒ½åŠ›è¯„ä¼°æŠ¥å‘Šã€‚
"""

import json
import os
from pathlib import Path
from collections import defaultdict
import statistics
# import pandas as pd

def generate_professional_report():
    """ç”Ÿæˆä¸“ä¸šåˆ†ææŠ¥å‘Š"""
    
    base_dir = Path(__file__).parent.parent / "kol-video-fetcher" / "output"
    ids_file = Path(__file__).parent.parent / "kol-video-fetcher" / "output" / "kol_video_ids.json"
    details_file = base_dir / "final_video_details.json"
    
    if not ids_file.exists() or not details_file.exists():
        print("âŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶")
        return

    print("ğŸ“Š å¼€å§‹ç”Ÿæˆä¸“ä¸šè¾¾äººè§†é¢‘æ•°æ®æŠ¥å‘Š...")
    print("=" * 60)

    # 1. åŠ è½½æ•°æ®
    with open(ids_file, 'r', encoding='utf-8') as f:
        kol_structure = json.load(f)  # List of {kol_id, videos: {masterpiece: id, ...}}
        
    with open(details_file, 'r', encoding='utf-8') as f:
        video_details_list = json.load(f)
        
    # å»ºç«‹è§†é¢‘IDåˆ°è¯¦æƒ…çš„æ˜ å°„
    video_map = {v['aweme_id']: v for v in video_details_list if v.get('aweme_id')}
    
    print(f"ğŸ“š åŠ è½½ KOL ç»“æ„: {len(kol_structure)} ä½")
    print(f"ğŸ¥ åŠ è½½è§†é¢‘è¯¦æƒ…: {len(video_map)} ä¸ª")
    print()

    # 2. æ•´åˆæ•°æ® (æŒ‰ç±»å‹)
    type_stats = defaultdict(list)
    kol_stats = {} # kol_id -> {type: stats}
    
    valid_kols = []
    
    for kol in kol_structure:
        kol_id = kol['kol_id']
        kol_name = kol.get('kol_name', 'Unknown')
        
        # æ”¶é›†è¯¥è¾¾äººçš„è§†é¢‘æ•°æ®
        kol_video_data = {}
        valid_videos_count = 0
        
        for v_type, vid in kol['videos'].items():
            if not vid: continue
            
            details = video_map.get(vid)
            if not details: continue
            
            stats = details.get('statistics', {})
            digg = stats.get('digg_count', 0)
            comment = stats.get('comment_count', 0)
            share = stats.get('share_count', 0)
            collect = stats.get('collect_count', 0)
            
            # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
            safe_digg = max(digg, 1)
            safe_comment = max(comment, 1)
            
            metrics = {
                'digg': digg,
                'comment': comment,
                'share': share,
                'collect': collect,
                'interaction_rate': (comment + share + collect) / safe_digg,
                'like_comment_ratio': digg / safe_comment,
                'engagement_score': (digg + comment*2 + share*3 + collect*2) # ç®€å•åŠ æƒåˆ†
            }
            
            type_stats[v_type].append(metrics)
            kol_video_data[v_type] = metrics
            valid_videos_count += 1
            
        if valid_videos_count > 0:
            # è®¡ç®—è¾¾äººç»¼åˆæŒ‡æ ‡
            total_digg = sum(d['digg'] for d in kol_video_data.values())
            avg_digg = total_digg / valid_videos_count
            
            # ç»¼åˆäº’åŠ¨ç‡
            avg_interaction_rate = sum(d['interaction_rate'] for d in kol_video_data.values()) / valid_videos_count
            
            # ç»¼åˆèµè¯„æ¯”
            avg_ratio = sum(d['like_comment_ratio'] for d in kol_video_data.values()) / valid_videos_count
            
            kol_stats[kol_id] = {
                'name': kol_name,
                'video_count': valid_videos_count,
                'avg_digg': avg_digg,
                'avg_interaction_rate': avg_interaction_rate,
                'avg_ratio': avg_ratio,
                'details': kol_video_data
            }
            valid_kols.append(kol_stats[kol_id])

    print(f"âœ… æœ‰æ•ˆåˆ†æè¾¾äºº: {len(valid_kols)} ä½")
    print()

    # 3. è¾“å‡ºæŠ¥å‘Šï¼šè§†é¢‘ç±»å‹å¯¹æ¯”
    print("ğŸ“‘ ç¬¬ä¸€éƒ¨åˆ†ï¼šè§†é¢‘ç±»å‹æ•°æ®è¡¨ç°å¯¹æ¯”")
    print("-" * 60)
    print(f"{'ç±»å‹':<12} | {'å¹³å‡ç‚¹èµ':<10} | {'å¹³å‡äº’åŠ¨ç‡':<10} | {'å¹³å‡èµè¯„æ¯”':<10} | {'æ ·æœ¬æ•°':<6}")
    print("-" * 60)
    
    type_mapping = {
        'masterpiece': 'çˆ†æ¬¾è§†é¢‘ (Tag 3)',
        'hot': 'çƒ­é—¨è§†é¢‘ (Tag 5)',
        'newest': 'æœ€æ–°è§†é¢‘ (Tag 6)'
    }
    
    for v_type in ['masterpiece', 'hot', 'newest']:
        stats_list = type_stats.get(v_type, [])
        if not stats_list: continue
        
        avg_digg = statistics.mean([s['digg'] for s in stats_list])
        avg_int_rate = statistics.mean([s['interaction_rate'] for s in stats_list])
        avg_ratio = statistics.mean([s['like_comment_ratio'] for s in stats_list])
        
        type_name = type_mapping.get(v_type, v_type)
        print(f"{type_name:<12} | {avg_digg:<10.1f} | {avg_int_rate:<10.4f} | {avg_ratio:<10.1f} | {len(stats_list):<6}")
    print()
    
    # 4. è¾“å‡ºæŠ¥å‘Šï¼šè¾¾äººåˆ†å¸ƒæƒ…å†µ
    print("ğŸ“‘ ç¬¬äºŒéƒ¨åˆ†ï¼š251ä½è¾¾äººåˆ†å¸ƒæƒ…å†µè¯„ä¼°")
    print("-" * 60)
    
    # æŒ‰å¹³å‡ç‚¹èµåˆ†å¸ƒ (é‡çº§)
    digg_levels = {
        'å¤´éƒ¨ (>1ä¸‡èµ)': len([k for k in valid_kols if k['avg_digg'] > 10000]),
        'è…°éƒ¨ (1åƒ-1ä¸‡)': len([k for k in valid_kols if 1000 <= k['avg_digg'] <= 10000]),
        'å°¾éƒ¨ (1ç™¾-1åƒ)': len([k for k in valid_kols if 100 <= k['avg_digg'] < 1000]),
        'èµ·æ­¥ (<100èµ)': len([k for k in valid_kols if k['avg_digg'] < 100])
    }
    
    print("1. æµé‡å±‚çº§åˆ†å¸ƒ (åŸºäºå¹³å‡ç‚¹èµ):")
    for level, count in digg_levels.items():
        print(f"   - {level}: {count} äºº ({count/len(valid_kols)*100:.1f}%)")
    print()
    
    # æŒ‰äº’åŠ¨è´¨é‡åˆ†å¸ƒ (äº’åŠ¨ç‡)
    int_levels = {
        'Sçº§äº’åŠ¨ (>10%)': len([k for k in valid_kols if k['avg_interaction_rate'] > 0.1]),
        'Açº§äº’åŠ¨ (5%-10%)': len([k for k in valid_kols if 0.05 <= k['avg_interaction_rate'] <= 0.1]),
        'Bçº§äº’åŠ¨ (1%-5%)': len([k for k in valid_kols if 0.01 <= k['avg_interaction_rate'] < 0.05]),
        'Cçº§äº’åŠ¨ (<1%)': len([k for k in valid_kols if k['avg_interaction_rate'] < 0.01])
    }
    
    print("2. äº’åŠ¨è´¨é‡åˆ†å¸ƒ (åŸºäºäº’åŠ¨ç‡):")
    for level, count in int_levels.items():
        print(f"   - {level}: {count} äºº ({count/len(valid_kols)*100:.1f}%)")
    print()
    
    # 5. ç»¼åˆè¯„ä¼°çŸ©é˜µ
    print("ğŸ“‘ ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¼˜è´¨è¾¾äººæ½œåŠ›è¯„ä¼°çŸ©é˜µ")
    print("-" * 60)
    
    # ç­›é€‰å‡º "åŒé«˜" è¾¾äºº (ç‚¹èµ > 1000 ä¸” äº’åŠ¨ç‡ > 5%)
    high_potential = [
        k for k in valid_kols 
        if k['avg_digg'] > 1000 and k['avg_interaction_rate'] > 0.05
    ]
    
    print(f"ğŸ’ æ½œåŠ›å¸¦è´§è¾¾äºº (ç‚¹èµ>1k & äº’åŠ¨>5%): å…± {len(high_potential)} äºº")
    
    # è¾“å‡ºå‰5å
    high_potential.sort(key=lambda x: x['avg_interaction_rate'], reverse=True)
    
    print(f"\n{'è¾¾äººåç§°':<20} | {'å¹³å‡ç‚¹èµ':<8} | {'äº’åŠ¨ç‡':<8} | {'èµè¯„æ¯”':<8}")
    print("-" * 60)
    for k in high_potential[:10]:
        name = k['name'][:18] + ".." if len(k['name']) > 18 else k['name']
        print(f"{name:<20} | {k['avg_digg']:<8.0f} | {k['avg_interaction_rate']:<8.4f} | {k['avg_ratio']:<8.1f}")
        
    print("-" * 60)
    print("\nğŸ’¡ è¯„ä¼°ç»“è®º:")
    print("1. çˆ†æ¬¾è§†é¢‘ (Masterpiece) é€šå¸¸å…·æœ‰æé«˜çš„äº’åŠ¨ç‡ï¼Œæ˜¯æ‹‰åŠ¨è¾¾äººæ•´ä½“æ•°æ®çš„å…³é”®ã€‚")
    print("2. çƒ­é—¨è§†é¢‘ (Hot) ä»£è¡¨äº†è¾¾äººè¿‘æœŸçš„æµé‡è¡¨ç°ï¼Œæ›´æ¥è¿‘çœŸå®å¸¦è´§æ—¶çš„é¢„æœŸæµé‡ã€‚")
    print("3. æœ€æ–°è§†é¢‘ (Newest) åæ˜ äº†è¾¾äººçš„æ´»è·ƒåº¦å’Œå½“å‰è´¦å·çŠ¶æ€ã€‚")
    print(f"4. åœ¨è¿™ {len(valid_kols)} ä½è¾¾äººä¸­ï¼Œçº¦ {digg_levels['è…°éƒ¨ (1åƒ-1ä¸‡)']} ä½å¤„äºè…°éƒ¨æµé‡å±‚çº§ï¼Œé…åˆ {int_levels['Açº§äº’åŠ¨ (5%-10%)']} ä½é«˜äº’åŠ¨è¾¾äººï¼Œæ˜¯æ€§ä»·æ¯”æœ€é«˜çš„å¸¦è´§äººé€‰ã€‚")

    # ä¿å­˜æŠ¥å‘Š
    report_data = {
        'type_comparison': {
            k: {
                'avg_digg': statistics.mean([s['digg'] for s in v]),
                'avg_interaction_rate': statistics.mean([s['interaction_rate'] for s in v]),
                'count': len(v)
            } for k, v in type_stats.items() if v
        },
        'distribution': {
            'digg_levels': digg_levels,
            'interaction_levels': int_levels
        },
        'high_potential_kols': high_potential
    }
    
    json_file = base_dir / "professional_kol_report.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
        
    print(f"\nğŸ’¾ å®Œæ•´æ•°æ®æŠ¥å‘Šå·²ä¿å­˜: {json_file}")

if __name__ == "__main__":
    generate_professional_report()

