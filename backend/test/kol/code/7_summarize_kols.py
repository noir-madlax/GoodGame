#!/usr/bin/env python3
"""
è„šæœ¬åç§°: 7_summarize_kols.py
åŠŸèƒ½æè¿°: æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœï¼Œç”ŸæˆæŠ¤è‚¤è¾¾äººåˆ—è¡¨
è¾“å…¥: ../output/file/{aweme_id}/analysis.json
è¾“å‡º: ../output/7_kol_summary_{timestamp}.json å’Œ 7_kol_list_{timestamp}.md
"""

import json
import time
from pathlib import Path
from typing import List, Dict
from collections import defaultdict


def load_all_analyses() -> List[dict]:
    """åŠ è½½æ‰€æœ‰åˆ†æç»“æœ
    
    è¿”å›:
        æ‰€æœ‰åˆ†æç»“æœçš„åˆ—è¡¨
    """
    output_dir = Path(__file__).resolve().parent.parent / "output" / "file"
    
    if not output_dir.exists():
        raise RuntimeError("åª’ä½“æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
    
    analyses = []
    
    for aweme_dir in output_dir.iterdir():
        if not aweme_dir.is_dir():
            continue
        
        analysis_file = aweme_dir / "analysis.json"
        if not analysis_file.exists():
            continue
        
        try:
            with open(analysis_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                analyses.append(data)
        except Exception as e:
            print(f"è¯»å– {analysis_file} å¤±è´¥: {e}")
            continue
    
    return analyses


def extract_kols_from_analyses(analyses: List[dict]) -> List[dict]:
    """ä»åˆ†æç»“æœä¸­æå–æ‰€æœ‰è¾¾äººä¿¡æ¯
    
    å‚æ•°:
        analyses: åˆ†æç»“æœåˆ—è¡¨
        
    è¿”å›:
        æ‰€æœ‰è¾¾äººä¿¡æ¯çš„åˆ—è¡¨
    """
    all_kols = []
    
    for analysis in analyses:
        aweme_id = analysis.get("aweme_id")
        desc = analysis.get("desc", "")
        analysis_data = analysis.get("analysis", {})
        
        kols_mentioned = analysis_data.get("kols_mentioned", [])
        
        for kol in kols_mentioned:
            # æ·»åŠ æ¥æºä¿¡æ¯
            kol_with_source = kol.copy()
            kol_with_source["source_aweme_id"] = aweme_id
            kol_with_source["source_desc"] = desc[:200]  # æˆªå–å‰200ä¸ªå­—ç¬¦
            all_kols.append(kol_with_source)
    
    return all_kols


def merge_duplicate_kols(kols: List[dict]) -> List[dict]:
    """åˆå¹¶é‡å¤çš„è¾¾äººï¼ˆåŸºäºåç§°ï¼‰
    
    å‚æ•°:
        kols: è¾¾äººåˆ—è¡¨
        
    è¿”å›:
        åˆå¹¶åçš„è¾¾äººåˆ—è¡¨
    """
    # æŒ‰åç§°åˆ†ç»„
    kol_groups = defaultdict(list)
    
    for kol in kols:
        name = kol.get("name", "").strip()
        if name:
            kol_groups[name].append(kol)
    
    # åˆå¹¶åŒåè¾¾äºº
    merged_kols = []
    
    for name, group in kol_groups.items():
        if len(group) == 1:
            merged_kols.append(group[0])
        else:
            # åˆå¹¶å¤šä¸ªè®°å½•
            merged = {
                "name": name,
                "mention_count": len(group),
                "platforms": list(set(kol.get("platform", "") for kol in group if kol.get("platform"))),
                "professional_backgrounds": list(set(kol.get("professional_background", "") for kol in group if kol.get("professional_background"))),
                "characteristics": list(set(char for kol in group for char in kol.get("characteristics", []))),
                "account_ids": list(set(kol.get("account_id", "") for kol in group if kol.get("account_id"))),
                "follower_counts": list(set(kol.get("follower_count", "") for kol in group if kol.get("follower_count"))),
                "ranking_positions": list(set(kol.get("ranking_position", "") for kol in group if kol.get("ranking_position"))),
                "mention_contexts": [kol.get("mention_context", "") for kol in group],
                "confidence_levels": [kol.get("confidence", "medium") for kol in group],
                "sources": [{"aweme_id": kol.get("source_aweme_id"), "desc": kol.get("source_desc")} for kol in group],
            }
            merged_kols.append(merged)
    
    # æŒ‰æåŠæ¬¡æ•°æ’åº
    merged_kols.sort(key=lambda x: x.get("mention_count", 1), reverse=True)
    
    return merged_kols


def generate_markdown_report(kols: List[dict], output_path: Path) -> None:
    """ç”ŸæˆMarkdownæ ¼å¼çš„è¾¾äººåˆ—è¡¨æŠ¥å‘Š
    
    å‚æ•°:
        kols: è¾¾äººåˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    lines = []
    
    lines.append("# æŠ–éŸ³æŠ¤è‚¤è¾¾äººè°ƒç ”æ±‡æ€»")
    lines.append("")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    lines.append("## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    lines.append("")
    lines.append(f"- **è¯†åˆ«åˆ°çš„è¾¾äººæ€»æ•°**: {len(kols)} ä½")
    
    high_confidence = sum(1 for kol in kols if "high" in kol.get("confidence_levels", []))
    medium_confidence = sum(1 for kol in kols if "medium" in kol.get("confidence_levels", []))
    
    lines.append(f"- **é«˜ç½®ä¿¡åº¦è¾¾äºº**: {high_confidence} ä½")
    lines.append(f"- **ä¸­ç½®ä¿¡åº¦è¾¾äºº**: {medium_confidence} ä½")
    lines.append("")
    
    # è¾¾äººåˆ—è¡¨
    lines.append("## ğŸ‘¤ æŠ¤è‚¤è¾¾äººè¯¦ç»†åˆ—è¡¨")
    lines.append("")
    
    for idx, kol in enumerate(kols, 1):
        lines.append(f"### {idx}. {kol['name']}")
        lines.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        if isinstance(kol.get("mention_count"), int) and kol.get("mention_count") > 1:
            lines.append(f"**æåŠæ¬¡æ•°**: {kol['mention_count']} æ¬¡")
            lines.append("")
        
        if kol.get("platforms"):
            platforms = [p for p in kol["platforms"] if p]
            if platforms:
                lines.append(f"**å¹³å°**: {', '.join(platforms)}")
                lines.append("")
        
        if kol.get("professional_backgrounds"):
            backgrounds = [b for b in kol["professional_backgrounds"] if b]
            if backgrounds:
                lines.append(f"**ä¸“ä¸šèƒŒæ™¯**: {', '.join(backgrounds)}")
                lines.append("")
        
        if kol.get("characteristics"):
            chars = [c for c in kol["characteristics"] if c]
            if chars:
                lines.append(f"**ç‰¹ç‚¹æ ‡ç­¾**: {', '.join(chars)}")
                lines.append("")
        
        if kol.get("account_ids"):
            ids = [i for i in kol["account_ids"] if i]
            if ids:
                lines.append(f"**è´¦å·ID**: {', '.join(ids)}")
                lines.append("")
        
        if kol.get("follower_counts"):
            counts = [c for c in kol["follower_counts"] if c]
            if counts:
                lines.append(f"**ç²‰ä¸æ•°**: {', '.join(counts)}")
                lines.append("")
        
        if kol.get("ranking_positions"):
            positions = [p for p in kol["ranking_positions"] if p]
            if positions:
                lines.append(f"**æ’åä½ç½®**: {', '.join(positions)}")
                lines.append("")
        
        # æåŠæ–¹å¼
        if "mention_contexts" in kol:
            contexts = [c for c in kol["mention_contexts"] if c]
            if contexts:
                lines.append("**æåŠæ–¹å¼**:")
                for context in contexts[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                    lines.append(f"- {context}")
                lines.append("")
        elif "mention_context" in kol:
            if kol["mention_context"]:
                lines.append(f"**æåŠæ–¹å¼**: {kol['mention_context']}")
                lines.append("")
        
        # ç½®ä¿¡åº¦
        if "confidence_levels" in kol:
            confidences = list(set(kol["confidence_levels"]))
            lines.append(f"**ç½®ä¿¡åº¦**: {', '.join(confidences)}")
        elif "confidence" in kol:
            lines.append(f"**ç½®ä¿¡åº¦**: {kol['confidence']}")
        
        lines.append("")
        lines.append("---")
        lines.append("")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))


def main() -> None:
    print("=" * 80)
    print("æŠ¤è‚¤è¾¾äººä¿¡æ¯æ±‡æ€»è„šæœ¬")
    print("=" * 80)
    
    # åŠ è½½æ‰€æœ‰åˆ†æç»“æœ
    print("\n[1/5] åŠ è½½åˆ†æç»“æœ...")
    analyses = load_all_analyses()
    print(f"âœ“ åŠ è½½äº† {len(analyses)} ä¸ªåˆ†æç»“æœ")
    
    # æå–è¾¾äººä¿¡æ¯
    print("\n[2/5] æå–è¾¾äººä¿¡æ¯...")
    all_kols = extract_kols_from_analyses(analyses)
    print(f"âœ“ æå–åˆ° {len(all_kols)} æ¡è¾¾äººè®°å½•")
    
    # åˆå¹¶é‡å¤è¾¾äºº
    print("\n[3/5] åˆå¹¶é‡å¤è¾¾äºº...")
    merged_kols = merge_duplicate_kols(all_kols)
    print(f"âœ“ åˆå¹¶åå‰©ä½™ {len(merged_kols)} ä½å”¯ä¸€è¾¾äºº")
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
    print("\n[4/5] ç”Ÿæˆè¾“å‡ºæ–‡ä»¶...")
    output_dir = Path(__file__).resolve().parent.parent / "output"
    stamp = time.strftime("%Y%m%d-%H%M%S")
    
    # JSONæ ¼å¼
    json_file = output_dir / f"7_kol_summary_{stamp}.json"
    summary_data = {
        "generated_at": stamp,
        "total_kols": len(merged_kols),
        "total_mentions": len(all_kols),
        "kols": merged_kols
    }
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ JSONæ–‡ä»¶å·²ä¿å­˜: {json_file}")
    
    # Markdownæ ¼å¼
    md_file = output_dir / f"7_kol_list_{stamp}.md"
    generate_markdown_report(merged_kols, md_file)
    print(f"âœ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {md_file}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n[5/5] æ±‡æ€»å®Œæˆ")
    print("\n" + "=" * 80)
    print("ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)
    print(f"åˆ†æçš„å¸–å­æ•°: {len(analyses)}")
    print(f"åŸå§‹è¾¾äººè®°å½•: {len(all_kols)}")
    print(f"å”¯ä¸€è¾¾äººæ•°é‡: {len(merged_kols)}")
    
    # æ˜¾ç¤ºTOP 10è¾¾äºº
    print("\n" + "=" * 80)
    print("TOP 10 æŠ¤è‚¤è¾¾äººï¼ˆæŒ‰æåŠæ¬¡æ•°ï¼‰")
    print("=" * 80)
    
    for idx, kol in enumerate(merged_kols[:10], 1):
        name = kol["name"]
        count = kol.get("mention_count", 1)
        background = kol.get("professional_backgrounds", [""])[0] if kol.get("professional_backgrounds") else ""
        
        print(f"{idx}. {name} (æåŠ{count}æ¬¡) {f'- {background}' if background else ''}")


if __name__ == "__main__":
    main()

