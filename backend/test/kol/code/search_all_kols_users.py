#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æœç´¢å…¨éƒ¨64ä¸ªè¾¾äººçš„æŠ–éŸ³è´¦å·ä¿¡æ¯
ä½¿ç”¨ fetch_hot_account_search_list æ¥å£
å¹¶å®ç°æ™ºèƒ½ç­›é€‰é€»è¾‘ï¼Œæ‰¾å‡ºçœŸæ­£çš„è¾¾äººä¸»è´¦å·

ç­›é€‰ç­–ç•¥ï¼š
1. æ˜µç§°åŒ¹é…åº¦ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
2. ç²‰ä¸æ•°ï¼ˆè¶Šå¤šè¶Šå¯èƒ½æ˜¯ä¸»è´¦å·ï¼‰
3. ä½œå“æ•°ï¼ˆæ´»è·ƒåº¦ï¼‰
4. ç‚¹èµæ•°ï¼ˆå½±å“åŠ›ï¼‰
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import time
from difflib import SequenceMatcher


def load_api_key():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½TikHub API Key"""
    backend_dir = Path(__file__).parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError(f"ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    return api_key


def load_kol_data(json_path: str) -> list:
    """åŠ è½½è¾¾äººæ•°æ®"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    kols = data.get('kols_ranking', [])
    print(f"âœ… åŠ è½½äº† {len(kols)} ä¸ªè¾¾äººæ•°æ®")
    
    return kols


def calculate_name_similarity(name1: str, name2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªåå­—çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰
    
    Args:
        name1: åŸå§‹è¾¾äººåå­—
        name2: æœç´¢ç»“æœä¸­çš„æ˜µç§°
        
    Returns:
        ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
    """
    # å»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    name1_clean = name1.strip().lower()
    name2_clean = name2.strip().lower()
    
    # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
    similarity = SequenceMatcher(None, name1_clean, name2_clean).ratio()
    
    return similarity


def select_best_match(kol_name: str, user_list: list) -> dict:
    """
    ä»å¤šä¸ªåŒ¹é…è´¦å·ä¸­é€‰æ‹©æœ€ä½³åŒ¹é…ï¼ˆçœŸæ­£çš„è¾¾äººè´¦å·ï¼‰
    
    ç­›é€‰ç­–ç•¥ï¼š
    1. æ˜µç§°åŒ¹é…åº¦ï¼ˆæƒé‡40%ï¼‰- å®Œå…¨åŒ¹é…æˆ–é«˜åº¦ç›¸ä¼¼
    2. ç²‰ä¸æ•°ï¼ˆæƒé‡30%ï¼‰- ç²‰ä¸è¶Šå¤šï¼Œå½±å“åŠ›è¶Šå¤§
    3. ç‚¹èµæ•°ï¼ˆæƒé‡20%ï¼‰- æ€»ç‚¹èµæ•°åæ˜ å—æ¬¢è¿ç¨‹åº¦
    4. ä½œå“æ•°ï¼ˆæƒé‡10%ï¼‰- æ´»è·ƒåº¦æŒ‡æ ‡
    
    Args:
        kol_name: åŸå§‹è¾¾äººåå­—
        user_list: æœç´¢è¿”å›çš„ç”¨æˆ·åˆ—è¡¨
        
    Returns:
        æœ€ä½³åŒ¹é…çš„ç”¨æˆ·ä¿¡æ¯ï¼ˆåŒ…å«è¯„åˆ†è¯¦æƒ…ï¼‰
    """
    if not user_list:
        return None
    
    # è®¡ç®—æ¯ä¸ªå€™é€‰è´¦å·çš„ç»¼åˆè¯„åˆ†
    scored_users = []
    
    # å…ˆæ‰¾å‡ºç²‰ä¸æ•°ã€ç‚¹èµæ•°ã€ä½œå“æ•°çš„æœ€å¤§å€¼ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
    max_fans = max([u.get('fans_cnt', 0) for u in user_list]) or 1
    max_likes = max([u.get('like_cnt', 0) for u in user_list]) or 1
    max_publish = max([u.get('publish_cnt', 0) for u in user_list]) or 1
    
    for user in user_list:
        nick_name = user.get('nick_name', '')
        fans_cnt = user.get('fans_cnt', 0)
        like_cnt = user.get('like_cnt', 0)
        publish_cnt = user.get('publish_cnt', 0)
        
        # 1. æ˜µç§°åŒ¹é…åº¦ï¼ˆ0-1ï¼‰
        name_similarity = calculate_name_similarity(kol_name, nick_name)
        
        # 2. ç²‰ä¸æ•°å½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
        fans_score = fans_cnt / max_fans
        
        # 3. ç‚¹èµæ•°å½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
        likes_score = like_cnt / max_likes
        
        # 4. ä½œå“æ•°å½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
        publish_score = publish_cnt / max_publish
        
        # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒï¼‰
        total_score = (
            name_similarity * 0.40 +  # æ˜µç§°åŒ¹é…åº¦40%
            fans_score * 0.30 +        # ç²‰ä¸æ•°30%
            likes_score * 0.20 +       # ç‚¹èµæ•°20%
            publish_score * 0.10       # ä½œå“æ•°10%
        )
        
        # ä¿å­˜è¯„åˆ†è¯¦æƒ…
        user_with_score = {
            **user,  # ä¿ç•™åŸå§‹ç”¨æˆ·ä¿¡æ¯
            'match_score': {
                'total': round(total_score, 4),
                'name_similarity': round(name_similarity, 4),
                'fans_score': round(fans_score, 4),
                'likes_score': round(likes_score, 4),
                'publish_score': round(publish_score, 4)
            }
        }
        
        scored_users.append(user_with_score)
    
    # æŒ‰æ€»åˆ†æ’åºï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„
    best_match = max(scored_users, key=lambda x: x['match_score']['total'])
    
    return best_match


def fetch_hot_account_search(api_key: str, keyword: str) -> dict:
    """è°ƒç”¨çƒ­é—¨è´¦å·æœç´¢æ¥å£"""
    base_url = "https://api.tikhub.io/api/v1"
    endpoint = "/douyin/billboard/fetch_hot_account_search_list"
    url = f"{base_url}{endpoint}"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'keyword': keyword,
        'cursor': 0
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": f"HTTP {response.status_code}",
                "message": response.text
            }
            
    except Exception as e:
        return {"error": str(e)}


def search_all_kols(kols: list, api_key: str):
    """
    æœç´¢æ‰€æœ‰è¾¾äººçš„æŠ–éŸ³è´¦å·
    
    Args:
        kols: è¾¾äººåˆ—è¡¨
        api_key: APIå¯†é’¥
        
    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    results = []
    total = len(kols)
    
    print(f"\n{'='*70}")
    print(f"ğŸ” å¼€å§‹æœç´¢å…¨éƒ¨ {total} ä¸ªè¾¾äººçš„æŠ–éŸ³è´¦å·")
    print(f"{'='*70}")
    
    # ç»Ÿè®¡æ•°æ®
    success_count = 0
    found_count = 0
    multi_match_count = 0
    
    for idx, kol in enumerate(kols, 1):
        name = kol.get('name', 'Unknown')
        rank = kol.get('rank', 0)
        mention_count = kol.get('mention_count', 0)
        
        print(f"\n[{idx}/{total}] æ’å#{rank} - {name}")
        print("-" * 70)
        
        # è°ƒç”¨æœç´¢æ¥å£
        search_result = fetch_hot_account_search(api_key, name)
        
        # å¤„ç†ç»“æœ
        result_entry = {
            "rank": rank,
            "name": name,
            "mention_count": mention_count,
            "platforms": kol.get('platforms', []),
            "characteristics": kol.get('characteristics', []),
            "professional_backgrounds": kol.get('professional_backgrounds', []),
            "search_timestamp": datetime.now().isoformat()
        }
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–æ•°æ®
        if isinstance(search_result, dict) and not search_result.get('error'):
            success_count += 1
            
            # æå–ç”¨æˆ·åˆ—è¡¨
            data_content = search_result.get('data', {})
            inner_data = data_content.get('data', {})
            user_list = inner_data.get('user_list', [])
            
            if user_list and len(user_list) > 0:
                found_count += 1
                
                print(f"   âœ… æ‰¾åˆ° {len(user_list)} ä¸ªåŒ¹é…è´¦å·")
                
                if len(user_list) > 1:
                    multi_match_count += 1
                
                # é€‰æ‹©æœ€ä½³åŒ¹é…
                best_match = select_best_match(name, user_list)
                
                if best_match:
                    match_score = best_match.get('match_score', {})
                    
                    print(f"   ğŸ¯ æœ€ä½³åŒ¹é…:")
                    print(f"      æ˜µç§°: {best_match.get('nick_name')}")
                    print(f"      ç²‰ä¸: {best_match.get('fans_cnt'):,}")
                    print(f"      ä½œå“: {best_match.get('publish_cnt')}")
                    print(f"      ç‚¹èµ: {best_match.get('like_cnt'):,}")
                    print(f"      user_id: {best_match.get('user_id')[:40]}...")
                    print(f"      åŒ¹é…åº¦: {match_score.get('total'):.2%} "
                          f"(æ˜µç§°:{match_score.get('name_similarity'):.2%} "
                          f"ç²‰ä¸:{match_score.get('fans_score'):.2%})")
                    
                    # ä¿å­˜æœ€ä½³åŒ¹é…ä¿¡æ¯
                    result_entry['best_match'] = {
                        'user_id': best_match.get('user_id'),
                        'nick_name': best_match.get('nick_name'),
                        'fans_cnt': best_match.get('fans_cnt'),
                        'like_cnt': best_match.get('like_cnt'),
                        'publish_cnt': best_match.get('publish_cnt'),
                        'avatar_url': best_match.get('avatar_url'),
                        'match_score': match_score
                    }
                    
                    # ä¿å­˜æ‰€æœ‰å€™é€‰è´¦å·ï¼ˆå‰5ä¸ªï¼‰
                    result_entry['all_candidates'] = user_list[:5]
                    result_entry['total_candidates'] = len(user_list)
                else:
                    print(f"   âš ï¸ æ— æ³•é€‰æ‹©æœ€ä½³åŒ¹é…")
                    result_entry['error'] = "æ— æ³•é€‰æ‹©æœ€ä½³åŒ¹é…"
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°åŒ¹é…è´¦å·")
                result_entry['error'] = "æœªæ‰¾åˆ°åŒ¹é…è´¦å·"
        else:
            print(f"   âŒ æœç´¢å¤±è´¥: {search_result.get('error', 'Unknown error')}")
            result_entry['error'] = search_result.get('error', 'Unknown error')
        
        results.append(result_entry)
        
        # æ¯10ä¸ªè¾“å‡ºä¸€æ¬¡è¿›åº¦
        if idx % 10 == 0:
            print(f"\nğŸ“Š è¿›åº¦: {idx}/{total} ({idx/total*100:.1f}%) - "
                  f"æˆåŠŸ:{found_count} å¤šåŒ¹é…:{multi_match_count}")
        
        # é¿å…è¯·æ±‚è¿‡å¿«ï¼Œæ¯ä¸ªè¯·æ±‚é—´éš”0.5ç§’
        if idx < total:
            time.sleep(0.5)
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æœç´¢å®Œæˆç»Ÿè®¡")
    print(f"{'='*70}")
    print(f"æ€»è®¡è¾¾äººæ•°: {total}")
    print(f"æˆåŠŸè·å–å“åº”: {success_count} ({success_count/total*100:.1f}%)")
    print(f"æ‰¾åˆ°åŒ¹é…è´¦å·: {found_count} ({found_count/total*100:.1f}%)")
    print(f"å¤šè´¦å·åŒ¹é…: {multi_match_count} ({multi_match_count/total*100:.1f}%)")
    print(f"å¹³å‡æ¯äººåŒ¹é…è´¦å·æ•°: {sum([r.get('total_candidates', 0) for r in results])/found_count:.1f}" if found_count > 0 else "N/A")
    
    return results


def generate_final_kol_accounts(results: list, output_path: str):
    """
    ç”Ÿæˆæœ€ç»ˆçš„è¾¾äººè´¦å·æ±‡æ€»JSON
    åªåŒ…å«æˆåŠŸæ‰¾åˆ°çš„çœŸå®è¾¾äººè´¦å·
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    final_kols = []
    
    for result in results:
        # åªåŒ…å«æˆåŠŸæ‰¾åˆ°æœ€ä½³åŒ¹é…çš„è¾¾äºº
        if 'best_match' in result:
            best_match = result['best_match']
            
            kol_account = {
                "rank": result['rank'],
                "name": result['name'],
                "mention_count": result['mention_count'],
                "platforms": result['platforms'],
                "characteristics": result['characteristics'],
                "professional_backgrounds": result['professional_backgrounds'],
                "douyin_account": {
                    "user_id": best_match['user_id'],
                    "sec_uid": best_match['user_id'],  # user_idå³ä¸ºsec_uid
                    "nick_name": best_match['nick_name'],
                    "fans_count": best_match['fans_cnt'],
                    "like_count": best_match['like_cnt'],
                    "publish_count": best_match['publish_cnt'],
                    "avatar_url": best_match['avatar_url'],
                    "match_quality": {
                        "score": best_match['match_score']['total'],
                        "name_similarity": best_match['match_score']['name_similarity'],
                        "confidence": "high" if best_match['match_score']['total'] > 0.7 else 
                                     "medium" if best_match['match_score']['total'] > 0.5 else "low"
                    }
                },
                "search_info": {
                    "total_candidates": result.get('total_candidates', 0),
                    "search_timestamp": result['search_timestamp']
                }
            }
            
            final_kols.append(kol_account)
    
    # å‡†å¤‡è¾“å‡ºæ•°æ®
    output_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "total_kols_searched": len(results),
            "total_kols_found": len(final_kols),
            "success_rate": f"{len(final_kols)/len(results)*100:.1f}%",
            "data_source": "TikHub API - fetch_hot_account_search_list",
            "match_strategy": "ç»¼åˆè¯„åˆ†ï¼ˆæ˜µç§°40% + ç²‰ä¸30% + ç‚¹èµ20% + ä½œå“10%ï¼‰"
        },
        "kol_accounts": final_kols
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æœ€ç»ˆè¾¾äººè´¦å·æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    print(f"   æˆåŠŸæ‰¾åˆ°: {len(final_kols)}/{len(results)} ä¸ªè¾¾äººçš„æŠ–éŸ³è´¦å·")
    
    return output_data


def save_detailed_results(results: list, output_dir: str):
    """ä¿å­˜è¯¦ç»†çš„æœç´¢ç»“æœï¼ˆåŒ…å«æ‰€æœ‰å€™é€‰è´¦å·ï¼‰"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = os.path.join(output_dir, f'all_kols_search_detailed_{timestamp}.json')
    
    output_data = {
        "search_metadata": {
            "search_date": datetime.now().isoformat(),
            "total_kols": len(results),
            "api_interface": "fetch_hot_account_search_list"
        },
        "detailed_results": results
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯¦ç»†æœç´¢ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return output_file


def analyze_match_patterns(results: list):
    """
    åˆ†æåŒ¹é…æ¨¡å¼ï¼Œå›ç­”ä¸ºä»€ä¹ˆæœ‰å¤šä¸ªåŒ¹é…è´¦å·
    """
    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ åŒ¹é…è´¦å·åˆ†æ")
    print(f"{'='*70}")
    
    # ç»Ÿè®¡åŒ¹é…æ•°é‡åˆ†å¸ƒ
    match_counts = [r.get('total_candidates', 0) for r in results if 'total_candidates' in r]
    
    if match_counts:
        print(f"\nåŒ¹é…è´¦å·æ•°é‡åˆ†å¸ƒ:")
        print(f"  å¹³å‡: {sum(match_counts)/len(match_counts):.1f} ä¸ª")
        print(f"  æœ€å¤š: {max(match_counts)} ä¸ª")
        print(f"  æœ€å°‘: {min(match_counts)} ä¸ª")
        
        # æŒ‰åŒ¹é…æ•°é‡åˆ†ç»„
        single_match = sum(1 for c in match_counts if c == 1)
        multi_match = sum(1 for c in match_counts if c > 1)
        
        print(f"\n  å•ä¸€åŒ¹é…: {single_match} ä¸ªè¾¾äºº ({single_match/len(match_counts)*100:.1f}%)")
        print(f"  å¤šä¸ªåŒ¹é…: {multi_match} ä¸ªè¾¾äºº ({multi_match/len(match_counts)*100:.1f}%)")
    
    print(f"\nğŸ’¡ å¤šè´¦å·åŒ¹é…çš„å¸¸è§åŸå› :")
    print(f"  1. åŒåè´¦å· - ä¸åŒäººä½¿ç”¨ç›¸ä¼¼æˆ–ç›¸åŒçš„æ˜µç§°")
    print(f"  2. åŒä¸€è¾¾äººçš„å¤šä¸ªè´¦å· - ä¸»å·ã€å°å·ã€åˆä½œå·ç­‰")
    print(f"  3. æ¨¡ä»¿è´¦å· - è¹­çƒ­åº¦çš„å±±å¯¨è´¦å·")
    print(f"  4. æ˜µç§°éƒ¨åˆ†åŒ¹é… - æœç´¢ç®—æ³•è¿”å›ç›¸å…³è´¦å·")
    
    print(f"\nğŸ¯ ç­›é€‰ç­–ç•¥:")
    print(f"  1. æ˜µç§°åŒ¹é…åº¦ï¼ˆ40%æƒé‡ï¼‰- å®Œå…¨åŒ¹é…æˆ–é«˜åº¦ç›¸ä¼¼çš„ä¼˜å…ˆ")
    print(f"  2. ç²‰ä¸æ•°ï¼ˆ30%æƒé‡ï¼‰- ç²‰ä¸è¶Šå¤šï¼Œè¶Šå¯èƒ½æ˜¯ä¸»è´¦å·")
    print(f"  3. ç‚¹èµæ•°ï¼ˆ20%æƒé‡ï¼‰- åæ˜ å†…å®¹å—æ¬¢è¿ç¨‹åº¦")
    print(f"  4. ä½œå“æ•°ï¼ˆ10%æƒé‡ï¼‰- æ´»è·ƒåº¦æŒ‡æ ‡")
    
    print(f"\nâœ… ç»“è®º:")
    print(f"  - é€šè¿‡ç»¼åˆè¯„åˆ†ï¼Œå¯ä»¥æœ‰æ•ˆç­›é€‰å‡ºçœŸæ­£çš„è¾¾äººä¸»è´¦å·")
    print(f"  - å¯¹äºé«˜åŒ¹é…åº¦ï¼ˆ>70%ï¼‰çš„ç»“æœï¼Œå¯ä¿¡åº¦å¾ˆé«˜")
    print(f"  - å¯¹äºä½åŒ¹é…åº¦ï¼ˆ<50%ï¼‰çš„ç»“æœï¼Œå»ºè®®äººå·¥å¤æ ¸")


def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 70)
    print("æŠ–éŸ³è¾¾äººè´¦å·æ‰¹é‡æœç´¢ - æ™ºèƒ½åŒ¹é…ç‰ˆæœ¬")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\n1ï¸âƒ£ åŠ è½½é…ç½®...")
    try:
        api_key = load_api_key()
        print(f"âœ… API Keyå·²åŠ è½½")
    except ValueError as e:
        print(f"âŒ {e}")
        return
    
    # 2. åŠ è½½è¾¾äººæ•°æ®
    print("\n2ï¸âƒ£ åŠ è½½è¾¾äººæ•°æ®...")
    script_dir = Path(__file__).parent.parent
    kol_data_path = script_dir / "output" / "final_kol_data_20251113-163615.json"
    
    if not kol_data_path.exists():
        print(f"âŒ è¾¾äººæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {kol_data_path}")
        return
    
    kols = load_kol_data(str(kol_data_path))
    
    # 3. æœç´¢æ‰€æœ‰è¾¾äºº
    print("\n3ï¸âƒ£ å¼€å§‹æ‰¹é‡æœç´¢...")
    results = search_all_kols(kols, api_key)
    
    # 4. åˆ†æåŒ¹é…æ¨¡å¼
    analyze_match_patterns(results)
    
    # 5. ä¿å­˜è¯¦ç»†ç»“æœ
    print("\n4ï¸âƒ£ ä¿å­˜ç»“æœ...")
    output_dir = script_dir / "output" / "kol_user_ids"
    save_detailed_results(results, str(output_dir))
    
    # 6. ç”Ÿæˆæœ€ç»ˆè¾¾äººè´¦å·æ±‡æ€»
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    final_output_path = output_dir / f"final_kol_accounts_{timestamp}.json"
    final_data = generate_final_kol_accounts(results, str(final_output_path))
    
    print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"   æ‰¾åˆ° {len(final_data['kol_accounts'])} ä¸ªçœŸå®è¾¾äººè´¦å·")


if __name__ == "__main__":
    main()

