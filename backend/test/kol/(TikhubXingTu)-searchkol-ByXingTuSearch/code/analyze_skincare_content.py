import os
import json
import time
import asyncio
import aiohttp
from typing import List, Dict
from supabase import create_client, Client
from math import ceil

# é…ç½®
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
# ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹ï¼Œå¦åˆ™é»˜è®¤ä¸º gpt-4o-mini
OPENROUTER_MODEL = os.getenv("OPENROUTER_MODEL", "openai/gpt-4o-mini")

if not all([SUPABASE_URL, SUPABASE_KEY, OPENROUTER_API_KEY]):
    print("âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (SUPABASE_URL, SUPABASE_KEY, OPENROUTER_API_KEY)")
    exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

async def analyze_titles_batch(session: aiohttp.ClientSession, titles_batch: List[Dict]) -> Dict[str, bool]:
    """
    è°ƒç”¨ LLM åˆ†æä¸€æ‰¹æ ‡é¢˜
    titles_batch: [{"id": 1, "title": "xxx"}, ...]
    è¿”å›: {"id1": true, "id2": false, ...}
    """
    prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æå¸ˆï¼Œä¸“æ³¨äºç¾å¦†å’ŒæŠ¤è‚¤é¢†åŸŸã€‚
è¯·åˆ†æä»¥ä¸‹æŠ–éŸ³è§†é¢‘æ ‡é¢˜ï¼Œåˆ¤æ–­å…¶å†…å®¹æ˜¯å¦ä¸»è¦ä¸"æŠ¤è‚¤"ï¼ˆSkincareï¼‰ã€"ç¾å®¹"ï¼ˆBeautyï¼‰ã€"èº«ä½“ä¿å…»"ï¼ˆBody Careï¼‰æˆ–"ç¾å¦†äº§å“"ï¼ˆCosmeticsï¼‰ç›¸å…³ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
1. âœ… ç›¸å…³ (true): åŒ…å«çš®è‚¤é—®é¢˜ï¼ˆç—˜ç—˜/é»‘å¤´/ç¾ç™½/æŠ—è€ï¼‰ã€æŠ¤è‚¤æ­¥éª¤ã€æŠ¤è‚¤å“æµ‹è¯„ã€åŒ–å¦†æ•™ç¨‹ã€ç¾å®¹ä»ªå™¨ã€åŒ»ç¾ä½“éªŒç­‰ã€‚
2. âŒ ä¸ç›¸å…³ (false): æ¸¸æˆã€ç¾é£Ÿã€æç¬‘å‰§æƒ…ã€èŒå® ã€æ•°ç ã€æ±½è½¦ã€å•çº¯çš„èˆè¹ˆ/å˜è£…ï¼ˆæ— ç¾å¦†æ•™å­¦ï¼‰ã€ä¸€èˆ¬çš„æ—¥å¸¸ç”Ÿæ´»è®°å½•ï¼ˆæœªæåŠæŠ¤è‚¤å“ï¼‰ã€‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœï¼ŒKey ä¸ºè§†é¢‘ IDï¼ŒValue ä¸º å¸ƒå°”å€¼ (true/false)ã€‚

å¾…åˆ†ææ ‡é¢˜åˆ—è¡¨ï¼š
"""
    for item in titles_batch:
        prompt += f'- ID: "{item["id"]}", æ ‡é¢˜: "{item["title"]}"\n'
    
    prompt += "\nç»“æœ JSON:"

    payload = {
        "model": OPENROUTER_MODEL,
        "messages": [
            {"role": "system", "content": "You are a helpful JSON outputting assistant."},
            {"role": "user", "content": prompt}
        ],
        "response_format": {"type": "json_object"}
    }

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://goodgame.ai",
        "X-Title": "GoodGame Content Analysis"
    }

    try:
        async with session.post("https://openrouter.ai/api/v1/chat/completions", json=payload, headers=headers) as resp:
            if resp.status != 200:
                error_text = await resp.text()
                print(f"âš ï¸ API Error: {resp.status} - {error_text[:100]}")
                return {}
            
            result = await resp.json()
            content = result['choices'][0]['message']['content']
            
            # æ¸…ç† Markdown ä»£ç å—
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
                
            return json.loads(content.strip())
    except Exception as e:
        print(f"âš ï¸ Exception: {e}")
        return {}

async def main():
    print("ğŸš€ å¼€å§‹è·å–è§†é¢‘æ•°æ®...")
    
    # 1. ä»æ•°æ®åº“è·å–è§†é¢‘æ ‡é¢˜
    try:
        # åˆ†é¡µè·å–æ‰€æœ‰æ•°æ®
        videos = []
        batch_size = 1000
        offset = 0
        
        while True:
            response = supabase.table("gg_xingtu_kol_videos")\
                .select("id, kol_id, item_title")\
                .neq("item_title", "")\
                .not_.is_("item_title", "null")\
                .range(offset, offset + batch_size - 1)\
                .execute()
            
            batch_data = response.data
            if not batch_data:
                break
                
            videos.extend(batch_data)
            offset += batch_size
            print(f"  å·²åŠ è½½ {len(videos)} æ¡æ•°æ®...")
            
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return

    print(f"âœ… æ€»å…±è·å–åˆ° {len(videos)} æ¡éç©ºæ ‡é¢˜è§†é¢‘")
    
    # 2. åˆ†æ‰¹å¤„ç†
    BATCH_SIZE = 50  # æ¯æ‰¹ 50 æ¡
    batches = [videos[i:i + BATCH_SIZE] for i in range(0, len(videos), BATCH_SIZE)]
    
    results = {}
    start_time = time.time()
    
    print(f"ğŸ“¦ åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡è¿›è¡Œ LLM åˆ†æ...")
    
    async with aiohttp.ClientSession() as session:
        tasks = []
        # ä¸ºäº†é¿å…é€Ÿç‡é™åˆ¶ï¼Œæˆ‘ä»¬é™åˆ¶å¹¶å‘æ•°
        CONCURRENCY_LIMIT = 10
        semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)

        async def limited_batch_process(batch, batch_idx):
            async with semaphore:
                # å‡†å¤‡ batch æ•°æ®
                processed_batch = [{"id": str(v["id"]), "title": v["item_title"]} for v in batch]
                
                print(f"  ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{len(batches)}...")
                batch_result = await analyze_titles_batch(session, processed_batch)
                
                if batch_result:
                    results.update(batch_result)
                else:
                    print(f"  âš ï¸ æ‰¹æ¬¡ {batch_idx+1} å¤±è´¥æˆ–æ— ç»“æœ")

        for i, batch in enumerate(batches):
            tasks.append(limited_batch_process(batch, i))
        
        await asyncio.gather(*tasks)

    duration = time.time() - start_time
    print(f"âœ… åˆ†æå®Œæˆï¼è€—æ—¶: {duration:.2f}ç§’")
    print(f"ğŸ“Š æˆåŠŸåˆ†æ: {len(results)}/{len(videos)} æ¡")
    
    # 3. æ•´åˆç»“æœå¹¶åˆ†æ
    skincare_videos = []
    kol_stats = {}  # {kol_id: {"total": 0, "skincare": 0, "titles": []}}

    for video in videos:
        vid = str(video["id"])
        kol_id = video["kol_id"]
        
        if kol_id not in kol_stats:
            kol_stats[kol_id] = {"total": 0, "skincare": 0, "titles": []}
        
        kol_stats[kol_id]["total"] += 1
        
        # æ£€æŸ¥ LLM ç»“æœ
        is_skincare = results.get(vid, False)
        # å…¼å®¹å¯èƒ½çš„å­—ç¬¦ä¸²è¿”å›å€¼
        if isinstance(is_skincare, str):
            is_skincare = is_skincare.lower() == 'true'
            
        if is_skincare:
            skincare_videos.append(video)
            kol_stats[kol_id]["skincare"] += 1
            # åªä¿å­˜å‰3ä¸ªæŠ¤è‚¤æ ‡é¢˜ä½œä¸ºç¤ºä¾‹
            if len(kol_stats[kol_id]["titles"]) < 3:
                kol_stats[kol_id]["titles"].append(video["item_title"])

    # 4. ç»Ÿè®¡æŠ¤è‚¤è¾¾äºº
    skincare_kols = []
    for kol_id, stats in kol_stats.items():
        if stats["skincare"] > 0:
            stats["ratio"] = round(stats["skincare"] / stats["total"] * 100, 2)
            stats["kol_id"] = kol_id
            skincare_kols.append(stats)
    
    # æŒ‰æŠ¤è‚¤è§†é¢‘æ•°é‡æ’åº
    skincare_kols.sort(key=lambda x: x["skincare"], reverse=True)

    # 5. è¾“å‡ºæŠ¥å‘Š
    report = {
        "total_videos_analyzed": len(videos),
        "skincare_videos_found": len(skincare_videos),
        "skincare_video_ratio": f"{len(skincare_videos)/len(videos)*100:.2f}%",
        "total_kols": len(kol_stats),
        "skincare_kols_count": len(skincare_kols),
        "top_skincare_kols": skincare_kols[:20]  # å‰20å
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = "skincare_analysis_report.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜è‡³ {output_file}")
    
    # æ‰“å°é¢„è§ˆ
    print("\nğŸ† æŠ¤è‚¤è§†é¢‘æœ€å¤šçš„è¾¾äºº TOP 10:")
    print(f"{'KOL ID':<25} {'æŠ¤è‚¤è§†é¢‘æ•°':<10} {'æ€»è§†é¢‘æ•°':<10} {'å æ¯”':<10} {'ç¤ºä¾‹æ ‡é¢˜'}")
    print("-" * 100)
    for kol in skincare_kols[:10]:
        titles_preview = kol['titles'][0][:20] + "..." if kol['titles'] else ""
        print(f"{kol['kol_id']:<25} {kol['skincare']:<10} {kol['total']:<10} {kol['ratio']}%    {titles_preview}")

if __name__ == "__main__":
    asyncio.run(main())

