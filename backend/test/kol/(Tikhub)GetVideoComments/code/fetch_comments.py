import os
import time
import json
import requests
from dotenv import load_dotenv
from supabase import create_client, Client
from pathlib import Path
from typing import List, Dict, Any

# -----------------------------------------------------------------------------
# é…ç½®ä¸ç¯å¢ƒåŠ è½½
# -----------------------------------------------------------------------------

def load_env():
    """åŠ è½½ç¯å¢ƒå˜é‡ï¼Œä»å½“å‰ç›®å½•å‘ä¸Šå¯»æ‰¾ backend/.env"""
    current_dir = Path(__file__).parent
    # å‡è®¾ç»“æ„: backend/test/kol/(Tikhub)GetVideoComments/code/fetch_comments.py
    # éœ€è¦å‘ä¸Š 4 çº§æ‰¾åˆ° backend/.env
    backend_dir = current_dir.parent.parent.parent.parent
    env_path = backend_dir / '.env'

    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {env_path}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")

# -----------------------------------------------------------------------------
# Supabase æ“ä½œ
# -----------------------------------------------------------------------------

def get_supabase_client() -> Client:
    """åˆå§‹åŒ–å¹¶è¿”å› Supabase å®¢æˆ·ç«¯"""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")
    if not url or not key:
        raise ValueError("âŒ ç¼ºå°‘ SUPABASE_URL æˆ– SUPABASE_KEY")
    return create_client(url, key)

def get_target_kol_ids(supabase: Client) -> List[str]:
    """
    è·å–æ‰€æœ‰è…°éƒ¨æŠ¤è‚¤è¾¾äººçš„ KOL ID
    æ¡ä»¶: is_mid_tier_skincare_kol = True
    """
    print("ğŸ” æ­£åœ¨æŸ¥è¯¢è…°éƒ¨æŠ¤è‚¤è¾¾äººåˆ—è¡¨...")
    # æ³¨æ„ï¼šSupabase é»˜è®¤é™åˆ¶ 1000 æ¡ï¼Œå¦‚æœè…°éƒ¨è¾¾äººè¶…è¿‡è¿™ä¸ªæ•°éœ€è¦åˆ†é¡µï¼Œä½†ç›®å‰çœ‹æè¿°åº”è¯¥ä¸å¤š
    response = supabase.table("gg_xingtu_kol_base_info")\
        .select("kol_id")\
        .eq("is_mid_tier_skincare_kol", True)\
        .execute()
    
    kol_ids = [item['kol_id'] for item in response.data if item.get('kol_id')]
    print(f"âœ… æ‰¾åˆ° {len(kol_ids)} ä½è…°éƒ¨æŠ¤è‚¤è¾¾äºº")
    return kol_ids

def get_videos_for_kols(supabase: Client, kol_ids: List[str]) -> List[Dict]:
    """
    è·å–æŒ‡å®š KOL åˆ—è¡¨å‘å¸ƒçš„è§†é¢‘ä¿¡æ¯
    ä» gg_xingtu_kol_videos_details è¡¨ä¸­æŸ¥è¯¢
    """
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢è¿™ {len(kol_ids)} ä½è¾¾äººçš„è§†é¢‘...")
    
    # ç”±äº kol_ids å¯èƒ½è¾ƒå¤šï¼Œåˆ†æ‰¹æŸ¥è¯¢ä»¥é¿å… URL è¿‡é•¿
    all_videos = []
    batch_size = 50 # æ¯æ¬¡æŸ¥ 50 ä¸ª KOL çš„è§†é¢‘
    
    for i in range(0, len(kol_ids), batch_size):
        batch_ids = kol_ids[i:i+batch_size]
        try:
            # æŸ¥è¯¢ kol_id åœ¨ batch_ids ä¸­çš„è§†é¢‘
            # åªéœ€ aweme_id å’Œ kol_idï¼Œä¹Ÿè®¸è¿˜éœ€è¦ title åšæ–‡ä»¶åæ–¹ä¾¿è¯†åˆ«
            response = supabase.table("gg_xingtu_kol_videos_details")\
                .select("aweme_id, kol_id, video_desc")\
                .in_("kol_id", batch_ids)\
                .execute()
            
            videos = response.data
            all_videos.extend(videos)
            print(f"   ...å·²è·å– {len(videos)} ä¸ªè§†é¢‘ (æ‰¹æ¬¡ {i//batch_size + 1})")
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢è§†é¢‘æ‰¹æ¬¡å¤±è´¥: {e}")
            
    print(f"âœ… æ€»è®¡æ‰¾åˆ° {len(all_videos)} ä¸ªç›¸å…³è§†é¢‘")
    return all_videos

# -----------------------------------------------------------------------------
# TikHub API æ“ä½œ
# -----------------------------------------------------------------------------

def fetch_video_comments(aweme_id: str, output_dir: Path, api_key: str):
    """
    è°ƒç”¨ TikHub API è·å–å•ä¸ªè§†é¢‘çš„è¯„è®ºæ•°æ®å¹¶ä¿å­˜
    
    API: /api/v1/douyin/app/v3/fetch_video_comments
    Docs: https://api.tikhub.io/#/Douyin-App-V3-API/fetch_video_comments_api_v1_douyin_app_v3_fetch_video_comments_get
    """
    base_url = "https://api.tikhub.io/api/v1/douyin/app/v3/fetch_video_comments"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    all_comments = []
    cursor = 0
    has_more = 1
    page_count = 0
    max_pages = 5  # é™åˆ¶æ¯ä¸ªè§†é¢‘æŠ“å–çš„é¡µæ•°ï¼Œé¿å…è¯„è®ºè¿‡å¤šå¯¼è‡´è€—æ—¶è¿‡é•¿ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
    
    print(f"ğŸ“¥ å¼€å§‹æŠ“å–è§†é¢‘ {aweme_id} çš„è¯„è®º...")
    
    while has_more == 1 and page_count < max_pages:
        params = {
            "aweme_id": aweme_id,
            "cursor": cursor,
            "count": 20 # ä¿æŒé»˜è®¤
        }
        
        try:
            response = requests.get(base_url, params=params, headers=headers, timeout=30)
            
            if response.status_code != 200:
                print(f"âŒ API è¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                break
                
            data = response.json()
            
            # æ£€æŸ¥ API è¿”å›çš„ä¸šåŠ¡çŠ¶æ€
            # TikHub é€šå¸¸ç›´æ¥è¿”å›æ•°æ®ï¼Œæˆ–åœ¨ data å­—æ®µä¸­
            # æ ¹æ®æ–‡æ¡£ï¼Œç›´æ¥è¿”å›è¯„è®ºæ•°æ®ç»“æ„
            
            # å°è¯•è§£æ comments
            # æ³¨æ„ï¼šå®é™…è¿”å›ç»“æ„å¯èƒ½åŒ…å«åœ¨ 'data' å­—æ®µé‡Œï¼Œä¹Ÿå¯èƒ½æ˜¯ç›´æ¥çš„ä¸€çº§å­—æ®µ
            # è¿™é‡Œæ ¹æ®ä¸€èˆ¬ TikHub æŠ–éŸ³æ¥å£ä¹ æƒ¯ï¼Œé€šå¸¸æ˜¯ data['comments']
            # å¦‚æœç›´æ¥æ˜¯ä»£ç†å“åº”ï¼Œå¯èƒ½ä¸æŠ–éŸ³åŸç”Ÿç»“æ„ä¸€è‡´
            
            # ä¿å­˜åŸå§‹å“åº”ä»¥ä¾¿è°ƒè¯•
            # debug_file = output_dir / f"{aweme_id}_page_{page_count}_debug.json"
            # with open(debug_file, "w", encoding="utf-8") as f:
            #    json.dump(data, f, ensure_ascii=False)
            
            # æå–è¯„è®ºåˆ—è¡¨
            comments_list = data.get("comments", [])
            if not comments_list and "data" in data:
                 # æœ‰æ—¶å€™åŒ…è£¹åœ¨ data å±‚çº§ä¸‹
                 comments_list = data["data"].get("comments", [])
            
            if not comments_list:
                print(f"   âš ï¸ ç¬¬ {page_count+1} é¡µæ— è¯„è®ºæ•°æ®æˆ–ç»“æ„ä¸åŒ¹é…")
                # å³ä½¿æ²¡æœ‰è¯„è®ºä¹Ÿå¯èƒ½æœ‰ cursor æ›´æ–°ï¼Œæˆ–è€…å°±æ˜¯æ²¡è¯„è®ºäº†
                if data.get("status_code") == 0: # æˆåŠŸä½†æ— æ•°æ®
                     pass
                else:
                     print(f"   API æ¶ˆæ¯: {data.get('status_msg')}")
            
            if comments_list:
                all_comments.extend(comments_list)
                print(f"   âœ… ç¬¬ {page_count+1} é¡µè·å– {len(comments_list)} æ¡è¯„è®º")
            
            # æ›´æ–°æ¸¸æ ‡
            cursor = data.get("cursor", 0)
            has_more = data.get("has_more", 0)
            page_count += 1
            
            # ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé¿å… QPS è¿‡é«˜
            time.sleep(1)
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            break
            
    # ä¿å­˜ç»“æœ
    if all_comments:
        output_file = output_dir / f"comments_{aweme_id}.json"
        result = {
            "aweme_id": aweme_id,
            "total_fetched": len(all_comments),
            "fetched_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "comments": all_comments
        }
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(all_comments)} æ¡è¯„è®ºåˆ° {output_file.name}")
    else:
        print(f"âš ï¸ è§†é¢‘ {aweme_id} æœªæŠ“å–åˆ°ä»»ä½•è¯„è®º")

# -----------------------------------------------------------------------------
# ä¸»æµç¨‹
# -----------------------------------------------------------------------------

def main():
    load_env()
    
    # 1. æ£€æŸ¥ TikHub Key
    tikhub_key = os.getenv("tikhub_API_KEY")
    if not tikhub_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° tikhub_API_KEY ç¯å¢ƒå˜é‡")
        return

    # 2. è¿æ¥æ•°æ®åº“
    try:
        supabase = get_supabase_client()
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return

    # 3. è·å–ç›®æ ‡è§†é¢‘
    target_kol_ids = get_target_kol_ids(supabase)
    if not target_kol_ids:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡ KOLï¼Œç»“æŸä»»åŠ¡")
        return
        
    videos = get_videos_for_kols(supabase, target_kol_ids)
    if not videos:
        print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘ï¼Œç»“æŸä»»åŠ¡")
        return
        
    # 4. å‡†å¤‡è¾“å‡ºç›®å½•
    current_dir = Path(__file__).parent
    output_dir = current_dir.parent / "output"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸš€ å¼€å§‹æŠ“å–è¯„è®ºï¼Œç›®æ ‡è§†é¢‘æ•°: {len(videos)}")
    print(f"ğŸ“‚ ç»“æœå°†ä¿å­˜è‡³: {output_dir}")
    
    # 5. éå†è§†é¢‘æŠ“å–è¯„è®º
    # é™åˆ¶æŠ“å–æ•°é‡ç”¨äºæµ‹è¯•ï¼Œé¿å…ä¸€æ¬¡è·‘å¤ªä¹…
    # è¿™é‡Œå¦‚æœéœ€è¦è·‘å…¨éƒ¨ï¼Œå¯ä»¥å»æ‰åˆ‡ç‰‡ [:5]
    # ä¸ºäº†æ¼”ç¤ºå’Œæµ‹è¯•ï¼Œæˆ‘ä»¬å…ˆè·‘å‰ 5 ä¸ªè§†é¢‘
    test_limit = 5
    print(f"â„¹ï¸ æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {test_limit} ä¸ªè§†é¢‘ (å¦‚éœ€å…¨éƒ¨è¯·ä¿®æ”¹ä»£ç )")
    
    for i, video in enumerate(videos[:test_limit]):
        aweme_id = video.get("aweme_id")
        if not aweme_id:
            continue
            
        print(f"\n[{i+1}/{min(len(videos), test_limit)}] å¤„ç†è§†é¢‘: {aweme_id}")
        fetch_video_comments(aweme_id, output_dir, tikhub_key)
        
        # è§†é¢‘é—´å»¶æ—¶
        time.sleep(2)

    print("\nâœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")

if __name__ == "__main__":
    main()

