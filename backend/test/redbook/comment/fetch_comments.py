#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦è¯„è®ºè·å–è„šæœ¬

ç”¨é€”:
- è·å–ç¬”è®°çš„è¯„è®ºåˆ—è¡¨
- è·å–è¯„è®ºçš„å­è¯„è®ºï¼ˆå›å¤ï¼‰
- æ±‡æ€»è¾“å‡ºè¯„è®ºå†…å®¹

æ¥å£æ–‡æ¡£:
- è·å–ç¬”è®°è¯„è®º: https://docs.tikhub.io/310965840e0
- è·å–å­è¯„è®º: https://docs.tikhub.io/310965841e0
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional
import time


def load_api_key() -> str:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½ TikHub API Key"""
    backend_dir = Path(__file__).parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError(f"ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    
    return api_key


def get_note_comments(
    api_key: str,
    note_id: str,
    start: str = "",
    sort_strategy: int = 1
) -> Dict[str, Any]:
    """
    è·å–ç¬”è®°è¯„è®º
    
    Args:
        api_key: TikHub API Key
        note_id: ç¬”è®°ID
        start: ç¿»é¡µæ¸¸æ ‡
        sort_strategy: æ’åºç­–ç•¥ (1: é»˜è®¤æ’åº, 2: æœ€æ–°è¯„è®º)
    
    Returns:
        API å“åº”æ•°æ®
    """
    url = "https://api.tikhub.io/api/v1/xiaohongshu/app/get_note_comments"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'note_id': note_id,
        'sort_strategy': sort_strategy
    }
    
    if start:
        params['start'] = start
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
            return {"error": f"HTTP {response.status_code}"}
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
        return {"error": str(e)}


def get_sub_comments(
    api_key: str,
    note_id: str,
    comment_id: str,
    start: str = ""
) -> Dict[str, Any]:
    """
    è·å–å­è¯„è®ºï¼ˆå›å¤ï¼‰
    
    Args:
        api_key: TikHub API Key
        note_id: ç¬”è®°ID
        comment_id: ä¸€çº§è¯„è®ºID
        start: ç¿»é¡µæ¸¸æ ‡
    
    Returns:
        API å“åº”æ•°æ®
    """
    url = "https://api.tikhub.io/api/v1/xiaohongshu/app/get_sub_comments"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'note_id': note_id,
        'comment_id': comment_id
    }
    
    if start:
        params['start'] = start
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
            return {"error": f"HTTP {response.status_code}"}
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
        return {"error": str(e)}


def fetch_all_comments(
    api_key: str,
    note_id: str,
    max_pages: int = 5,
    fetch_sub_comments: bool = True,
    max_sub_pages: int = 3
) -> Dict[str, Any]:
    """
    è·å–ç¬”è®°çš„æ‰€æœ‰è¯„è®ºï¼ˆåŒ…æ‹¬å­è¯„è®ºï¼‰
    
    Args:
        api_key: TikHub API Key
        note_id: ç¬”è®°ID
        max_pages: æœ€å¤§è·å–é¡µæ•°
        fetch_sub_comments: æ˜¯å¦è·å–å­è¯„è®º
        max_sub_pages: å­è¯„è®ºæœ€å¤§è·å–é¡µæ•°
    
    Returns:
        åŒ…å«æ‰€æœ‰è¯„è®ºçš„å­—å…¸
    """
    all_comments = []
    cursor = ""
    page = 0
    total_count = 0
    
    print(f"\nğŸ“¥ å¼€å§‹è·å–ç¬”è®° {note_id} çš„è¯„è®º...")
    
    while page < max_pages:
        page += 1
        print(f"   è·å–è¯„è®ºç¬¬ {page} é¡µ...")
        
        result = get_note_comments(api_key, note_id, start=cursor)
        
        if result.get('code') != 200:
            print(f"   âŒ è·å–è¯„è®ºå¤±è´¥: {result}")
            break
        
        # è§£æå“åº”
        data = result.get('data', {})
        inner_data = data.get('data', {})
        comments = inner_data.get('comments', [])
        has_more = inner_data.get('has_more', False)
        cursor = inner_data.get('cursor', '')
        
        if page == 1:
            total_count = inner_data.get('total', 0)
            print(f"   ğŸ“Š æ€»è¯„è®ºæ•°: {total_count}")
        
        if not comments:
            print(f"   æ²¡æœ‰æ›´å¤šè¯„è®º")
            break
        
        print(f"   âœ… è·å– {len(comments)} æ¡è¯„è®º")
        
        # å¤„ç†æ¯æ¡è¯„è®º
        for comment in comments:
            # ç”¨æˆ·ä¿¡æ¯å¯èƒ½åœ¨ user æˆ– user_info å­—æ®µ
            user_info = comment.get('user') or comment.get('user_info', {})
            # æ—¶é—´å¯èƒ½åœ¨ time æˆ– create_time å­—æ®µ
            create_time = comment.get('time') or comment.get('create_time')
            # ç‚¹èµæ•°å¯èƒ½åœ¨ like_count æˆ– interact_info.liked_count
            like_count = comment.get('like_count', 0)
            if not like_count:
                interact_info = comment.get('interact_info', {})
                like_count = interact_info.get('liked_count', 0)
            
            comment_data = {
                'id': comment.get('id'),
                'content': comment.get('content', ''),
                'create_time': create_time,
                'user_info': user_info,
                'interact_info': {'liked_count': like_count},
                'sub_comment_count': comment.get('sub_comment_count', 0),
                'sub_comments': []
            }
            
            # è·å–å­è¯„è®º
            if fetch_sub_comments and comment_data['sub_comment_count'] > 0:
                print(f"      è·å–å­è¯„è®º (å…± {comment_data['sub_comment_count']} æ¡)...", flush=True)
                sub_cursor = ""
                sub_page = 0
                
                while sub_page < max_sub_pages:
                    sub_page += 1
                    
                    sub_result = get_sub_comments(
                        api_key, 
                        note_id, 
                        comment_data['id'],
                        start=sub_cursor
                    )
                    
                    if sub_result.get('code') != 200:
                        print(f"      âŒ è·å–å­è¯„è®ºå¤±è´¥", flush=True)
                        break
                    
                    sub_data = sub_result.get('data', {})
                    sub_inner = sub_data.get('data', {})
                    sub_comments = sub_inner.get('comments', [])
                    
                    if not sub_comments:
                        break
                    
                    print(f"      âœ… è·å– {len(sub_comments)} æ¡å­è¯„è®º", flush=True)
                    
                    for sub in sub_comments:
                        # å­è¯„è®ºçš„ç”¨æˆ·ä¿¡æ¯
                        sub_user = sub.get('user') or sub.get('user_info', {})
                        sub_time = sub.get('time') or sub.get('create_time')
                        comment_data['sub_comments'].append({
                            'id': sub.get('id'),
                            'content': sub.get('content', ''),
                            'create_time': sub_time,
                            'user_info': sub_user,
                            'target_comment': sub.get('target_comment', {})
                        })
                    
                    # è·å–ä¸‹ä¸€é¡µå­è¯„è®ºçš„æ¸¸æ ‡
                    if sub_comments:
                        sub_cursor = sub_comments[-1].get('id', '')
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤š
                    if len(sub_comments) < 10:  # å‡è®¾æ¯é¡µ10æ¡
                        break
                    
                    time.sleep(0.3)
            
            all_comments.append(comment_data)
        
        if not has_more:
            print(f"   å·²è·å–å…¨éƒ¨è¯„è®º")
            break
        
        time.sleep(0.5)
    
    return {
        'note_id': note_id,
        'total_count': total_count,
        'fetched_count': len(all_comments),
        'comments': all_comments
    }


def format_timestamp(ts: int) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    if not ts:
        return "æœªçŸ¥æ—¶é—´"
    try:
        # å°çº¢ä¹¦æ—¶é—´æˆ³å¯èƒ½æ˜¯æ¯«ç§’
        if ts > 10000000000:
            ts = ts // 1000
        return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')
    except:
        return "æœªçŸ¥æ—¶é—´"


def generate_summary_file(
    note_info: Dict[str, Any],
    comments_data: Dict[str, Any],
    output_path: str
) -> None:
    """
    ç”Ÿæˆè¯„è®ºæ±‡æ€»æ–‡ä»¶ï¼ˆç±»ä¼¼å°çº¢ä¹¦å¸–å­æ ¼å¼ï¼‰
    
    Args:
        note_info: ç¬”è®°ä¿¡æ¯
        comments_data: è¯„è®ºæ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    lines = []
    
    # å¸–å­ä¿¡æ¯
    lines.append("=" * 60)
    lines.append(f"ğŸ“ å°çº¢ä¹¦å¸–å­è¯„è®ºæ±‡æ€»")
    lines.append("=" * 60)
    lines.append("")
    lines.append(f"ã€å¸–å­ä¿¡æ¯ã€‘")
    lines.append(f"ID: {note_info.get('id', 'N/A')}")
    lines.append(f"æ ‡é¢˜: {note_info.get('title', 'æ— æ ‡é¢˜')}")
    lines.append(f"ä½œè€…: {note_info.get('author', 'N/A')}")
    lines.append(f"ç‚¹èµæ•°: {note_info.get('liked_count', 0)}")
    lines.append(f"è¯„è®ºæ•°: {note_info.get('comments_count', 0)}")
    lines.append(f"æ”¶è—æ•°: {note_info.get('collected_count', 0)}")
    lines.append("")
    lines.append("-" * 60)
    lines.append("")
    
    # è¯„è®ºç»Ÿè®¡
    total_comments = len(comments_data.get('comments', []))
    total_sub_comments = sum(
        len(c.get('sub_comments', [])) 
        for c in comments_data.get('comments', [])
    )
    
    lines.append(f"ã€è¯„è®ºç»Ÿè®¡ã€‘")
    lines.append(f"è·å–çš„ä¸€çº§è¯„è®ºæ•°: {total_comments}")
    lines.append(f"è·å–çš„å­è¯„è®ºæ•°: {total_sub_comments}")
    lines.append(f"è¯„è®ºæ€»æ•°: {total_comments + total_sub_comments}")
    lines.append("")
    lines.append("=" * 60)
    lines.append("ğŸ’¬ è¯„è®ºè¯¦æƒ…")
    lines.append("=" * 60)
    lines.append("")
    
    # è¯„è®ºè¯¦æƒ…
    for i, comment in enumerate(comments_data.get('comments', []), 1):
        user_info = comment.get('user_info', {})
        nickname = user_info.get('nickname', 'åŒ¿åç”¨æˆ·')
        content = comment.get('content', '')
        create_time = format_timestamp(comment.get('create_time', 0))
        interact_info = comment.get('interact_info', {})
        liked_count = interact_info.get('liked_count', 0)
        sub_count = comment.get('sub_comment_count', 0)
        
        lines.append(f"ã€{i}æ¥¼ã€‘{nickname}")
        lines.append(f"   {content}")
        lines.append(f"   â¤ï¸ {liked_count}  ğŸ’¬ {sub_count}  ğŸ• {create_time}")
        
        # å­è¯„è®º
        sub_comments = comment.get('sub_comments', [])
        if sub_comments:
            for j, sub in enumerate(sub_comments, 1):
                sub_user = sub.get('user_info', {})
                sub_nickname = sub_user.get('nickname', 'åŒ¿åç”¨æˆ·')
                sub_content = sub.get('content', '')
                sub_time = format_timestamp(sub.get('create_time', 0))
                
                # æ£€æŸ¥æ˜¯å¦å›å¤å…¶ä»–å­è¯„è®º
                target = sub.get('target_comment', {})
                target_user = target.get('user_info', {}) if target else {}
                target_nickname = target_user.get('nickname', '')
                
                if target_nickname:
                    lines.append(f"   â””â”€ {sub_nickname} å›å¤ {target_nickname}: {sub_content}")
                else:
                    lines.append(f"   â””â”€ {sub_nickname}: {sub_content}")
                lines.append(f"      ğŸ• {sub_time}")
        
        lines.append("")
    
    # å†™å…¥æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))
    
    print(f"ğŸ’¾ è¯„è®ºæ±‡æ€»å·²ä¿å­˜: {output_path}")


def main():
    import sys
    print("=" * 60, flush=True)
    print("å°çº¢ä¹¦è¯„è®ºè·å–å·¥å…·", flush=True)
    print("=" * 60, flush=True)
    
    api_key = load_api_key()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    # è¯»å– Top3 å¸–å­ä¿¡æ¯
    search_output_dir = script_dir.parent / "search" / "output"
    top3_file = search_output_dir / "top3_notes.json"
    
    if not top3_file.exists():
        print(f"âŒ æœªæ‰¾åˆ° Top3 å¸–å­æ–‡ä»¶: {top3_file}")
        print("è¯·å…ˆè¿è¡Œ fetch_all_pages.py è·å–å¸–å­åˆ—è¡¨")
        return
    
    with open(top3_file, 'r', encoding='utf-8') as f:
        top3_notes = json.load(f)
    
    print(f"\nğŸ“‹ å°†è·å–ä»¥ä¸‹ {len(top3_notes)} ä¸ªå¸–å­çš„è¯„è®º:")
    for i, note in enumerate(top3_notes, 1):
        print(f"   {i}. {note['title'][:40]}... (è¯„è®ºæ•°: {note['comments_count']})")
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # è·å–æ¯ä¸ªå¸–å­çš„è¯„è®º
    for i, note in enumerate(top3_notes, 1):
        note_id = note['id']
        
        print(f"\n{'='*60}")
        print(f"ğŸ“– å¤„ç†å¸–å­ {i}/{len(top3_notes)}: {note['title'][:40]}...")
        print(f"{'='*60}")
        
        # è·å–è¯„è®ºï¼ˆé™åˆ¶é¡µæ•°ä»¥æ§åˆ¶ API è°ƒç”¨ï¼‰
        # ç”±äºè¯„è®ºæ•°å¾ˆå¤šï¼Œæˆ‘ä»¬åªè·å–å‰å‡ é¡µä½œä¸ºç¤ºä¾‹
        comments_data = fetch_all_comments(
            api_key,
            note_id,
            max_pages=2,  # é™åˆ¶ä¸º2é¡µ
            fetch_sub_comments=True,
            max_sub_pages=1  # å­è¯„è®ºé™åˆ¶1é¡µ
        )
        
        # ä¿å­˜åŸå§‹è¯„è®ºæ•°æ®
        raw_file = output_dir / f"comments_raw_{note_id}_{timestamp}.json"
        with open(raw_file, 'w', encoding='utf-8') as f:
            json.dump(comments_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜: {raw_file}")
        
        # ç”Ÿæˆæ±‡æ€»æ–‡ä»¶
        summary_file = output_dir / f"comments_summary_{note_id}_{timestamp}.txt"
        generate_summary_file(note, comments_data, str(summary_file))
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        if i < len(top3_notes):
            print("\nâ³ ç­‰å¾… 2 ç§’åç»§ç»­...")
            time.sleep(2)
    
    print(f"\n{'='*60}")
    print("âœ… æ‰€æœ‰å¸–å­è¯„è®ºè·å–å®Œæˆï¼")
    print(f"{'='*60}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
