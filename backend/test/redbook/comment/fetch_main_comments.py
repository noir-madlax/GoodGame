#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦ä¸»è¯„è®ºè·å–è„šæœ¬

åŠŸèƒ½:
1. åªè·å–ä¸€çº§è¯„è®ºï¼ˆä¸è·å–å­è¯„è®ºï¼‰
2. å¢é‡ä¿å­˜ï¼šæ¯è·å–ä¸€é¡µè¯„è®ºå°±ä¿å­˜
3. æ–­ç‚¹ç»­ä¼ ï¼šå·²ä¿å­˜çš„å†…å®¹ä¸é‡å¤è·å–
4. å®Œæ•´è®°å½•è¯·æ±‚å’Œå“åº”ä½“
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, Optional
import time


def load_config() -> Dict[str, Any]:
    """ä» config.json åŠ è½½é…ç½®"""
    config_path = Path(__file__).parent / "params" / "config.json"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_api_key() -> str:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½ TikHub API Key"""
    backend_dir = Path(__file__).parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    
    return api_key


def load_progress(output_dir: Path, note_id: str) -> Dict[str, Any]:
    """åŠ è½½è¿›åº¦æ–‡ä»¶"""
    progress_file = output_dir / f"main_progress_{note_id}.json"
    if progress_file.exists():
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        'note_id': note_id,
        'last_cursor': '',
        'total_fetched': 0,
        'fetched_comment_ids': [],
        'completed': False,
        'last_update': None
    }


def save_progress(output_dir: Path, note_id: str, progress: Dict[str, Any]) -> None:
    """ä¿å­˜è¿›åº¦æ–‡ä»¶"""
    progress_file = output_dir / f"main_progress_{note_id}.json"
    progress['last_update'] = datetime.now().isoformat()
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def load_comments(output_dir: Path, note_id: str) -> Dict[str, Any]:
    """åŠ è½½å·²ä¿å­˜çš„è¯„è®º"""
    comments_file = output_dir / f"main_comments_{note_id}.json"
    if comments_file.exists():
        with open(comments_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        'note_id': note_id,
        'total_count': 0,
        'comments': []
    }


def save_comments(output_dir: Path, note_id: str, data: Dict[str, Any]) -> None:
    """ä¿å­˜è¯„è®ºæ•°æ®"""
    comments_file = output_dir / f"main_comments_{note_id}.json"
    with open(comments_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def append_api_log(output_dir: Path, note_id: str, log_entry: Dict[str, Any]) -> None:
    """è¿½åŠ  API æ—¥å¿—"""
    log_file = output_dir / f"main_api_log_{note_id}.jsonl"
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')


def save_raw_response(output_dir: Path, note_id: str, page: int, response_data: Dict[str, Any]) -> None:
    """ä¿å­˜åŸå§‹å“åº”"""
    raw_dir = output_dir / "raw"
    raw_dir.mkdir(exist_ok=True)
    raw_file = raw_dir / f"main_raw_page{page}_{note_id}.json"
    with open(raw_file, 'w', encoding='utf-8') as f:
        json.dump(response_data, f, ensure_ascii=False, indent=2)


def get_note_comments(
    api_key: str,
    note_id: str,
    cursor: str = "",
    sort_strategy: str = "latest_v2"
) -> Dict[str, Any]:
    """
    è·å–ç¬”è®°è¯„è®º
    
    ä½¿ç”¨ Web API: /api/v1/xiaohongshu/web/get_note_comments
    """
    url = "https://api.tikhub.io/api/v1/xiaohongshu/web/get_note_comments"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'note_id': note_id,
        'sort_strategy': sort_strategy
    }
    
    if cursor:
        params['lastCursor'] = cursor
    
    request_info = {
        'url': url,
        'method': 'GET',
        'params': params.copy(),
        'timestamp': datetime.now().isoformat()
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        response_info = {
            'status_code': response.status_code,
            'timestamp': datetime.now().isoformat(),
            'success': response.status_code == 200,
            'error': None
        }
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'data': result,
                'request': request_info,
                'response': response_info
            }
        else:
            response_info['error'] = response.text[:500]
            return {
                'success': False,
                'error': f"HTTP {response.status_code}: {response.text[:200]}",
                'request': request_info,
                'response': response_info
            }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'request': request_info,
            'response': {
                'status_code': None,
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e)
            }
        }


def extract_comment_info(comment: Dict[str, Any]) -> Dict[str, Any]:
    """æå–è¯„è®ºå…³é”®ä¿¡æ¯"""
    user = comment.get('user', {})
    return {
        'id': comment.get('id'),
        'content': comment.get('content', ''),
        'time': comment.get('time'),
        'user_nickname': user.get('nickname', ''),
        'user_id': user.get('userid', ''),
        'like_count': comment.get('like_count', 0),
        'sub_comment_count': comment.get('sub_comment_count', 0),
        'ip_location': comment.get('ip_location', '')
    }


def fetch_all_main_comments(
    api_key: str,
    note_id: str,
    output_dir: Path,
    max_pages: int = 500,
    request_delay: float = 0.5
) -> None:
    """
    è·å–æ‰€æœ‰ä¸»è¯„è®º
    
    Args:
        api_key: TikHub API Key
        note_id: ç¬”è®° ID
        output_dir: è¾“å‡ºç›®å½•
        max_pages: æœ€å¤§é¡µæ•°é™åˆ¶
        request_delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    """
    # åŠ è½½è¿›åº¦
    progress = load_progress(output_dir, note_id)
    comments_data = load_comments(output_dir, note_id)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if progress.get('completed'):
        print(f"âœ… ç¬”è®° {note_id} çš„ä¸»è¯„è®ºå·²å…¨éƒ¨è·å–å®Œæˆ")
        print(f"   æ€»è®¡: {progress['total_fetched']} æ¡")
        return
    
    # å·²è·å–çš„è¯„è®º ID é›†åˆ
    existing_ids = set(progress.get('fetched_comment_ids', []))
    cursor = progress.get('last_cursor', '')
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ è·å–ç¬”è®° {note_id} çš„ä¸»è¯„è®º")
    print(f"{'='*60}")
    print(f"   å·²æœ‰: {len(existing_ids)} æ¡")
    print(f"   æ¸¸æ ‡: {cursor[:20]}..." if cursor else "   æ¸¸æ ‡: (ä»å¤´å¼€å§‹)")
    
    page = 0
    new_count = 0
    
    while page < max_pages:
        page += 1
        print(f"\nğŸ“„ ç¬¬ {page} é¡µ...", flush=True)
        
        # è°ƒç”¨ API
        result = get_note_comments(api_key, note_id, cursor=cursor)
        
        # è®°å½• API æ—¥å¿—
        log_entry = {
            'page': page,
            'cursor_used': cursor,
            'request': result['request'],
            'response': result['response']
        }
        append_api_log(output_dir, note_id, log_entry)
        
        if not result['success']:
            print(f"   âŒ è¯·æ±‚å¤±è´¥: {result['error']}")
            break
        
        # ä¿å­˜åŸå§‹å“åº”
        save_raw_response(output_dir, note_id, page, result['data'])
        
        # è§£æå“åº”
        api_data = result['data'].get('data', {})
        inner_data = api_data.get('data', {})
        comments = inner_data.get('comments', [])
        has_more = inner_data.get('has_more', False)
        raw_cursor = inner_data.get('cursor', '')
        total_l1 = inner_data.get('comment_count_l1', 0)
        
        # å¤„ç† cursorï¼šå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ– JSON å¯¹è±¡
        if isinstance(raw_cursor, dict):
            new_cursor = raw_cursor.get('cursor', '')
        elif isinstance(raw_cursor, str) and raw_cursor.startswith('{'):
            try:
                cursor_obj = json.loads(raw_cursor)
                new_cursor = cursor_obj.get('cursor', raw_cursor)
            except:
                new_cursor = raw_cursor
        else:
            new_cursor = raw_cursor
        
        print(f"   ä¸€çº§è¯„è®ºæ€»æ•°: {total_l1}")
        
        if not comments:
            print(f"   æ²¡æœ‰æ›´å¤šè¯„è®º")
            progress['completed'] = True
            save_progress(output_dir, note_id, progress)
            break
        
        # å¤„ç†è¯„è®º
        page_new = 0
        for comment in comments:
            comment_id = comment.get('id')
            if comment_id and comment_id not in existing_ids:
                comment_info = extract_comment_info(comment)
                comments_data['comments'].append(comment_info)
                existing_ids.add(comment_id)
                progress['fetched_comment_ids'].append(comment_id)
                page_new += 1
                new_count += 1
        
        # æ›´æ–°è¿›åº¦
        cursor = new_cursor
        progress['last_cursor'] = cursor
        progress['total_fetched'] = len(existing_ids)
        comments_data['total_count'] = len(existing_ids)
        
        # ç«‹å³ä¿å­˜
        save_progress(output_dir, note_id, progress)
        save_comments(output_dir, note_id, comments_data)
        
        print(f"   âœ… æœ¬é¡µ {len(comments)} æ¡ï¼Œæ–°å¢ {page_new} æ¡")
        print(f"   ğŸ“Š ç´¯è®¡: {len(existing_ids)}/{total_l1} æ¡")
        
        if not has_more:
            print(f"\nâœ… å·²è·å–å…¨éƒ¨ä¸»è¯„è®º")
            progress['completed'] = True
            save_progress(output_dir, note_id, progress)
            break
        
        # è¯·æ±‚é—´éš”
        time.sleep(request_delay)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è·å–å®Œæˆ")
    print(f"   æ–°å¢: {new_count} æ¡")
    print(f"   æ€»è®¡: {len(existing_ids)} æ¡")
    print(f"{'='*60}")


def main():
    import sys
    
    print("=" * 60)
    print("å°çº¢ä¹¦ä¸»è¯„è®ºè·å–å·¥å…·")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    api_key = load_api_key()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    # è·å–ç›®æ ‡å¸–å­ ID
    note_ids = config.get('ç›®æ ‡å¸–å­', {}).get('note_ids', [])
    if not note_ids:
        print("âŒ æœªé…ç½®ç›®æ ‡å¸–å­ ID")
        return
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šå¸–å­ç´¢å¼•æˆ– ID
    if len(sys.argv) > 1:
        arg = sys.argv[1]
        if arg.startswith('--index='):
            index = int(arg.split('=')[1])
            if index >= len(note_ids):
                print(f"âŒ ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼Œå…± {len(note_ids)} ä¸ªå¸–å­")
                return
            note_id = note_ids[index]
        elif arg.startswith('--id='):
            note_id = arg.split('=')[1]
        else:
            # ç›´æ¥ä¼ å…¥ note_id
            note_id = arg
    else:
        note_id = note_ids[0]  # é»˜è®¤å¤„ç†ç¬¬ä¸€ä¸ª
    
    print(f"\nç›®æ ‡å¸–å­: {note_id}")
    
    # è·å–é…ç½®å‚æ•°
    max_pages = config.get('ä¸€çº§è¯„è®ºè·å–', {}).get('max_pages', 100)
    request_delay = config.get('è¯·æ±‚é—´éš”', {}).get('request_delay', 0.5)
    
    print(f"æœ€å¤§é¡µæ•°: {max_pages}")
    print(f"è¯·æ±‚é—´éš”: {request_delay}s")
    
    # å¼€å§‹è·å–
    fetch_all_main_comments(
        api_key=api_key,
        note_id=note_id,
        output_dir=output_dir,
        max_pages=max_pages,
        request_delay=request_delay
    )


if __name__ == "__main__":
    main()
