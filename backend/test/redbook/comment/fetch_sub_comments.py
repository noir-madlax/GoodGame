#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦å­è¯„è®ºè·å–è„šæœ¬

åŠŸèƒ½:
1. è·å–æŒ‡å®šè¯„è®ºçš„å­è¯„è®º
2. å¢é‡ä¿å­˜ï¼šæ¯è·å–å®Œä¸€ä¸ªè¯„è®ºçš„å­è¯„è®ºå°±ä¿å­˜
3. æ–­ç‚¹ç»­ä¼ ï¼šå·²è·å–çš„ä¸é‡å¤è·å–
4. æ”¯æŒå¹¶å‘è·å–ï¼ˆä¸åŒè¯„è®ºçš„å­è¯„è®ºå¯ä»¥å¹¶å‘ï¼‰
5. å®Œæ•´è®°å½•è¯·æ±‚å’Œå“åº”ä½“
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import threading


# çº¿ç¨‹é”ï¼Œç”¨äºå®‰å…¨å†™å…¥æ–‡ä»¶
file_lock = threading.Lock()


def load_config() -> Dict[str, Any]:
    """ä» config.json åŠ è½½é…ç½®"""
    config_path = Path(__file__).parent / "params" / "config.json"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def load_api_key() -> str:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½ TikHub API Key"""
    backend_dir = Path(__file__).parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    
    return api_key


def load_sub_progress(output_dir: Path, note_id: str) -> Dict[str, Any]:
    """åŠ è½½å­è¯„è®ºè·å–è¿›åº¦"""
    progress_file = output_dir / f"sub_progress_{note_id}.json"
    if progress_file.exists():
        with open(progress_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        'note_id': note_id,
        'completed_comment_ids': [],  # å·²å®Œæˆè·å–å­è¯„è®ºçš„è¯„è®º ID
        'in_progress': {},  # æ­£åœ¨è·å–ä¸­çš„è¯„è®º {comment_id: last_cursor}
        'last_update': None
    }


def save_sub_progress(output_dir: Path, note_id: str, progress: Dict[str, Any]) -> None:
    """ä¿å­˜å­è¯„è®ºè·å–è¿›åº¦"""
    with file_lock:
        progress_file = output_dir / f"sub_progress_{note_id}.json"
        progress['last_update'] = datetime.now().isoformat()
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)


def load_sub_comments_data(output_dir: Path, note_id: str) -> Dict[str, Any]:
    """åŠ è½½å­è¯„è®ºæ•°æ®"""
    data_file = output_dir / f"sub_comments_{note_id}.json"
    if data_file.exists():
        with open(data_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        'note_id': note_id,
        'sub_comments': {}  # {comment_id: [sub_comments]}
    }


def save_sub_comments_data(output_dir: Path, note_id: str, data: Dict[str, Any]) -> None:
    """ä¿å­˜å­è¯„è®ºæ•°æ®"""
    with file_lock:
        data_file = output_dir / f"sub_comments_{note_id}.json"
        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


def append_sub_api_log(output_dir: Path, note_id: str, log_entry: Dict[str, Any]) -> None:
    """è¿½åŠ å­è¯„è®º API æ—¥å¿—"""
    with file_lock:
        log_file = output_dir / f"sub_api_log_{note_id}.jsonl"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')


def save_sub_raw_response(output_dir: Path, note_id: str, comment_id: str, page: int, response_data: Dict[str, Any]) -> None:
    """ä¿å­˜å­è¯„è®ºåŸå§‹å“åº”"""
    raw_dir = output_dir / "raw" / "sub"
    raw_dir.mkdir(parents=True, exist_ok=True)
    # ä½¿ç”¨ comment_id å’Œ page ä½œä¸ºæ–‡ä»¶åï¼Œé¿å…è¦†ç›–
    raw_file = raw_dir / f"sub_{comment_id}_page{page}.json"
    with open(raw_file, 'w', encoding='utf-8') as f:
        json.dump(response_data, f, ensure_ascii=False, indent=2)


def get_sub_comments_api(
    api_key: str,
    note_id: str,
    comment_id: str,
    cursor: str = ""
) -> Dict[str, Any]:
    """
    è·å–å­è¯„è®º API
    
    ä½¿ç”¨ App API: /api/v1/xiaohongshu/app/get_sub_comments
    """
    url = "https://api.tikhub.io/api/v1/xiaohongshu/app/get_sub_comments"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'note_id': note_id,
        'comment_id': comment_id
    }
    
    if cursor:
        params['start'] = cursor
    
    request_info = {
        'url': url,
        'method': 'GET',
        'params': params.copy(),
        'timestamp': datetime.now().isoformat()
    }
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        response_info = {
            'status_code': response.status_code,
            'timestamp': datetime.now().isoformat(),
            'success': response.status_code == 200,
            'error': None
        }
        
        if response.status_code == 200:
            result = response.json()
            return {
                'success': True,
                'data': result,
                'request': request_info,
                'response': response_info
            }
        else:
            response_info['error'] = response.text[:500]
            return {
                'success': False,
                'error': f"HTTP {response.status_code}: {response.text[:200]}",
                'request': request_info,
                'response': response_info
            }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'request': request_info,
            'response': {
                'status_code': None,
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e)
            }
        }


def extract_sub_comment_info(sub: Dict[str, Any]) -> Dict[str, Any]:
    """æå–å­è¯„è®ºå…³é”®ä¿¡æ¯"""
    user = sub.get('user', {})
    target = sub.get('target_comment', {})
    target_user = target.get('user', {}) if target else {}
    
    return {
        'id': sub.get('id'),
        'content': sub.get('content', ''),
        'time': sub.get('time'),
        'user_nickname': user.get('nickname', ''),
        'user_id': user.get('userid', ''),
        'like_count': sub.get('like_count', 0),
        'reply_to_nickname': target_user.get('nickname', ''),
        'reply_to_user_id': target_user.get('userid', ''),
        'ip_location': sub.get('ip_location', '')
    }


def fetch_single_comment_subs(
    api_key: str,
    note_id: str,
    comment_id: str,
    expected_count: int,
    output_dir: Path,
    progress: Dict[str, Any],
    sub_data: Dict[str, Any],
    max_pages: int = 50,
    request_delay: float = 0.3
) -> int:
    """
    è·å–å•ä¸ªè¯„è®ºçš„æ‰€æœ‰å­è¯„è®º
    
    Returns:
        è·å–åˆ°çš„å­è¯„è®ºæ•°é‡
    """
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
    if comment_id in progress.get('completed_comment_ids', []):
        existing = sub_data.get('sub_comments', {}).get(comment_id, [])
        print(f"   â­ï¸  è¯„è®º {comment_id[:12]}... å·²å®Œæˆï¼Œè·³è¿‡ (å·²æœ‰ {len(existing)} æ¡)")
        return len(existing)
    
    # è·å–å·²æœ‰çš„å­è¯„è®ºå’Œæ¸¸æ ‡
    existing_subs = sub_data.get('sub_comments', {}).get(comment_id, [])
    existing_ids = set(s['id'] for s in existing_subs)
    cursor = progress.get('in_progress', {}).get(comment_id, '')
    
    print(f"   ğŸ“¥ è¯„è®º {comment_id[:12]}... (é¢„æœŸ {expected_count} æ¡ï¼Œå·²æœ‰ {len(existing_ids)} æ¡)")
    
    page = 0
    new_count = 0
    
    while page < max_pages:
        page += 1
        
        # è°ƒç”¨ API
        result = get_sub_comments_api(api_key, note_id, comment_id, cursor=cursor)
        
        # è®°å½• API æ—¥å¿—
        log_entry = {
            'comment_id': comment_id,
            'page': page,
            'cursor_used': cursor,
            'request': result['request'],
            'response': result['response']
        }
        append_sub_api_log(output_dir, note_id, log_entry)
        
        if not result['success']:
            print(f"      âŒ ç¬¬ {page} é¡µå¤±è´¥: {result['error']}")
            # ä¿å­˜è¿›åº¦ï¼Œä¸‹æ¬¡å¯ä»¥ç»§ç»­
            progress['in_progress'][comment_id] = cursor
            save_sub_progress(output_dir, note_id, progress)
            break
        
        # ä¿å­˜åŸå§‹å“åº”
        save_sub_raw_response(output_dir, note_id, comment_id, page, result['data'])
        
        # è§£æå“åº” (App API ç»“æ„)
        # æ£€æŸ¥ code å­—æ®µ
        if result['data'].get('code') != 200:
            print(f"      âŒ ç¬¬ {page} é¡µ API è¿”å›é”™è¯¯: {result['data'].get('message', 'Unknown')}")
            break
        
        api_data = result['data'].get('data', {})
        inner_data = api_data.get('data', {})
        comments = inner_data.get('comments', [])
        
        if not comments:
            break
        
        # å¤„ç†å­è¯„è®º
        page_new = 0
        for sub in comments:
            sub_id = sub.get('id')
            if sub_id and sub_id not in existing_ids:
                sub_info = extract_sub_comment_info(sub)
                existing_subs.append(sub_info)
                existing_ids.add(sub_id)
                page_new += 1
                new_count += 1
        
        # æ›´æ–°æ•°æ®
        if comment_id not in sub_data['sub_comments']:
            sub_data['sub_comments'][comment_id] = []
        sub_data['sub_comments'][comment_id] = existing_subs
        
        # ä½¿ç”¨æœ€åä¸€æ¡è¯„è®ºçš„ ID ä½œä¸ºæ¸¸æ ‡
        new_cursor = comments[-1].get('id', '') if comments else ''
        cursor = new_cursor
        progress['in_progress'][comment_id] = cursor
        
        # App API æ¯é¡µè¿”å›çº¦ 5 æ¡ï¼Œå¦‚æœè¿”å›æ•°é‡å°‘äº 5 æ¡è¯´æ˜æ²¡æœ‰æ›´å¤šäº†
        # æˆ–è€…å·²è·å–æ•°é‡è¾¾åˆ°é¢„æœŸæ•°é‡
        has_more = len(comments) >= 5 and len(existing_subs) < expected_count
        
        # ç«‹å³ä¿å­˜
        save_sub_comments_data(output_dir, note_id, sub_data)
        save_sub_progress(output_dir, note_id, progress)
        
        if not has_more:
            break
        
        time.sleep(request_delay)
    
    # æ ‡è®°å®Œæˆ
    if comment_id not in progress['completed_comment_ids']:
        progress['completed_comment_ids'].append(comment_id)
    if comment_id in progress.get('in_progress', {}):
        del progress['in_progress'][comment_id]
    save_sub_progress(output_dir, note_id, progress)
    
    total = len(existing_subs)
    print(f"      âœ… å®Œæˆï¼Œæ–°å¢ {new_count} æ¡ï¼Œå…± {total}/{expected_count} æ¡")
    
    return total


def fetch_all_sub_comments(
    api_key: str,
    note_id: str,
    output_dir: Path,
    min_sub_count: int = 5,
    max_concurrent: int = 5,
    request_delay: float = 0.3
) -> None:
    """
    è·å–æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å­è¯„è®º
    """
    # åŠ è½½ä¸»è¯„è®ºæ•°æ®
    main_comments_file = output_dir / f"main_comments_{note_id}.json"
    if not main_comments_file.exists():
        print(f"âŒ æœªæ‰¾åˆ°ä¸»è¯„è®ºæ–‡ä»¶: {main_comments_file}")
        return
    
    with open(main_comments_file, 'r', encoding='utf-8') as f:
        main_data = json.load(f)
    
    # ç­›é€‰éœ€è¦è·å–å­è¯„è®ºçš„è¯„è®º
    comments_to_fetch = [
        c for c in main_data['comments']
        if c.get('sub_comment_count', 0) >= min_sub_count
    ]
    
    # æŒ‰å­è¯„è®ºæ•°é™åºæ’åº
    comments_to_fetch.sort(key=lambda x: x['sub_comment_count'], reverse=True)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ è·å–å­è¯„è®º")
    print(f"{'='*60}")
    print(f"   ç¬”è®° ID: {note_id}")
    print(f"   å­è¯„è®ºæ•°é˜ˆå€¼: >= {min_sub_count}")
    print(f"   ç¬¦åˆæ¡ä»¶çš„è¯„è®ºæ•°: {len(comments_to_fetch)}")
    print(f"   é¢„è®¡å­è¯„è®ºæ€»æ•°: {sum(c['sub_comment_count'] for c in comments_to_fetch)}")
    
    # åŠ è½½è¿›åº¦å’Œæ•°æ®
    progress = load_sub_progress(output_dir, note_id)
    sub_data = load_sub_comments_data(output_dir, note_id)
    
    completed = set(progress.get('completed_comment_ids', []))
    to_fetch = [c for c in comments_to_fetch if c['id'] not in completed]
    
    print(f"   å·²å®Œæˆ: {len(completed)} ä¸ªè¯„è®º")
    print(f"   å¾…è·å–: {len(to_fetch)} ä¸ªè¯„è®º")
    print(f"{'='*60}")
    
    if not to_fetch:
        print("âœ… æ‰€æœ‰å­è¯„è®ºå·²è·å–å®Œæˆ")
        # ç»Ÿè®¡æ€»æ•°
        total_subs = sum(len(subs) for subs in sub_data.get('sub_comments', {}).values())
        print(f"   å­è¯„è®ºæ€»æ•°: {total_subs}")
        return
    
    # ä¸²è¡Œè·å–ï¼ˆå› ä¸ºè¦ä¿è¯è¿›åº¦æ­£ç¡®ä¿å­˜ï¼‰
    for i, comment in enumerate(comments_to_fetch, 1):
        comment_id = comment['id']
        expected = comment['sub_comment_count']
        
        print(f"\n[{i}/{len(comments_to_fetch)}] å¤„ç†è¯„è®º: {comment['content'][:30]}...")
        
        fetch_single_comment_subs(
            api_key=api_key,
            note_id=note_id,
            comment_id=comment_id,
            expected_count=expected,
            output_dir=output_dir,
            progress=progress,
            sub_data=sub_data,
            request_delay=request_delay
        )
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"ğŸ“Š è·å–å®Œæˆ")
    total_subs = sum(len(subs) for subs in sub_data.get('sub_comments', {}).values())
    print(f"   å­è¯„è®ºæ€»æ•°: {total_subs}")
    print(f"{'='*60}")


def main():
    import sys
    
    print("=" * 60)
    print("å°çº¢ä¹¦å­è¯„è®ºè·å–å·¥å…·")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    api_key = load_api_key()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    # è·å–ç›®æ ‡å¸–å­ ID
    note_ids = config.get('ç›®æ ‡å¸–å­', {}).get('note_ids', [])
    if not note_ids:
        print("âŒ æœªé…ç½®ç›®æ ‡å¸–å­ ID")
        return
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šå¸–å­ç´¢å¼•æˆ– ID
    if len(sys.argv) > 1:
        arg = sys.argv[1]
        if arg.startswith('--index='):
            index = int(arg.split('=')[1])
            if index >= len(note_ids):
                print(f"âŒ ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼Œå…± {len(note_ids)} ä¸ªå¸–å­")
                return
            note_id = note_ids[index]
        elif arg.startswith('--id='):
            note_id = arg.split('=')[1]
        else:
            note_id = arg
    else:
        note_id = note_ids[0]
    
    # è·å–é…ç½®å‚æ•°
    min_sub_count = config.get('å­è¯„è®ºè·å–', {}).get('sub_comment_threshold', 5)
    max_concurrent = config.get('å¹¶å‘è®¾ç½®', {}).get('max_concurrent', 5)
    request_delay = config.get('è¯·æ±‚é—´éš”', {}).get('request_delay', 0.3)
    
    # å¼€å§‹è·å–
    fetch_all_sub_comments(
        api_key=api_key,
        note_id=note_id,
        output_dir=output_dir,
        min_sub_count=min_sub_count,
        max_concurrent=max_concurrent,
        request_delay=request_delay
    )


if __name__ == "__main__":
    main()
