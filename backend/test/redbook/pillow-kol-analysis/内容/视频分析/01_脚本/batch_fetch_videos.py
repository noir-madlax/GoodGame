#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹é‡è·å–è§†é¢‘è¯¦æƒ…å’Œä¸‹è½½è§†é¢‘

è§£å†³APIè°ƒç”¨å¤±è´¥ç‡é«˜çš„é—®é¢˜ï¼š
1. ä½¿ç”¨å¤šä¸ªAPIç«¯ç‚¹å°è¯•
2. å¢åŠ é‡è¯•æœºåˆ¶
3. æ‰¹é‡å¤„ç†å¹¶ä¿å­˜è¿›åº¦
"""

import os
import json
import asyncio
import aiohttp
import aiofiles
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
import logging
import random

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é¡¹ç›®è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent
DATA_DIR = PROJECT_DIR / "02_è§†é¢‘æ•°æ®"

# åŠ è½½ç¯å¢ƒå˜é‡
BACKEND_DIR = Path("/Users/rigel/project/hdl-tikhub-goodgame/backend")
load_dotenv(BACKEND_DIR / '.env')


class VideoFetcher:
    """è§†é¢‘è·å–å™¨ - æ”¯æŒå¤šAPIç«¯ç‚¹å’Œé‡è¯•"""
    
    def __init__(self):
        self.token = os.getenv('JUSTONEAPI_API_KEY', '')
        self.base_url = "https://api.justoneapi.com"
        self.semaphore = asyncio.Semaphore(3)  # å¹¶å‘æ§åˆ¶
        self.delay = 1.0  # APIè°ƒç”¨å»¶è¿Ÿ
        
        # APIç«¯ç‚¹åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        self.api_endpoints = [
            # è’²å…¬è‹±solaræ¥å£ï¼ˆæœ€ç¨³å®šï¼‰
            {
                'name': 'pgy_solar',
                'url': '/api/xiaohongshu-pgy/api/solar/note/noteId/detail/v1',
                'params': lambda note_id: {'token': self.token, 'noteId': note_id},
                'extract': self._extract_from_solar
            },
            # XHSåŸç”Ÿæ¥å£v5
            {
                'name': 'xhs_v5',
                'url': '/api/xiaohongshu/note/detail/v5',
                'params': lambda note_id: {'token': self.token, 'note_id': note_id},
                'extract': self._extract_from_xhs_v5
            },
        ]
        
        # ç»Ÿè®¡
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'downloaded': 0,
            'download_failed': 0
        }
    
    def _extract_from_solar(self, data: Dict) -> Optional[str]:
        """ä»è’²å…¬è‹±solaræ¥å£æå–è§†é¢‘URL"""
        if data.get('code') != 0:
            return None
        video_info = data.get('data', {}).get('videoInfo', {})
        return video_info.get('videoUrl')
    
    def _extract_from_xhs_v5(self, data: Dict) -> Optional[str]:
        """ä»XHS v5æ¥å£æå–è§†é¢‘URL"""
        if data.get('code') != 0:
            return None
        data_content = data.get('data', {})
        video = data_content.get('video', {})
        media = video.get('media', {})
        stream = media.get('stream', {})
        h264 = stream.get('h264', [])
        if h264:
            return h264[0].get('master_url')
        return None
    
    async def fetch_video_url(self, session: aiohttp.ClientSession, 
                               note_id: str) -> Tuple[Optional[str], Optional[Dict]]:
        """è·å–è§†é¢‘URLï¼ˆå°è¯•å¤šä¸ªAPIç«¯ç‚¹ï¼‰"""
        async with self.semaphore:
            for endpoint in self.api_endpoints:
                try:
                    url = f"{self.base_url}{endpoint['url']}"
                    params = endpoint['params'](note_id)
                    
                    async with session.get(url, params=params,
                                          timeout=aiohttp.ClientTimeout(total=30)) as resp:
                        if resp.status == 200:
                            result = await resp.json()
                            video_url = endpoint['extract'](result)
                            if video_url:
                                logger.debug(f"âœ… {note_id} via {endpoint['name']}")
                                return video_url, result.get('data', {})
                            else:
                                code = result.get('code', 'unknown')
                                logger.debug(f"âš ï¸ {note_id} via {endpoint['name']}: code={code}")
                except Exception as e:
                    logger.debug(f"âŒ {note_id} via {endpoint['name']}: {e}")
                
                # çŸ­æš‚å»¶è¿Ÿåå°è¯•ä¸‹ä¸€ä¸ªç«¯ç‚¹
                await asyncio.sleep(0.3)
            
            # æ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥
            return None, None
    
    async def download_video(self, session: aiohttp.ClientSession,
                              video_url: str, save_path: Path) -> bool:
        """ä¸‹è½½è§†é¢‘æ–‡ä»¶"""
        if save_path.exists() and save_path.stat().st_size > 10000:
            logger.info(f"â­ï¸ å·²å­˜åœ¨: {save_path.name}")
            return True
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
            'Referer': 'https://www.xiaohongshu.com/'
        }
        
        try:
            async with session.get(video_url, headers=headers,
                                  timeout=aiohttp.ClientTimeout(total=300)) as resp:
                if resp.status == 200:
                    save_path.parent.mkdir(parents=True, exist_ok=True)
                    async with aiofiles.open(save_path, 'wb') as f:
                        total = 0
                        async for chunk in resp.content.iter_chunked(1024 * 1024):
                            await f.write(chunk)
                            total += len(chunk)
                    
                    if total > 10000:
                        logger.info(f"ğŸ“¥ ä¸‹è½½å®Œæˆ: {save_path.name} ({total/1024/1024:.1f}MB)")
                        return True
                    else:
                        save_path.unlink()
                        return False
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥ {save_path.name}: {e}")
        
        return False
    
    def get_kol_top5_videos(self) -> List[Dict]:
        """ä»æ•°æ®åº“è·å–æ¯ä¸ªKOLçš„TOP5è§†é¢‘"""
        from supabase import create_client
        
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        client = create_client(url, key)
        
        # è·å–å…¥é€‰KOL
        kol_response = client.table('gg_pgy_kol_analysis_result').select(
            'kol_id, kol_name, fans_count_current'
        ).eq('post_frequency_pass', True
        ).eq('comment_gt_20_pass', True
        ).eq('read_fans_ratio_pass', True
        ).execute()
        
        kol_map = {row['kol_id']: row for row in kol_response.data}
        logger.info(f"è·å–åˆ° {len(kol_map)} ä½å…¥é€‰KOL")
        
        all_videos = []
        
        for kol_id, kol_info in kol_map.items():
            # è·å–è¯¥KOLçš„è§†é¢‘ç¬”è®°ï¼ŒæŒ‰äº’åŠ¨æ’åºå–TOP5
            notes_response = client.table('gg_pgy_kol_notes').select(
                'note_id, title, is_video, is_advertise, '
                'read_num, like_num, collect_num, comment_num, publish_date, img_url'
            ).eq('kol_id', kol_id
            ).eq('is_video', True
            ).order('like_num', desc=True
            ).limit(5
            ).execute()
            
            if not notes_response.data:
                logger.warning(f"KOL {kol_info.get('kol_name')} æ— è§†é¢‘")
                continue
            
            for i, note in enumerate(notes_response.data):
                total_interact = (
                    (note.get('like_num') or 0) + 
                    (note.get('collect_num') or 0) + 
                    (note.get('comment_num') or 0)
                )
                
                video = {
                    'note_id': note['note_id'],
                    'kol_id': kol_id,
                    'kol_name': kol_info.get('kol_name') or 'Unknown',
                    'title': note.get('title') or '',
                    'content': note.get('content') or '',
                    'is_advertise': note.get('is_advertise', False),
                    'publish_date': str(note.get('publish_date', '')),
                    'read_num': note.get('read_num') or 0,
                    'like_num': note.get('like_num') or 0,
                    'collect_num': note.get('collect_num') or 0,
                    'comment_num': note.get('comment_num') or 0,
                    'total_interact': total_interact,
                    'rank': i + 1,
                    'fans_count': kol_info.get('fans_count_current') or 0,
                    'cover_url': note.get('img_url'),
                    'video_url': None,
                    'video_duration': 0,
                    'downloaded': False,
                    'file_path': None
                }
                all_videos.append(video)
        
        self.stats['total'] = len(all_videos)
        logger.info(f"å…±éœ€å¤„ç† {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos
    
    async def process_video(self, session: aiohttp.ClientSession, video: Dict) -> Dict:
        """å¤„ç†å•ä¸ªè§†é¢‘ï¼šè·å–URLå¹¶ä¸‹è½½"""
        note_id = video['note_id']
        kol_name = video['kol_name']
        
        # 1. è·å–è§†é¢‘URL
        video_url, detail_data = await self.fetch_video_url(session, note_id)
        
        if video_url:
            video['video_url'] = video_url
            if detail_data:
                video['video_duration'] = detail_data.get('videoInfo', {}).get('meta', {}).get('duration', 0)
                # è¡¥å……contentå¦‚æœä¸ºç©º
                if not video['content']:
                    video['content'] = detail_data.get('content', '')
            
            self.stats['success'] += 1
            
            # 2. ä¸‹è½½è§†é¢‘
            kol_dir = DATA_DIR / f"kol_{video['kol_id']}" / "videos"
            video_file = kol_dir / f"{note_id}.mp4"
            
            downloaded = await self.download_video(session, video_url, video_file)
            if downloaded:
                video['downloaded'] = True
                video['file_path'] = str(video_file)
                self.stats['downloaded'] += 1
            else:
                self.stats['download_failed'] += 1
            
            logger.info(f"âœ… {kol_name}: {video['title'][:25]}...")
        else:
            self.stats['failed'] += 1
            logger.warning(f"âŒ {kol_name}: {note_id} - æ— æ³•è·å–URL")
        
        await asyncio.sleep(self.delay + random.uniform(0, 0.5))
        return video
    
    def save_results(self, videos: List[Dict]):
        """ä¿å­˜ç»“æœ"""
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰KOLåˆ†ç»„ä¿å­˜
        kol_videos = {}
        for v in videos:
            kol_id = v['kol_id']
            if kol_id not in kol_videos:
                kol_videos[kol_id] = []
            kol_videos[kol_id].append(v)
        
        for kol_id, kol_vids in kol_videos.items():
            kol_dir = DATA_DIR / f"kol_{kol_id}"
            kol_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜è¯¥KOLçš„å…ƒæ•°æ®
            metadata = {
                'kol_id': kol_id,
                'kol_name': kol_vids[0]['kol_name'],
                'fans_count': kol_vids[0]['fans_count'],
                'video_count': len(kol_vids),
                'videos_with_url': sum(1 for v in kol_vids if v['video_url']),
                'videos_downloaded': sum(1 for v in kol_vids if v['downloaded']),
                'videos': kol_vids
            }
            
            metadata_file = kol_dir / "metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        summary = {
            'generated_at': datetime.now().isoformat(),
            'stats': self.stats,
            'total_kols': len(kol_videos),
            'total_videos': len(videos),
            'videos_with_url': sum(1 for v in videos if v['video_url']),
            'videos_downloaded': sum(1 for v in videos if v['downloaded']),
            'videos': videos
        }
        
        summary_file = DATA_DIR / "video_list.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {DATA_DIR}")
    
    async def run(self, skip_download: bool = False):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰¹é‡è·å–è§†é¢‘")
        logger.info("=" * 60)
        
        # 1. è·å–éœ€è¦å¤„ç†çš„è§†é¢‘åˆ—è¡¨
        videos = self.get_kol_top5_videos()
        
        # 2. æ‰¹é‡å¤„ç†
        async with aiohttp.ClientSession() as session:
            # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹10ä¸ª
            batch_size = 10
            for i in range(0, len(videos), batch_size):
                batch = videos[i:i+batch_size]
                logger.info(f"\nå¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(videos)-1)//batch_size + 1}")
                
                tasks = [self.process_video(session, v) for v in batch]
                results = await asyncio.gather(*tasks)
                
                # æ›´æ–°videosåˆ—è¡¨
                for j, result in enumerate(results):
                    videos[i+j] = result
                
                # æ¯æ‰¹æ¬¡åä¿å­˜è¿›åº¦
                self.save_results(videos)
        
        # 3. æ‰“å°ç»Ÿè®¡
        self._print_stats()
        
        return videos
    
    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡"""
        print("\n" + "=" * 60)
        print("å¤„ç†å®Œæˆ")
        print("=" * 60)
        print(f"æ€»è§†é¢‘æ•°: {self.stats['total']}")
        print(f"URLè·å–æˆåŠŸ: {self.stats['success']}")
        print(f"URLè·å–å¤±è´¥: {self.stats['failed']}")
        print(f"ä¸‹è½½æˆåŠŸ: {self.stats['downloaded']}")
        print(f"ä¸‹è½½å¤±è´¥: {self.stats['download_failed']}")
        
        # æŒ‰KOLç»Ÿè®¡
        video_list_file = DATA_DIR / "video_list.json"
        if video_list_file.exists():
            with open(video_list_file, 'r') as f:
                data = json.load(f)
            
            print("\nå„KOLè§†é¢‘æƒ…å†µ:")
            kol_stats = {}
            for v in data['videos']:
                kol_name = v['kol_name']
                if kol_name not in kol_stats:
                    kol_stats[kol_name] = {'total': 0, 'with_url': 0, 'downloaded': 0}
                kol_stats[kol_name]['total'] += 1
                if v.get('video_url'):
                    kol_stats[kol_name]['with_url'] += 1
                if v.get('downloaded'):
                    kol_stats[kol_name]['downloaded'] += 1
            
            for name, stats in sorted(kol_stats.items()):
                print(f"  {name[:15]:<16}: {stats['total']}ä¸ª, URL {stats['with_url']}ä¸ª, ä¸‹è½½ {stats['downloaded']}ä¸ª")
        
        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='æ‰¹é‡è·å–è§†é¢‘')
    parser.add_argument('--skip-download', action='store_true', help='è·³è¿‡è§†é¢‘ä¸‹è½½')
    args = parser.parse_args()
    
    fetcher = VideoFetcher()
    await fetcher.run(skip_download=args.skip_download)


if __name__ == "__main__":
    asyncio.run(main())
