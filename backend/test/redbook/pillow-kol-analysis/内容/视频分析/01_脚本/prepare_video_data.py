#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å‡†å¤‡è§†é¢‘åˆ†ææ•°æ® - ä¸€ç«™å¼è„šæœ¬

åŠŸèƒ½ï¼š
1. ä»æ•°æ®åº“è·å–31ä½KOLçš„TOP5è§†é¢‘ï¼ˆæ’é™¤çº¯å›¾æ–‡åšä¸»ï¼‰
2. è°ƒç”¨APIè·å–è§†é¢‘è¯¦æƒ…ï¼ˆå«è§†é¢‘URLï¼‰
3. ä¸‹è½½è§†é¢‘æ–‡ä»¶
4. å¯¼å‡ºåˆ†ææ‰€éœ€çš„å…ƒæ•°æ®JSON
"""

import os
import json
import asyncio
import aiohttp
import aiofiles
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field, asdict
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é¡¹ç›®è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent
DATA_DIR = PROJECT_DIR / "02_è§†é¢‘æ•°æ®"

# åŠ è½½ç¯å¢ƒå˜é‡
BACKEND_DIR = Path("/Users/rigel/project/hdl-tikhub-goodgame/backend")
load_dotenv(BACKEND_DIR / '.env')


@dataclass
class VideoMetadata:
    """è§†é¢‘å…ƒæ•°æ®ï¼ˆç”¨äºAIåˆ†æï¼‰"""
    note_id: str
    kol_id: str
    kol_name: str
    title: str
    content: str = ""  # ç¬”è®°æ­£æ–‡
    is_advertise: bool = False
    publish_date: str = ""
    read_num: int = 0
    like_num: int = 0
    collect_num: int = 0
    comment_num: int = 0
    total_interact: int = 0
    rank: int = 0
    fans_count: int = 0
    video_url: Optional[str] = None
    video_duration: int = 0  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    cover_url: Optional[str] = None
    downloaded: bool = False
    file_path: Optional[str] = None


class VideoDataPreparer:
    """è§†é¢‘æ•°æ®å‡†å¤‡å™¨"""
    
    def __init__(self, concurrency: int = 5, download_concurrency: int = 3):
        self.api_concurrency = concurrency
        self.download_concurrency = download_concurrency
        self.token = os.getenv('JUSTONEAPI_API_KEY', '')
        self.base_url = "https://api.justoneapi.com"
        self.api_semaphore = asyncio.Semaphore(concurrency)
        self.download_semaphore = asyncio.Semaphore(download_concurrency)
        
        # ç»Ÿè®¡
        self.stats = {
            'total_videos': 0,
            'details_fetched': 0,
            'details_failed': 0,
            'downloaded': 0,
            'download_failed': 0,
            'skipped': 0
        }
    
    def _get_supabase_client(self):
        """è·å–Supabaseå®¢æˆ·ç«¯"""
        from supabase import create_client
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        return create_client(url, key)
    
    def get_video_list(self) -> List[VideoMetadata]:
        """ä»æ•°æ®åº“è·å–è§†é¢‘åˆ—è¡¨ï¼ˆTOP5/æ¯ä½KOLï¼ŒæŒ‰äº’åŠ¨æ’åºï¼‰"""
        client = self._get_supabase_client()
        
        # SQLé€»è¾‘ï¼š32ä½å…¥é€‰KOLä¸­æœ‰è§†é¢‘çš„ï¼Œæ¯äººTOP5
        # å…ˆè·å–å…¥é€‰KOL
        kol_response = client.table('gg_pgy_kol_analysis_result').select(
            'kol_id, kol_name, fans_count_current'
        ).eq('post_frequency_pass', True
        ).eq('comment_gt_20_pass', True
        ).eq('read_fans_ratio_pass', True
        ).execute()
        
        kol_map = {row['kol_id']: row for row in kol_response.data}
        logger.info(f"è·å–åˆ° {len(kol_map)} ä½å…¥é€‰KOL")
        
        all_videos = []
        
        for kol_id, kol_info in kol_map.items():
            # è·å–è¯¥KOLçš„è§†é¢‘ç¬”è®°ï¼ŒæŒ‰äº’åŠ¨æ’åº
            notes_response = client.table('gg_pgy_kol_notes').select(
                'note_id, title, is_video, is_advertise, '
                'read_num, like_num, collect_num, comment_num, publish_date, img_url'
            ).eq('kol_id', kol_id
            ).eq('is_video', True
            ).order('like_num', desc=True
            ).limit(5
            ).execute()
            
            if not notes_response.data:
                logger.warning(f"KOL {kol_info.get('kol_name')} æ— è§†é¢‘")
                continue
            
            for i, note in enumerate(notes_response.data):
                total_interact = (
                    (note.get('like_num') or 0) + 
                    (note.get('collect_num') or 0) + 
                    (note.get('comment_num') or 0)
                )
                
                video = VideoMetadata(
                    note_id=note['note_id'],
                    kol_id=kol_id,
                    kol_name=kol_info.get('kol_name') or 'Unknown',
                    title=note.get('title') or '',
                    is_advertise=note.get('is_advertise', False),
                    publish_date=str(note.get('publish_date', '')),
                    read_num=note.get('read_num') or 0,
                    like_num=note.get('like_num') or 0,
                    collect_num=note.get('collect_num') or 0,
                    comment_num=note.get('comment_num') or 0,
                    total_interact=total_interact,
                    rank=i + 1,
                    fans_count=kol_info.get('fans_count_current') or 0,
                    cover_url=note.get('img_url')
                )
                all_videos.append(video)
        
        self.stats['total_videos'] = len(all_videos)
        logger.info(f"å…±è·å– {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos
    
    async def fetch_video_detail(self, session: aiohttp.ClientSession, 
                                  video: VideoMetadata) -> VideoMetadata:
        """è·å–è§†é¢‘è¯¦æƒ…"""
        async with self.api_semaphore:
            url = f"{self.base_url}/api/xiaohongshu-pgy/api/solar/note/noteId/detail/v1"
            params = {'token': self.token, 'noteId': video.note_id}
            
            try:
                async with session.get(url, params=params, 
                                       timeout=aiohttp.ClientTimeout(total=30)) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        if result.get('code') == 0:
                            data = result.get('data', {})
                            
                            # æå–è§†é¢‘URL
                            video_info = data.get('videoInfo', {})
                            video.video_url = video_info.get('videoUrl')
                            video.video_duration = video_info.get('meta', {}).get('duration', 0)
                            
                            # æå–æ­£æ–‡å†…å®¹
                            video.content = data.get('content', '')
                            
                            self.stats['details_fetched'] += 1
                            logger.info(f"âœ… {video.kol_name} - {video.title[:20]}...")
                        else:
                            self.stats['details_failed'] += 1
                            logger.warning(f"âš ï¸ {video.note_id}: APIé”™è¯¯ {result.get('code')}")
                    else:
                        self.stats['details_failed'] += 1
                        logger.error(f"âŒ {video.note_id}: HTTP {resp.status}")
                        
            except Exception as e:
                self.stats['details_failed'] += 1
                logger.error(f"âŒ {video.note_id}: {e}")
            
            await asyncio.sleep(0.5)
            return video
    
    async def download_video(self, session: aiohttp.ClientSession, 
                              video: VideoMetadata) -> VideoMetadata:
        """ä¸‹è½½è§†é¢‘"""
        if not video.video_url:
            self.stats['skipped'] += 1
            return video
        
        # ç›®æ ‡æ–‡ä»¶è·¯å¾„
        kol_dir = DATA_DIR / f"kol_{video.kol_id}" / "videos"
        kol_dir.mkdir(parents=True, exist_ok=True)
        video_file = kol_dir / f"{video.note_id}.mp4"
        
        # å·²å­˜åœ¨åˆ™è·³è¿‡
        if video_file.exists() and video_file.stat().st_size > 10000:
            video.downloaded = True
            video.file_path = str(video_file)
            self.stats['skipped'] += 1
            logger.info(f"â­ï¸ å·²å­˜åœ¨: {video.kol_name} - {video.note_id}")
            return video
        
        async with self.download_semaphore:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
                'Referer': 'https://www.xiaohongshu.com/'
            }
            
            try:
                async with session.get(video.video_url, headers=headers,
                                       timeout=aiohttp.ClientTimeout(total=300)) as resp:
                    if resp.status == 200:
                        async with aiofiles.open(video_file, 'wb') as f:
                            async for chunk in resp.content.iter_chunked(1024 * 1024):
                                await f.write(chunk)
                        
                        file_size = video_file.stat().st_size
                        if file_size > 10000:
                            video.downloaded = True
                            video.file_path = str(video_file)
                            self.stats['downloaded'] += 1
                            logger.info(f"ğŸ“¥ ä¸‹è½½å®Œæˆ: {video.kol_name} ({file_size/1024/1024:.1f}MB)")
                        else:
                            video_file.unlink()
                            self.stats['download_failed'] += 1
                            logger.warning(f"âš ï¸ æ–‡ä»¶å¤ªå°: {video.note_id}")
                    else:
                        self.stats['download_failed'] += 1
                        logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {video.note_id} HTTP {resp.status}")
                        
            except Exception as e:
                self.stats['download_failed'] += 1
                logger.error(f"âŒ ä¸‹è½½å¼‚å¸¸: {video.note_id} - {e}")
        
        return video
    
    def save_metadata(self, videos: List[VideoMetadata]):
        """ä¿å­˜å…ƒæ•°æ®"""
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰KOLåˆ†ç»„ä¿å­˜
        kol_videos = {}
        for v in videos:
            if v.kol_id not in kol_videos:
                kol_videos[v.kol_id] = []
            kol_videos[v.kol_id].append(v)
        
        for kol_id, kol_vids in kol_videos.items():
            kol_dir = DATA_DIR / f"kol_{kol_id}"
            kol_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜è¯¥KOLçš„å…ƒæ•°æ®
            metadata_file = kol_dir / "metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'kol_id': kol_id,
                    'kol_name': kol_vids[0].kol_name,
                    'fans_count': kol_vids[0].fans_count,
                    'video_count': len(kol_vids),
                    'videos': [asdict(v) for v in kol_vids]
                }, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ±‡æ€»æ–‡ä»¶
        summary_file = DATA_DIR / "video_list.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                'generated_at': datetime.now().isoformat(),
                'stats': self.stats,
                'total_kols': len(kol_videos),
                'total_videos': len(videos),
                'videos': [asdict(v) for v in videos]
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {DATA_DIR}")
    
    async def run(self, skip_download: bool = False):
        """æ‰§è¡Œå®Œæ•´æµç¨‹"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹å‡†å¤‡è§†é¢‘åˆ†ææ•°æ®")
        logger.info("=" * 60)
        
        # 1. è·å–è§†é¢‘åˆ—è¡¨
        videos = self.get_video_list()
        
        # 2. è·å–è§†é¢‘è¯¦æƒ…
        logger.info("\nğŸ“¡ è·å–è§†é¢‘è¯¦æƒ…...")
        async with aiohttp.ClientSession() as session:
            tasks = [self.fetch_video_detail(session, v) for v in videos]
            videos = await asyncio.gather(*tasks)
        
        # 3. ä¸‹è½½è§†é¢‘
        if not skip_download:
            logger.info("\nğŸ“¥ ä¸‹è½½è§†é¢‘æ–‡ä»¶...")
            async with aiohttp.ClientSession() as session:
                tasks = [self.download_video(session, v) for v in videos]
                videos = await asyncio.gather(*tasks)
        
        # 4. ä¿å­˜å…ƒæ•°æ®
        self.save_metadata(videos)
        
        # 5. æ‰“å°ç»Ÿè®¡
        self._print_stats()
        
        return videos
    
    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("å‡†å¤‡å®Œæˆ")
        print("=" * 60)
        print(f"æ€»è§†é¢‘æ•°: {self.stats['total_videos']}")
        print(f"è¯¦æƒ…è·å–æˆåŠŸ: {self.stats['details_fetched']}")
        print(f"è¯¦æƒ…è·å–å¤±è´¥: {self.stats['details_failed']}")
        print(f"ä¸‹è½½æˆåŠŸ: {self.stats['downloaded']}")
        print(f"ä¸‹è½½å¤±è´¥: {self.stats['download_failed']}")
        print(f"è·³è¿‡ï¼ˆå·²å­˜åœ¨/æ— URLï¼‰: {self.stats['skipped']}")
        print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    parser = argparse.ArgumentParser(description='å‡†å¤‡è§†é¢‘åˆ†ææ•°æ®')
    parser.add_argument('--skip-download', action='store_true', help='è·³è¿‡è§†é¢‘ä¸‹è½½')
    parser.add_argument('--limit', type=int, default=0, help='é™åˆ¶å¤„ç†è§†é¢‘æ•°é‡ï¼ˆ0=å…¨éƒ¨ï¼‰')
    args = parser.parse_args()
    
    preparer = VideoDataPreparer()
    await preparer.run(skip_download=args.skip_download)


if __name__ == "__main__":
    asyncio.run(main())
