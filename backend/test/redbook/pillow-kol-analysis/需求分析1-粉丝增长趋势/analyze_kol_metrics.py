#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
KOL æ•°æ®åˆ†æè„šæœ¬ - æ•å¤´é¡¹ç›®

åŠŸèƒ½ï¼š
1. åˆ†æç²‰ä¸å¢é•¿è¶‹åŠ¿ï¼ˆéœ€æ±‚1ï¼‰
2. å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“
3. ç”Ÿæˆå¢é•¿æ’åæŠ¥å‘Š
"""

import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from dotenv import load_dotenv
import statistics
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class FansTrendAnalysis:
    """ç²‰ä¸è¶‹åŠ¿åˆ†æç»“æœ"""
    fans_count_current: int
    fans_count_30d_ago: int
    fans_growth_30d: int
    fans_growth_rate_30d: float
    fans_trend_status: str  # rising/stable/declining
    fans_trend_detail: Dict[str, Any]


@dataclass 
class KolAnalysisResult:
    """KOL åˆ†æç»“æœ"""
    kol_id: str
    kol_name: str
    project_name: str = "æ•å¤´åˆ†æ"
    
    # éœ€æ±‚1: ç²‰ä¸å¢é•¿è¶‹åŠ¿
    fans_count_current: Optional[int] = None
    fans_count_30d_ago: Optional[int] = None
    fans_growth_30d: Optional[int] = None
    fans_growth_rate_30d: Optional[float] = None
    fans_trend_status: Optional[str] = None
    fans_trend_detail: Optional[Dict] = None
    
    # åˆ†æå…ƒæ•°æ®
    analysis_date: Optional[str] = None


class KolMetricsAnalyzer:
    """KOL æ•°æ®åˆ†æå™¨"""
    
    def __init__(self, data_dir: str = None):
        self.data_dir = Path(data_dir) if data_dir else Path(__file__).parent / "output" / "api_data"
        self.results: List[KolAnalysisResult] = []
        self._init_supabase()
    
    def _init_supabase(self):
        """åˆå§‹åŒ– Supabase è¿æ¥"""
        backend_dir = Path(__file__).parent.parent.parent.parent
        env_path = backend_dir / '.env'
        
        if env_path.exists():
            load_dotenv(env_path)
        
        from supabase import create_client
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        
        if not url or not key:
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® SUPABASE_URL å’Œ SUPABASE_KEY")
        
        self.supabase = create_client(url, key)
        logger.info("Supabase è¿æ¥æˆåŠŸ")
    
    def load_kol_data(self, kol_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å•ä¸ª KOL çš„ API æ•°æ®"""
        kol_dir = self.data_dir / f"kol_{kol_id}"
        data_file = kol_dir / "all_data.json"
        
        if not data_file.exists():
            logger.warning(f"æœªæ‰¾åˆ° KOL æ•°æ®æ–‡ä»¶: {kol_id}")
            return None
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®ï¼ˆé skippedï¼‰
        apis = data.get('apis', {})
        has_real_data = False
        for api_name, api_data in apis.items():
            if isinstance(api_data, dict) and api_data.get('code') == 0:
                has_real_data = True
                break
        
        if not has_real_data:
            logger.warning(f"KOL {kol_id} æ²¡æœ‰æœ‰æ•ˆçš„ API æ•°æ®")
            return None
        
        return data
    
    def analyze_fans_trend(self, kol_data: Dict[str, Any]) -> Optional[FansTrendAnalysis]:
        """
        åˆ†æéœ€æ±‚1ï¼šç²‰ä¸å¢é•¿è¶‹åŠ¿
        
        è¯„ä¼°ç»´åº¦ï¼š
        1. 30å¤©ç²‰ä¸å¢é•¿æ•°å’Œå¢é•¿ç‡
        2. å¢é•¿è¶‹åŠ¿ç¨³å®šæ€§ï¼ˆæ˜¯å¦æŒç»­å¢é•¿ï¼Œæœ‰æ— å¤§æ³¢åŠ¨ï¼‰
        3. ä¸åŒè¡Œå¯¹æ¯”çš„è¡¨ç°
        """
        fans_trend = kol_data.get('apis', {}).get('kol_fans_trend', {})
        fans_summary = kol_data.get('apis', {}).get('kol_fans_summary', {})
        
        if fans_trend.get('code') != 0:
            return None
        
        trend_data = fans_trend.get('data', {})
        trend_list = trend_data.get('list', [])
        
        if not trend_list or len(trend_list) < 7:
            logger.warning(f"ç²‰ä¸è¶‹åŠ¿æ•°æ®ä¸è¶³")
            return None
        
        # åŸºç¡€æ•°æ®
        fans_current = trend_list[-1]['num'] if trend_list else 0
        fans_30d_ago = trend_list[0]['num'] if trend_list else 0
        fans_growth = fans_current - fans_30d_ago
        fans_growth_rate = (fans_growth / fans_30d_ago * 100) if fans_30d_ago > 0 else 0
        
        # è®¡ç®—è¶‹åŠ¿ç¨³å®šæ€§
        daily_changes = []
        for i in range(1, len(trend_list)):
            change = trend_list[i]['num'] - trend_list[i-1]['num']
            daily_changes.append(change)
        
        # ç»Ÿè®¡åˆ†æ
        positive_days = sum(1 for c in daily_changes if c > 0)
        negative_days = sum(1 for c in daily_changes if c < 0)
        zero_days = sum(1 for c in daily_changes if c == 0)
        avg_daily_change = statistics.mean(daily_changes) if daily_changes else 0
        
        # è®¡ç®—æ³¢åŠ¨æ€§ï¼ˆæ ‡å‡†å·®/å¹³å‡å€¼ï¼‰
        if daily_changes and avg_daily_change != 0:
            volatility = statistics.stdev(daily_changes) / abs(avg_daily_change) if len(daily_changes) > 1 else 0
        else:
            volatility = 0
        
        # åˆ¤æ–­è¶‹åŠ¿çŠ¶æ€
        if fans_growth_rate > 5:
            trend_status = "rising"
        elif fans_growth_rate < -2:
            trend_status = "declining"
        else:
            trend_status = "stable"
        
        # è·å–åŒè¡Œå¯¹æ¯”æ•°æ®
        summary_data = fans_summary.get('data', {}) if fans_summary.get('code') == 0 else {}
        beyond_rate = summary_data.get('fansGrowthBeyondRate', '')
        
        return FansTrendAnalysis(
            fans_count_current=fans_current,
            fans_count_30d_ago=fans_30d_ago,
            fans_growth_30d=fans_growth,
            fans_growth_rate_30d=round(fans_growth_rate, 4),
            fans_trend_status=trend_status,
            fans_trend_detail={
                'positive_days': positive_days,
                'negative_days': negative_days,
                'zero_days': zero_days,
                'avg_daily_change': round(avg_daily_change, 2),
                'volatility': round(volatility, 4),
                'beyond_rate': beyond_rate,
                'daily_data': [
                    {'date': item['dateKey'], 'fans': item['num']}
                    for item in trend_list
                ]
            }
        )
    
    def analyze_single_kol(self, kol_id: str) -> Optional[KolAnalysisResult]:
        """åˆ†æå•ä¸ª KOL"""
        kol_data = self.load_kol_data(kol_id)
        if not kol_data:
            return None
        
        kol_name = kol_data.get('kol_name', 'Unknown')
        
        # åˆ†æç²‰ä¸è¶‹åŠ¿
        fans_trend = self.analyze_fans_trend(kol_data)
        
        if not fans_trend:
            logger.warning(f"KOL {kol_id} ç²‰ä¸è¶‹åŠ¿åˆ†æå¤±è´¥")
            return None
        
        result = KolAnalysisResult(
            kol_id=kol_id,
            kol_name=kol_name,
            project_name="æ•å¤´åˆ†æ",
            fans_count_current=fans_trend.fans_count_current,
            fans_count_30d_ago=fans_trend.fans_count_30d_ago,
            fans_growth_30d=fans_trend.fans_growth_30d,
            fans_growth_rate_30d=fans_trend.fans_growth_rate_30d,
            fans_trend_status=fans_trend.fans_trend_status,
            fans_trend_detail=fans_trend.fans_trend_detail,
            analysis_date=datetime.now().isoformat()
        )
        
        return result
    
    def get_all_kol_ids_from_files(self) -> List[str]:
        """ä»æ–‡ä»¶ç³»ç»Ÿè·å–æ‰€æœ‰æœ‰å®é™…æ•°æ®çš„ KOL ID åˆ—è¡¨"""
        kol_ids = []
        
        for kol_dir in sorted(self.data_dir.iterdir()):
            if not kol_dir.is_dir() or not kol_dir.name.startswith('kol_'):
                continue
            
            data_file = kol_dir / "all_data.json"
            if not data_file.exists():
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…æ•°æ®
            with open(data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            apis = data.get('apis', {})
            has_real_data = any(
                isinstance(api_data, dict) and api_data.get('code') == 0
                for api_data in apis.values()
            )
            
            if has_real_data:
                kol_id = kol_dir.name.replace('kol_', '')
                kol_ids.append(kol_id)
        
        return kol_ids
    
    def analyze_batch(self, kol_ids: List[str]) -> List[KolAnalysisResult]:
        """æ‰¹é‡åˆ†æ KOL"""
        results = []
        failed = []
        
        for i, kol_id in enumerate(kol_ids):
            logger.info(f"åˆ†æè¿›åº¦: {i+1}/{len(kol_ids)} - KOL: {kol_id}")
            
            result = self.analyze_single_kol(kol_id)
            if result:
                results.append(result)
            else:
                failed.append(kol_id)
        
        logger.info(f"åˆ†æå®Œæˆ: æˆåŠŸ {len(results)}, å¤±è´¥ {len(failed)}")
        if failed:
            logger.info(f"å¤±è´¥çš„ KOL: {failed[:10]}{'...' if len(failed) > 10 else ''}")
        
        self.results = results
        return results
    
    def save_to_db(self, results: List[KolAnalysisResult]) -> Tuple[int, int]:
        """ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“"""
        success_count = 0
        fail_count = 0
        
        for result in results:
            try:
                # è½¬æ¢ä¸ºå­—å…¸
                data = {
                    'kol_id': result.kol_id,
                    'kol_name': result.kol_name,
                    'project_name': result.project_name,
                    'fans_count_current': result.fans_count_current,
                    'fans_count_30d_ago': result.fans_count_30d_ago,
                    'fans_growth_30d': result.fans_growth_30d,
                    'fans_growth_rate_30d': result.fans_growth_rate_30d,
                    'fans_trend_status': result.fans_trend_status,
                    'fans_trend_detail': json.dumps(result.fans_trend_detail) if result.fans_trend_detail else None,
                    'analysis_date': result.analysis_date,
                    'updated_at': datetime.now().isoformat()
                }
                
                # ä½¿ç”¨ upsert æ“ä½œ
                self.supabase.table('gg_pgy_kol_analysis_result').upsert(
                    data,
                    on_conflict='kol_id,project_name'
                ).execute()
                
                success_count += 1
                
            except Exception as e:
                logger.error(f"ä¿å­˜ KOL {result.kol_id} å¤±è´¥: {e}")
                fail_count += 1
        
        return success_count, fail_count
    
    def generate_growth_ranking_report(self, results: List[KolAnalysisResult]) -> str:
        """ç”Ÿæˆå¢é•¿æ’åæŠ¥å‘Šï¼ˆæ— è¯„åˆ†ï¼‰"""
        if not results:
            return "æ²¡æœ‰åˆ†æç»“æœ"
        
        # ç»Ÿè®¡æ•°æ®
        total = len(results)
        rising = sum(1 for r in results if r.fans_trend_status == 'rising')
        stable = sum(1 for r in results if r.fans_trend_status == 'stable')
        declining = sum(1 for r in results if r.fans_trend_status == 'declining')
        
        avg_growth_rate = statistics.mean([r.fans_growth_rate_30d for r in results if r.fans_growth_rate_30d is not None])
        
        # æŒ‰å¢é•¿ç‡æ’åº
        sorted_by_growth = sorted(results, key=lambda x: x.fans_growth_rate_30d or 0, reverse=True)
        
        report = f"""# KOL ç²‰ä¸å¢é•¿æ’åæŠ¥å‘Š

> **é¡¹ç›®**: æ•å¤´åˆ†æ  
> **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
> **KOL æ•°é‡**: {total}

---

## ä¸€ã€æ•´ä½“æ¦‚å†µ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| åˆ†æ KOL æ€»æ•° | {total} |
| ä¸Šå‡æœŸ (>5%) | {rising} ({rising/total*100:.1f}%) |
| ç¨³å®šæœŸ (-2%~5%) | {stable} ({stable/total*100:.1f}%) |
| ä¸‹é™æœŸ (<-2%) | {declining} ({declining/total*100:.1f}%) |
| å¹³å‡å¢é•¿ç‡ | {avg_growth_rate:.2f}% |

---

## äºŒã€å®Œæ•´å¢é•¿ç‡æ’å

| æ’å | KOLåç§° | å½“å‰ç²‰ä¸ | 30å¤©å¢é•¿ | å¢é•¿ç‡ | è¶‹åŠ¿çŠ¶æ€ |
|------|---------|----------|----------|--------|----------|
"""
        for i, r in enumerate(sorted_by_growth, 1):
            growth_sign = '+' if r.fans_growth_30d >= 0 else ''
            status_emoji = {'rising': 'ğŸŸ¢', 'stable': 'ğŸŸ¡', 'declining': 'ğŸ”´'}.get(r.fans_trend_status, '')
            report += f"| {i} | {r.kol_name} | {r.fans_count_current:,} | {growth_sign}{r.fans_growth_30d:,} | {r.fans_growth_rate_30d:.2f}% | {status_emoji} {r.fans_trend_status} |\n"
        
        report += f"""

---

## ä¸‰ã€è¶‹åŠ¿çŠ¶æ€è¯´æ˜

- ğŸŸ¢ **rising (ä¸Šå‡æœŸ)**: 30å¤©å¢é•¿ç‡ > 5%
- ğŸŸ¡ **stable (ç¨³å®šæœŸ)**: 30å¤©å¢é•¿ç‡åœ¨ -2% ~ 5% ä¹‹é—´
- ğŸ”´ **declining (ä¸‹é™æœŸ)**: 30å¤©å¢é•¿ç‡ < -2%

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}*
"""
        return report


def main():
    """ä¸»å‡½æ•° - å¤„ç†å…¨é‡ KOL"""
    analyzer = KolMetricsAnalyzer()
    
    # è·å–æ‰€æœ‰æœ‰å®é™…æ•°æ®çš„ KOL ID
    logger.info("æ­£åœ¨è·å–æ‰€æœ‰æœ‰æ•ˆçš„ KOL åˆ—è¡¨...")
    kol_ids = analyzer.get_all_kol_ids_from_files()
    logger.info(f"æ‰¾åˆ° {len(kol_ids)} ä¸ªæœ‰æ•ˆçš„ KOL")
    
    if not kol_ids:
        logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ KOL æ•°æ®")
        return
    
    # æ‰¹é‡åˆ†æ
    logger.info("å¼€å§‹æ‰¹é‡åˆ†æ...")
    results = analyzer.analyze_batch(kol_ids)
    logger.info(f"åˆ†æå®Œæˆï¼ŒæˆåŠŸ {len(results)} ä¸ª")
    
    if not results:
        logger.error("æ²¡æœ‰æˆåŠŸçš„åˆ†æç»“æœ")
        return
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    logger.info("ä¿å­˜ç»“æœåˆ°æ•°æ®åº“...")
    success, fail = analyzer.save_to_db(results)
    logger.info(f"æ•°æ®åº“ä¿å­˜å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {fail}")
    
    # ç”Ÿæˆå¢é•¿æ’åæŠ¥å‘Š
    logger.info("ç”Ÿæˆå¢é•¿æ’åæŠ¥å‘Š...")
    report = analyzer.generate_growth_ranking_report(results)
    
    # ä¿å­˜æŠ¥å‘Š
    report_dir = Path(__file__).parent / "output" / "reports"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_file = report_dir / f"fans_growth_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    print(report)
    
    return results


if __name__ == "__main__":
    main()
