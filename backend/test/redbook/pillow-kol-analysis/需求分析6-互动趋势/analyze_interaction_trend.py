#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
KOL äº’åŠ¨è¶‹åŠ¿åˆ†æè„šæœ¬ - éœ€æ±‚6

éœ€æ±‚è¯´æ˜ï¼š
- æ•°æ®è¶‹åŠ¿ï¼ˆç²‰ä¸/é˜…è¯»/è¯„è®º/äº’åŠ¨ï¼‰
- ä½¿ç”¨ engageï¼ˆäº’åŠ¨=ç‚¹èµ+æ”¶è—+è¯„è®ºï¼‰ä½œä¸ºè¶‹åŠ¿æŒ‡æ ‡

æ•°æ®æ¥æºï¼š
- kol_core_data: 30å¤©æ¯æ—¥æ•°æ® (dailyData: imp, read, engage)

æ•°æ®åº“å­—æ®µï¼š
- interaction_trend_status: è¶‹åŠ¿çŠ¶æ€ (rising/stable/declining)
- interaction_trend_detail: JSONB è¶‹åŠ¿è¯¦æƒ…
- daily_imp_avg: 30å¤©æ—¥å‡æ›å…‰
- daily_read_avg: 30å¤©æ—¥å‡é˜…è¯»
- daily_engage_avg: 30å¤©æ—¥å‡äº’åŠ¨
"""

import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv
import statistics
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class InteractionTrendAnalysis:
    """äº’åŠ¨è¶‹åŠ¿åˆ†æç»“æœ"""
    # æ—¥å‡æ•°æ®
    daily_imp_avg: float           # 30å¤©æ—¥å‡æ›å…‰
    daily_read_avg: float          # 30å¤©æ—¥å‡é˜…è¯»
    daily_engage_avg: float        # 30å¤©æ—¥å‡äº’åŠ¨
    
    # è¶‹åŠ¿çŠ¶æ€
    interaction_trend_status: str  # rising/stable/declining
    
    # è¶‹åŠ¿è¯¦æƒ…
    interaction_trend_detail: Dict[str, Any]


class InteractionTrendAnalyzer:
    """äº’åŠ¨è¶‹åŠ¿åˆ†æå™¨"""
    
    def __init__(self, data_dir: str = None):
        base_dir = Path(__file__).parent.parent
        self.data_dir = Path(data_dir) if data_dir else base_dir / "output" / "api_data"
        self._init_supabase()
    
    def _init_supabase(self):
        """åˆå§‹åŒ– Supabase è¿æ¥"""
        backend_dir = Path(__file__).parent.parent.parent.parent.parent
        env_path = backend_dir / '.env'
        
        if env_path.exists():
            load_dotenv(env_path)
        
        from supabase import create_client
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_KEY')
        
        if not url or not key:
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® SUPABASE_URL å’Œ SUPABASE_KEY")
        
        self.supabase = create_client(url, key)
        logger.info("Supabase è¿æ¥æˆåŠŸ")
    
    def load_kol_data(self, kol_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½å•ä¸ª KOL çš„ API æ•°æ®"""
        kol_dir = self.data_dir / f"kol_{kol_id}"
        data_file = kol_dir / "all_data.json"
        
        if not data_file.exists():
            return None
        
        with open(data_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _calculate_trend(self, values: List[float]) -> Tuple[str, float]:
        """
        è®¡ç®—è¶‹åŠ¿çŠ¶æ€
        
        ä½¿ç”¨ç®€å•çº¿æ€§å›å½’æ–œç‡åˆ¤æ–­ï¼š
        - æ–œç‡ > 5%å‡å€¼ï¼šä¸Šå‡æœŸ
        - æ–œç‡ < -5%å‡å€¼ï¼šä¸‹é™æœŸ
        - å…¶ä»–ï¼šç¨³å®šæœŸ
        
        è¿”å›: (è¶‹åŠ¿çŠ¶æ€, æ–œç‡)
        """
        if not values or len(values) < 7:
            return 'stable', 0
        
        n = len(values)
        x_mean = (n - 1) / 2
        y_mean = sum(values) / n
        
        # è®¡ç®—æ–œç‡
        numerator = sum((i - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((i - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            return 'stable', 0
        
        slope = numerator / denominator
        
        # è®¡ç®—ç›¸å¯¹å˜åŒ–ç‡
        if y_mean == 0:
            return 'stable', 0
        
        relative_change = slope * n / y_mean  # 30å¤©æ€»å˜åŒ–ç‡
        
        # åˆ¤æ–­è¶‹åŠ¿
        if relative_change > 0.15:  # 30å¤©å¢é•¿>15%
            return 'rising', round(slope, 2)
        elif relative_change < -0.15:  # 30å¤©ä¸‹é™>15%
            return 'declining', round(slope, 2)
        else:
            return 'stable', round(slope, 2)
    
    def analyze_interaction_trend(self, kol_data: Dict[str, Any]) -> Optional[InteractionTrendAnalysis]:
        """
        åˆ†æäº’åŠ¨è¶‹åŠ¿
        
        ä½¿ç”¨ kol_core_data.dailyData ä¸­çš„ engage æ•°æ®
        """
        core_data_api = kol_data.get('apis', {}).get('kol_core_data', {})
        
        if core_data_api.get('code') != 0:
            logger.warning("kol_core_data æ•°æ®è·å–å¤±è´¥")
            return None
        
        data = core_data_api.get('data')
        if not data:
            logger.warning("kol_core_data data ä¸ºç©º")
            return None
        
        daily_data = data.get('dailyData', [])
        
        if not daily_data:
            logger.warning("dailyData ä¸ºç©º")
            return None
        
        # æå–æ•°æ®
        imp_list = []
        read_list = []
        engage_list = []
        
        for day in daily_data:
            imp_list.append(day.get('imp', 0) or 0)
            read_list.append(day.get('read', 0) or 0)
            engage_list.append(day.get('engage', 0) or 0)
        
        # è®¡ç®—æ—¥å‡å€¼
        daily_imp_avg = round(statistics.mean(imp_list), 2) if imp_list else 0
        daily_read_avg = round(statistics.mean(read_list), 2) if read_list else 0
        daily_engage_avg = round(statistics.mean(engage_list), 2) if engage_list else 0
        
        # è®¡ç®—äº’åŠ¨è¶‹åŠ¿
        trend_status, slope = self._calculate_trend(engage_list)
        
        # è®¡ç®—å‰ååŠæœˆå¯¹æ¯”
        mid = len(engage_list) // 2
        first_half_avg = statistics.mean(engage_list[:mid]) if engage_list[:mid] else 0
        second_half_avg = statistics.mean(engage_list[mid:]) if engage_list[mid:] else 0
        
        change_rate = ((second_half_avg - first_half_avg) / first_half_avg * 100) if first_half_avg > 0 else 0
        
        # æ„å»ºè¯¦æƒ…
        trend_detail = {
            'data_days': len(engage_list),
            'first_half_avg': round(first_half_avg, 2),
            'second_half_avg': round(second_half_avg, 2),
            'change_rate': round(change_rate, 2),
            'slope': slope,
            'daily_data': [
                {
                    'date': daily_data[i].get('dateKey', ''),
                    'imp': imp_list[i],
                    'read': read_list[i],
                    'engage': engage_list[i]
                }
                for i in range(min(30, len(daily_data)))  # æœ€å¤šä¿å­˜30å¤©
            ]
        }
        
        return InteractionTrendAnalysis(
            daily_imp_avg=daily_imp_avg,
            daily_read_avg=daily_read_avg,
            daily_engage_avg=daily_engage_avg,
            interaction_trend_status=trend_status,
            interaction_trend_detail=trend_detail
        )
    
    def get_all_kol_ids_from_files(self) -> List[str]:
        """ä»æ–‡ä»¶ç³»ç»Ÿè·å–æ‰€æœ‰æœ‰å®é™…æ•°æ®çš„ KOL ID åˆ—è¡¨"""
        kol_ids = []
        
        for kol_dir in sorted(self.data_dir.iterdir()):
            if not kol_dir.is_dir() or not kol_dir.name.startswith('kol_'):
                continue
            
            data_file = kol_dir / "all_data.json"
            if not data_file.exists():
                continue
            
            kol_id = kol_dir.name.replace('kol_', '')
            kol_ids.append(kol_id)
        
        return kol_ids
    
    def analyze_batch(self, kol_ids: List[str]) -> List[Tuple[str, str, InteractionTrendAnalysis]]:
        """æ‰¹é‡åˆ†æ KOL"""
        results = []
        failed = []
        
        for i, kol_id in enumerate(kol_ids):
            logger.info(f"åˆ†æè¿›åº¦: {i+1}/{len(kol_ids)} - KOL: {kol_id}")
            
            kol_data = self.load_kol_data(kol_id)
            if not kol_data:
                failed.append(kol_id)
                continue
            
            kol_name = kol_data.get('kol_name', 'Unknown')
            analysis = self.analyze_interaction_trend(kol_data)
            
            if analysis:
                results.append((kol_id, kol_name, analysis))
            else:
                failed.append(kol_id)
        
        logger.info(f"åˆ†æå®Œæˆ: æˆåŠŸ {len(results)}, å¤±è´¥ {len(failed)}")
        return results
    
    def save_to_db(self, results: List[Tuple[str, str, InteractionTrendAnalysis]]) -> Tuple[int, int]:
        """ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“"""
        success_count = 0
        fail_count = 0
        
        for kol_id, kol_name, analysis in results:
            try:
                data = {
                    'kol_id': kol_id,
                    'daily_imp_avg': analysis.daily_imp_avg,
                    'daily_read_avg': analysis.daily_read_avg,
                    'daily_engage_avg': analysis.daily_engage_avg,
                    'interaction_trend_status': analysis.interaction_trend_status,
                    'interaction_trend_detail': json.dumps(analysis.interaction_trend_detail, ensure_ascii=False),
                    'updated_at': datetime.now().isoformat()
                }
                
                self.supabase.table('gg_pgy_kol_analysis_result').upsert(
                    data,
                    on_conflict='kol_id,project_name'
                ).execute()
                
                success_count += 1
                
            except Exception as e:
                logger.error(f"ä¿å­˜ KOL {kol_id} å¤±è´¥: {e}")
                fail_count += 1
        
        return success_count, fail_count
    
    def generate_report(self, results: List[Tuple[str, str, InteractionTrendAnalysis]]) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not results:
            return "æ²¡æœ‰åˆ†æç»“æœ"
        
        total = len(results)
        
        # ç»Ÿè®¡å„è¶‹åŠ¿æ•°é‡
        rising_count = sum(1 for _, _, a in results if a.interaction_trend_status == 'rising')
        stable_count = sum(1 for _, _, a in results if a.interaction_trend_status == 'stable')
        declining_count = sum(1 for _, _, a in results if a.interaction_trend_status == 'declining')
        
        avg_imp = statistics.mean([a.daily_imp_avg for _, _, a in results])
        avg_read = statistics.mean([a.daily_read_avg for _, _, a in results])
        avg_engage = statistics.mean([a.daily_engage_avg for _, _, a in results])
        
        # æŒ‰æ—¥å‡äº’åŠ¨æ’åº
        sorted_results = sorted(results, key=lambda x: x[2].daily_engage_avg, reverse=True)
        
        report = f"""# KOL äº’åŠ¨è¶‹åŠ¿åˆ†ææŠ¥å‘Š

> **é¡¹ç›®**: æ•å¤´åˆ†æ  
> **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
> **KOL æ•°é‡**: {total}

---

## ä¸€ã€æ•´ä½“æ¦‚å†µ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| åˆ†æ KOL æ€»æ•° | {total} |
| ä¸Šå‡æœŸ (rising) | {rising_count} ({rising_count/total*100:.1f}%) |
| ç¨³å®šæœŸ (stable) | {stable_count} ({stable_count/total*100:.1f}%) |
| ä¸‹é™æœŸ (declining) | {declining_count} ({declining_count/total*100:.1f}%) |
| å¹³å‡æ—¥å‡æ›å…‰ | {avg_imp:,.0f} |
| å¹³å‡æ—¥å‡é˜…è¯» | {avg_read:,.0f} |
| å¹³å‡æ—¥å‡äº’åŠ¨ | {avg_engage:,.0f} |

---

## äºŒã€å®Œæ•´æ’åï¼ˆæŒ‰æ—¥å‡äº’åŠ¨ï¼‰

| æ’å | KOLåç§° | æ—¥å‡æ›å…‰ | æ—¥å‡é˜…è¯» | æ—¥å‡äº’åŠ¨ | è¶‹åŠ¿çŠ¶æ€ |
|------|---------|----------|----------|----------|----------|
"""
        status_icons = {
            'rising': 'ğŸ“ˆ ä¸Šå‡',
            'stable': 'â¡ï¸ ç¨³å®š',
            'declining': 'ğŸ“‰ ä¸‹é™'
        }
        
        for i, (kol_id, kol_name, a) in enumerate(sorted_results, 1):
            status_icon = status_icons.get(a.interaction_trend_status, 'â“')
            report += f"| {i} | {kol_name} | {a.daily_imp_avg:,.0f} | {a.daily_read_avg:,.0f} | {a.daily_engage_avg:,.0f} | {status_icon} |\n"
        
        report += f"""

---

## ä¸‰ã€åˆ¤æ–­æ ‡å‡†è¯´æ˜

- **è¶‹åŠ¿è®¡ç®—**: åŸºäº30å¤©æ—¥äº’åŠ¨æ•°æ®çš„çº¿æ€§å›å½’æ–œç‡
- **ä¸Šå‡æœŸ**: 30å¤©äº’åŠ¨å¢é•¿ > 15%
- **ä¸‹é™æœŸ**: 30å¤©äº’åŠ¨ä¸‹é™ > 15%
- **ç¨³å®šæœŸ**: å˜åŒ–åœ¨Â±15%ä¹‹å†…
- **æ—¥å‡äº’åŠ¨**: engageï¼ˆç‚¹èµ+æ”¶è—+è¯„è®ºï¼‰çš„30å¤©å¹³å‡å€¼

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}*
"""
        return report


def main():
    """ä¸»å‡½æ•°"""
    analyzer = InteractionTrendAnalyzer()
    
    logger.info("æ­£åœ¨è·å–æ‰€æœ‰ KOL åˆ—è¡¨...")
    kol_ids = analyzer.get_all_kol_ids_from_files()
    logger.info(f"æ‰¾åˆ° {len(kol_ids)} ä¸ª KOL")
    
    if not kol_ids:
        logger.error("æ²¡æœ‰æ‰¾åˆ° KOL æ•°æ®")
        return
    
    logger.info("å¼€å§‹åˆ†æäº’åŠ¨è¶‹åŠ¿...")
    results = analyzer.analyze_batch(kol_ids)
    logger.info(f"åˆ†æå®Œæˆï¼ŒæˆåŠŸ {len(results)} ä¸ª")
    
    if not results:
        logger.error("æ²¡æœ‰æˆåŠŸçš„åˆ†æç»“æœ")
        return
    
    logger.info("ä¿å­˜ç»“æœåˆ°æ•°æ®åº“...")
    success, fail = analyzer.save_to_db(results)
    logger.info(f"æ•°æ®åº“ä¿å­˜å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {fail}")
    
    logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_report(results)
    
    report_dir = Path(__file__).parent / "output"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_file = report_dir / f"interaction_trend_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    logger.info(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    print(report)
    
    return results


if __name__ == "__main__":
    main()
