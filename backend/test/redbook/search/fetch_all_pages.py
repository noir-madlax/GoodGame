#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦æœç´¢ç¬”è®° - è·å–å¤šé¡µæ•°æ®å¹¶ç»Ÿè®¡è¯„è®ºæ•°é‡

ç”¨é€”:
- è·å–æœç´¢ç»“æœçš„ç¬¬1-5é¡µ
- ç»Ÿè®¡æ¯ä¸ªå¸–å­çš„è¯„è®ºæ•°é‡
- æ‰¾å‡ºè¯„è®ºæœ€å¤šçš„å¸–å­
"""

import os
import json
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List
import time


def load_api_key() -> str:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½ TikHub API Key"""
    backend_dir = Path(__file__).parent.parent.parent.parent
    env_path = backend_dir / '.env'
    
    if env_path.exists():
        load_dotenv(env_path)
    
    api_key = os.getenv('tikhub_API_KEY')
    if not api_key:
        raise ValueError(f"ç¯å¢ƒå˜é‡ tikhub_API_KEY æœªè®¾ç½®")
    
    return api_key


def search_notes(
    api_key: str,
    keyword: str,
    page: int = 1,
    sort_type: str = "general",
    filter_note_type: str = "ä¸é™",
    filter_note_time: str = "åŠå¹´å†…",
    search_id: str = "",
    session_id: str = ""
) -> Dict[str, Any]:
    """è°ƒç”¨å°çº¢ä¹¦æœç´¢ç¬”è®°æ¥å£"""
    url = "https://api.tikhub.io/api/v1/xiaohongshu/app/search_notes"
    
    headers = {
        'accept': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }
    
    params = {
        'keyword': keyword,
        'page': page,
        'sort_type': sort_type,
        'filter_note_type': filter_note_type,
        'filter_note_time': filter_note_time
    }
    
    # ç¿»é¡µæ—¶éœ€è¦æºå¸¦ search_id å’Œ session_id
    if search_id:
        params['search_id'] = search_id
    if session_id:
        params['session_id'] = session_id
    
    print(f"ğŸ“¡ è¯·æ±‚ç¬¬ {page} é¡µ...")
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
            return {"error": f"HTTP {response.status_code}"}
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
        return {"error": str(e)}


def extract_notes_from_response(result: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä»å“åº”ä¸­æå–ç¬”è®°åˆ—è¡¨"""
    notes = []
    try:
        data = result.get('data', {})
        inner_data = data.get('data', {})
        items = inner_data.get('items', [])
        
        for item in items:
            if item.get('model_type') == 'note':
                note = item.get('note', {})
                if note:
                    notes.append(note)
    except Exception as e:
        print(f"è§£æç¬”è®°å¤±è´¥: {e}")
    
    return notes


def get_session_ids(result: Dict[str, Any]) -> tuple:
    """ä»å“åº”ä¸­æå– searchId å’Œ sessionId"""
    data = result.get('data', {})
    search_id = data.get('searchId', '')
    session_id = data.get('sessionId', '')
    return search_id, session_id


def main():
    print("=" * 60)
    print("å°çº¢ä¹¦æœç´¢ç¬”è®° - è·å–å¤šé¡µæ•°æ®")
    print("=" * 60)
    
    api_key = load_api_key()
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    # æœç´¢å‚æ•°
    keyword = "æŠ±æ•"
    all_notes = []
    search_id = ""
    session_id = ""
    
    # è·å–ç¬¬1-5é¡µ
    for page in range(1, 6):
        result = search_notes(
            api_key,
            keyword=keyword,
            page=page,
            filter_note_time="åŠå¹´å†…",
            search_id=search_id,
            session_id=session_id
        )
        
        if result.get('code') == 200:
            # æå– session IDs ç”¨äºç¿»é¡µ
            search_id, session_id = get_session_ids(result)
            
            # æå–ç¬”è®°
            notes = extract_notes_from_response(result)
            all_notes.extend(notes)
            print(f"   âœ… ç¬¬ {page} é¡µè·å– {len(notes)} æ¡ç¬”è®°")
            
            # ä¿å­˜æ¯é¡µçš„åŸå§‹å“åº”
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            with open(output_dir / f"page_{page}_{timestamp}.json", 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
        else:
            print(f"   âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥")
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        if page < 5:
            time.sleep(1)
    
    print(f"\nğŸ“Š å…±è·å– {len(all_notes)} æ¡ç¬”è®°")
    
    # ç»Ÿè®¡è¯„è®ºæ•°é‡å¹¶æ’åº
    notes_with_comments = []
    for note in all_notes:
        note_id = note.get('id', 'N/A')
        title = note.get('title', note.get('display_title', 'æ— æ ‡é¢˜'))
        comments_count = note.get('comments_count', 0) or 0
        liked_count = note.get('liked_count', 0) or 0
        collected_count = note.get('collected_count', 0) or 0
        note_type = note.get('type', 'unknown')
        user = note.get('user', {})
        nickname = user.get('nickname', 'N/A')
        
        notes_with_comments.append({
            'id': note_id,
            'title': title[:50] if title else 'æ— æ ‡é¢˜',
            'comments_count': comments_count,
            'liked_count': liked_count,
            'collected_count': collected_count,
            'type': note_type,
            'author': nickname
        })
    
    # æŒ‰è¯„è®ºæ•°æ’åº
    notes_with_comments.sort(key=lambda x: x['comments_count'], reverse=True)
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print(f"\n{'='*80}")
    print("ğŸ“ å¸–å­è¯„è®ºæ•°é‡ç»Ÿè®¡ï¼ˆæŒ‰è¯„è®ºæ•°é™åºï¼‰")
    print(f"{'='*80}")
    print(f"{'åºå·':<4} {'ID':<26} {'è¯„è®ºæ•°':<8} {'ç‚¹èµæ•°':<8} {'æ”¶è—æ•°':<8} {'ç±»å‹':<8} {'æ ‡é¢˜'}")
    print("-" * 80)
    
    for i, note in enumerate(notes_with_comments, 1):
        print(f"{i:<4} {note['id']:<26} {note['comments_count']:<8} {note['liked_count']:<8} {note['collected_count']:<8} {note['type']:<8} {note['title'][:30]}")
    
    # ä¿å­˜ç»Ÿè®¡ç»“æœ
    stats_file = output_dir / f"notes_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_notes': len(notes_with_comments),
            'keyword': keyword,
            'notes': notes_with_comments
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {stats_file}")
    
    # æ‰¾å‡ºè¯„è®ºæœ€å¤šçš„3ä¸ªå¸–å­
    top3 = notes_with_comments[:3]
    print(f"\n{'='*60}")
    print("ğŸ† è¯„è®ºæœ€å¤šçš„ Top 3 å¸–å­")
    print(f"{'='*60}")
    for i, note in enumerate(top3, 1):
        print(f"\nã€Top {i}ã€‘")
        print(f"  ID: {note['id']}")
        print(f"  æ ‡é¢˜: {note['title']}")
        print(f"  è¯„è®ºæ•°: {note['comments_count']}")
        print(f"  ç‚¹èµæ•°: {note['liked_count']}")
        print(f"  ä½œè€…: {note['author']}")
    
    # ä¿å­˜ Top3 ID ä¾›åç»­ä½¿ç”¨
    top3_file = output_dir / "top3_notes.json"
    with open(top3_file, 'w', encoding='utf-8') as f:
        json.dump(top3, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ Top3 å¸–å­ä¿¡æ¯å·²ä¿å­˜: {top3_file}")


if __name__ == "__main__":
    main()
