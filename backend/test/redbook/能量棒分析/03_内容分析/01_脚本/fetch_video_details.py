#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é˜¶æ®µ6-1: è·å–è§†é¢‘è¯¦æƒ…

åŠŸèƒ½ï¼š
1. ä»è¯¦ç»†æ•°æ®ä¸­è¯»å–ç¬”è®°åˆ—è¡¨
2. ç­›é€‰éå¹¿å‘Šè§†é¢‘ï¼Œæ¯äººTOP 5
3. è°ƒç”¨APIè·å–è§†é¢‘è¯¦æƒ…ï¼ˆåŒ…å«è§†é¢‘URLï¼‰
4. ä¿å­˜åˆ°æœ¬åœ°

ç›®æ ‡KOL (4äºº):
- åŠ ç»’å·å­: 6080c7ca0000000001004c6b
- æ±¤åœ†å°ç©å­: 6297c9030000000021022723
- vikkå•¦å•¦å•¦: 59476bb282ec39663ed76f6a
- å‡ºé€ƒçš„å“ˆå“ˆyağŸˆ: 58ef740f6a6a696f5c5fa25f

é¢„è®¡APIè°ƒç”¨: 4 Ã— 5 = 20æ¬¡
"""

import os
import json
import asyncio
import aiohttp
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é¡¹ç›®è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
PROJECT_DIR = SCRIPT_DIR.parent
DATA_DIR = SCRIPT_DIR.parent.parent / "01_KOLæ•°æ®è·å–" / "02_è¯¦ç»†æ•°æ®"
OUTPUT_DIR = PROJECT_DIR / "02_è§†é¢‘æ•°æ®"

# ç›®æ ‡KOL
TARGET_KOLS = [
    {"kol_id": "6080c7ca0000000001004c6b", "name": "åŠ ç»’å·å­"},
    {"kol_id": "6297c9030000000021022723", "name": "æ±¤åœ†å°ç©å­"},
    {"kol_id": "59476bb282ec39663ed76f6a", "name": "vikkå•¦å•¦å•¦"},
    {"kol_id": "58ef740f6a6a696f5c5fa25f", "name": "å‡ºé€ƒçš„å“ˆå“ˆyağŸˆ"},
]

CONFIG = {
    "api_base_url": "https://api.justoneapi.com",
    "concurrency": 5,
    "timeout": 30,
    "api_delay": 0.5,
    "top_n": 5,  # æ¯äººå–TOP 5è§†é¢‘
}


class VideoDetailFetcher:
    """è§†é¢‘è¯¦æƒ…è·å–å™¨"""
    
    def __init__(self):
        self.config = CONFIG
        self.token = self._load_api_token()
        self.base_url = self.config['api_base_url']
        self.semaphore = asyncio.Semaphore(self.config['concurrency'])
        
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    def _load_api_token(self) -> str:
        """åŠ è½½API Token"""
        # backendç›®å½•è·¯å¾„
        backend_dir = Path(__file__).parent.parent.parent.parent.parent.parent
        env_path = backend_dir / '.env'
        
        if env_path.exists():
            load_dotenv(env_path)
        
        token = os.getenv('JUSTONEAPI_API_KEY', '')
        if not token:
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® JUSTONEAPI_API_KEY")
        return token
    
    def get_kol_videos(self, kol_id: str, kol_name: str) -> List[Dict]:
        """ä»æœ¬åœ°æ•°æ®è·å–KOLçš„è§†é¢‘åˆ—è¡¨"""
        note_list_file = DATA_DIR / f"kol_{kol_id}" / "kol_note_list.json"
        
        if not note_list_file.exists():
            logger.warning(f"æ‰¾ä¸åˆ° {kol_name} çš„ç¬”è®°åˆ—è¡¨æ–‡ä»¶")
            return []
        
        with open(note_list_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        result = data.get('result', {})
        if result.get('code') != 0:
            logger.warning(f"{kol_name} ç¬”è®°åˆ—è¡¨APIè¿”å›é”™è¯¯")
            return []
        
        notes = result.get('data', {}).get('list', []) or []
        
        # ç­›é€‰ï¼šè§†é¢‘ + éå¹¿å‘Š
        videos = []
        for note in notes:
            if note.get('isVideo') and not note.get('isAdvertise'):
                videos.append({
                    'note_id': note.get('noteId'),
                    'kol_id': kol_id,
                    'kol_name': kol_name,
                    'title': note.get('title', ''),
                    'is_video': True,
                    'is_advertise': False,
                    'read_num': note.get('readNum', 0) or 0,
                    'like_num': note.get('likeNum', 0) or 0,
                    'collect_num': note.get('collectNum', 0) or 0,
                    'publish_date': note.get('date', ''),
                    'img_url': note.get('imgUrl', ''),
                    'total_interact': (note.get('likeNum', 0) or 0) + (note.get('collectNum', 0) or 0)
                })
        
        # æŒ‰äº’åŠ¨æ’åºï¼Œå–TOP N
        videos.sort(key=lambda x: x['total_interact'], reverse=True)
        videos = videos[:self.config['top_n']]
        
        # æ·»åŠ æ’å
        for i, v in enumerate(videos):
            v['rank'] = i + 1
        
        logger.info(f"  {kol_name}: ç­›é€‰å‡º {len(videos)} ä¸ªè§†é¢‘")
        return videos
    
    async def fetch_note_detail(self, session: aiohttp.ClientSession, 
                                 note_id: str, kol_name: str) -> Dict[str, Any]:
        """è·å–ç¬”è®°è¯¦æƒ…ï¼ˆåŒ…å«è§†é¢‘URLï¼‰"""
        async with self.semaphore:
            url = f"{self.base_url}/api/xiaohongshu-pgy/api/solar/note/noteId/detail/v1"
            params = {
                'token': self.token,
                'noteId': note_id
            }
            
            try:
                async with session.get(url, params=params,
                                       timeout=aiohttp.ClientTimeout(total=self.config['timeout'])) as response:
                    if response.status == 200:
                        result = await response.json()
                        await asyncio.sleep(self.config['api_delay'])
                        return result
                    else:
                        logger.error(f"è·å– {note_id} è¯¦æƒ…å¤±è´¥: HTTP {response.status}")
                        return {"error": f"HTTP {response.status}"}
            except Exception as e:
                logger.error(f"è·å– {note_id} è¯¦æƒ…å¼‚å¸¸: {e}")
                return {"error": str(e)}
    
    def extract_video_url(self, detail_data: Dict) -> Optional[str]:
        """ä»è¯¦æƒ…æ•°æ®ä¸­æå–è§†é¢‘URL"""
        if detail_data.get('code') != 0:
            return None
        
        data = detail_data.get('data', {})
        if not data:
            return None
        
        # è·¯å¾„1: videoInfo.videoUrl
        video_info = data.get('videoInfo', {})
        if video_info:
            video_url = video_info.get('videoUrl')
            if video_url:
                return video_url
        
        return None
    
    def extract_video_content(self, detail_data: Dict) -> str:
        """æå–è§†é¢‘æ­£æ–‡å†…å®¹"""
        if detail_data.get('code') != 0:
            return ""
        
        data = detail_data.get('data', {})
        return data.get('content', '') or ''
    
    async def fetch_all(self):
        """è·å–æ‰€æœ‰è§†é¢‘è¯¦æƒ…"""
        logger.info("=" * 60)
        logger.info("ğŸš€ é˜¶æ®µ6-1: è·å–è§†é¢‘è¯¦æƒ…")
        logger.info("=" * 60)
        
        # æ”¶é›†æ‰€æœ‰è§†é¢‘
        all_videos = []
        for kol in TARGET_KOLS:
            videos = self.get_kol_videos(kol['kol_id'], kol['name'])
            all_videos.extend(videos)
        
        logger.info(f"\næ€»è®¡ {len(all_videos)} ä¸ªè§†é¢‘å¾…è·å–è¯¦æƒ…")
        logger.info(f"é¢„è®¡APIè°ƒç”¨: {len(all_videos)} æ¬¡\n")
        
        # è·å–è¯¦æƒ…
        async with aiohttp.ClientSession() as session:
            for i, video in enumerate(all_videos, 1):
                note_id = video['note_id']
                kol_name = video['kol_name']
                title = video['title'][:20] if video['title'] else 'æ— æ ‡é¢˜'
                
                logger.info(f"[{i}/{len(all_videos)}] {kol_name} - {title}...")
                
                detail = await self.fetch_note_detail(session, note_id, kol_name)
                video['detail_data'] = detail
                video['video_url'] = self.extract_video_url(detail)
                video['content'] = self.extract_video_content(detail)
                
                if video['video_url']:
                    logger.info(f"  âœ… è·å–è§†é¢‘URLæˆåŠŸ")
                else:
                    logger.warning(f"  âš ï¸ æœªæ‰¾åˆ°è§†é¢‘URL")
        
        # ä¿å­˜ç»“æœ
        self._save_results(all_videos)
        self._print_summary(all_videos)
    
    def _save_results(self, videos: List[Dict]):
        """ä¿å­˜ç»“æœ"""
        # ä¿å­˜æ±‡æ€»
        video_list = []
        for v in videos:
            video_list.append({
                'note_id': v['note_id'],
                'kol_id': v['kol_id'],
                'kol_name': v['kol_name'],
                'title': v['title'],
                'read_num': v['read_num'],
                'like_num': v['like_num'],
                'collect_num': v['collect_num'],
                'total_interact': v['total_interact'],
                'publish_date': v['publish_date'],
                'img_url': v['img_url'],
                'video_url': v['video_url'],
                'content': v.get('content', '')[:500],  # æˆªå–å‰500å­—
                'rank': v['rank'],
                'has_video_url': v['video_url'] is not None,
                'downloaded': False,
                'file_path': None
            })
        
        summary_file = OUTPUT_DIR / "video_list.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                'generated_at': datetime.now().isoformat(),
                'total_videos': len(videos),
                'videos_with_url': sum(1 for v in videos if v['video_url']),
                'videos': video_list
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ“„ è§†é¢‘åˆ—è¡¨å·²ä¿å­˜: {summary_file}")
        
        # æŒ‰KOLåˆ†ç›®å½•ä¿å­˜è¯¦æƒ…
        for kol in TARGET_KOLS:
            kol_id = kol['kol_id']
            kol_videos = [v for v in videos if v['kol_id'] == kol_id]
            
            if not kol_videos:
                continue
            
            kol_dir = OUTPUT_DIR / f"kol_{kol_id}"
            details_dir = kol_dir / "details"
            details_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜KOLä¿¡æ¯
            kol_info = {
                'kol_id': kol_id,
                'kol_name': kol['name'],
                'video_count': len(kol_videos),
                'videos_with_url': sum(1 for v in kol_videos if v['video_url'])
            }
            with open(kol_dir / "info.json", 'w', encoding='utf-8') as f:
                json.dump(kol_info, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æ¯ä¸ªè§†é¢‘è¯¦æƒ…
            for v in kol_videos:
                detail_file = details_dir / f"{v['note_id']}.json"
                with open(detail_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'note_id': v['note_id'],
                        'title': v['title'],
                        'video_url': v['video_url'],
                        'content': v.get('content', ''),
                        'img_url': v['img_url'],
                        'publish_date': v['publish_date'],
                        'read_num': v['read_num'],
                        'like_num': v['like_num'],
                        'collect_num': v['collect_num'],
                        'total_interact': v['total_interact'],
                        'rank': v['rank'],
                        'detail_data': v['detail_data']
                    }, f, ensure_ascii=False, indent=2)
    
    def _print_summary(self, videos: List[Dict]):
        """æ‰“å°æ±‡æ€»"""
        total = len(videos)
        with_url = sum(1 for v in videos if v['video_url'])
        
        logger.info("")
        logger.info("=" * 60)
        logger.info("ğŸ“‹ è§†é¢‘è¯¦æƒ…è·å–æ±‡æ€»")
        logger.info("=" * 60)
        logger.info(f"æ€»è§†é¢‘æ•°: {total}")
        logger.info(f"æˆåŠŸè·å–URL: {with_url} ({with_url/total*100:.1f}%)")
        logger.info(f"æœªè·å–URL: {total - with_url}")
        logger.info("")
        
        # æŒ‰KOLç»Ÿè®¡
        logger.info("æŒ‰KOLç»Ÿè®¡:")
        for kol in TARGET_KOLS:
            kol_videos = [v for v in videos if v['kol_id'] == kol['kol_id']]
            kol_with_url = sum(1 for v in kol_videos if v['video_url'])
            status = "âœ…" if kol_with_url == len(kol_videos) else "âš ï¸"
            logger.info(f"  {status} {kol['name']}: {kol_with_url}/{len(kol_videos)}")


async def main():
    """ä¸»å‡½æ•°"""
    fetcher = VideoDetailFetcher()
    await fetcher.fetch_all()


if __name__ == "__main__":
    asyncio.run(main())
